{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "19aa883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90120496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_012</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_012  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0           0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1           0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2           0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3           0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4           0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                   0.0           0.0     0.0  ...            1.0   \n",
       "1                   0.0           1.0     0.0  ...            0.0   \n",
       "2                   0.0           0.0     1.0  ...            1.0   \n",
       "3                   0.0           1.0     1.0  ...            1.0   \n",
       "4                   0.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
       "0          0.0      5.0      18.0      15.0       1.0  0.0   9.0        4.0   \n",
       "1          1.0      3.0       0.0       0.0       0.0  0.0   7.0        6.0   \n",
       "2          1.0      5.0      30.0      30.0       1.0  0.0   9.0        4.0   \n",
       "3          0.0      2.0       0.0       0.0       0.0  0.0  11.0        3.0   \n",
       "4          0.0      2.0       3.0       0.0       0.0  0.0  11.0        5.0   \n",
       "\n",
       "   Income  \n",
       "0     3.0  \n",
       "1     1.0  \n",
       "2     8.0  \n",
       "3     6.0  \n",
       "4     4.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(',./Resources/diabetes_health_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77e0bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = df[\"Diabetes_012\"].values\n",
    "X = df.drop(columns=\"Diabetes_012\").values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e19a62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4325062c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 120)               2640      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                6050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                1530      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 10,251\n",
      "Trainable params: 10,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 120\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 30\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02451af7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5946/5946 [==============================] - 6s 989us/step - loss: -9.3992 - accuracy: 0.7185\n",
      "Epoch 2/200\n",
      "5946/5946 [==============================] - 6s 978us/step - loss: -429.2288 - accuracy: 0.6922\n",
      "Epoch 3/200\n",
      "5946/5946 [==============================] - 6s 965us/step - loss: -2761.5806 - accuracy: 0.6792\n",
      "Epoch 4/200\n",
      "5946/5946 [==============================] - 6s 976us/step - loss: -9197.4619 - accuracy: 0.66850s\n",
      "Epoch 5/200\n",
      "5946/5946 [==============================] - 6s 962us/step - loss: -23245.3711 - accuracy: 0.6651\n",
      "Epoch 6/200\n",
      "5946/5946 [==============================] - 6s 940us/step - loss: -48261.3047 - accuracy: 0.6603\n",
      "Epoch 7/200\n",
      "5946/5946 [==============================] - 6s 960us/step - loss: -88736.3516 - accuracy: 0.6596 0s - loss: -86060.0312 -\n",
      "Epoch 8/200\n",
      "5946/5946 [==============================] - 6s 981us/step - loss: -150494.0938 - accuracy: 0.6573\n",
      "Epoch 9/200\n",
      "5946/5946 [==============================] - 6s 980us/step - loss: -239131.2500 - accuracy: 0.6573\n",
      "Epoch 10/200\n",
      "5946/5946 [==============================] - 6s 970us/step - loss: -362127.5625 - accuracy: 0.65740s - loss: -349140.0938 - ac\n",
      "Epoch 11/200\n",
      "5946/5946 [==============================] - 6s 971us/step - loss: -523719.8125 - accuracy: 0.6572\n",
      "Epoch 12/200\n",
      "5946/5946 [==============================] - 6s 963us/step - loss: -738984.1250 - accuracy: 0.6567\n",
      "Epoch 13/200\n",
      "5946/5946 [==============================] - 6s 969us/step - loss: -1011170.8750 - accuracy: 0.6568\n",
      "Epoch 14/200\n",
      "5946/5946 [==============================] - 6s 975us/step - loss: -1345572.1250 - accuracy: 0.6573\n",
      "Epoch 15/200\n",
      "5946/5946 [==============================] - 6s 984us/step - loss: -1764343.7500 - accuracy: 0.6568\n",
      "Epoch 16/200\n",
      "5946/5946 [==============================] - 6s 982us/step - loss: -2268930.7500 - accuracy: 0.6566 0s - loss: -2284409.7500 - \n",
      "Epoch 17/200\n",
      "5946/5946 [==============================] - 6s 990us/step - loss: -2859600.7500 - accuracy: 0.6567 4s - l\n",
      "Epoch 18/200\n",
      "5946/5946 [==============================] - 6s 986us/step - loss: -3570510.5000 - accuracy: 0.6578 0s - loss: -3600695.7500 - accuracy\n",
      "Epoch 19/200\n",
      "5946/5946 [==============================] - 6s 972us/step - loss: -4399895.5000 - accuracy: 0.6579\n",
      "Epoch 20/200\n",
      "5946/5946 [==============================] - 6s 987us/step - loss: -5381580.0000 - accuracy: 0.6579\n",
      "Epoch 21/200\n",
      "5946/5946 [==============================] - 6s 964us/step - loss: -6501555.0000 - accuracy: 0.6583 5s - loss: -799 - ETA: 1s - loss: -66865\n",
      "Epoch 22/200\n",
      "5946/5946 [==============================] - 6s 976us/step - loss: -7807749.0000 - accuracy: 0.6581\n",
      "Epoch 23/200\n",
      "5946/5946 [==============================] - 6s 976us/step - loss: -9287119.0000 - accuracy: 0.6575 4s - loss - ETA: 2s - - ETA: 0s - loss: -8835999.0000 - acc\n",
      "Epoch 24/200\n",
      "5946/5946 [==============================] - 6s 991us/step - loss: -10993806.0000 - accuracy: 0.6582 - ETA: 0s - l\n",
      "Epoch 25/200\n",
      "5946/5946 [==============================] - 6s 978us/step - loss: -12884981.0000 - accuracy: 0.6585\n",
      "Epoch 26/200\n",
      "5946/5946 [==============================] - 6s 987us/step - loss: -15040634.0000 - accuracy: 0.6574: 0s - loss: -14898368.0000 - accuracy: 0.\n",
      "Epoch 27/200\n",
      "5946/5946 [==============================] - 6s 993us/step - loss: -17446640.0000 - accuracy: 0.6586\n",
      "Epoch 28/200\n",
      "5946/5946 [==============================] - 6s 984us/step - loss: -20101010.0000 - accuracy: 0.65800s - loss: -19\n",
      "Epoch 29/200\n",
      "5946/5946 [==============================] - 6s 993us/step - loss: -23012838.0000 - accuracy: 0.65830s - loss: -23034288.0000 - accuracy: 0.65\n",
      "Epoch 30/200\n",
      "5946/5946 [==============================] - 6s 976us/step - loss: -26324298.0000 - accuracy: 0.6580\n",
      "Epoch 31/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -29908048.0000 - accuracy: 0.6580: \n",
      "Epoch 32/200\n",
      "5946/5946 [==============================] - 6s 985us/step - loss: -33801384.0000 - accuracy: 0.6583\n",
      "Epoch 33/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -38082416.0000 - accuracy: 0.6566\n",
      "Epoch 34/200\n",
      "5946/5946 [==============================] - 6s 989us/step - loss: -42848308.0000 - accuracy: 0.6573\n",
      "Epoch 35/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -47972668.0000 - accuracy: 0.6579\n",
      "Epoch 36/200\n",
      "5946/5946 [==============================] - 6s 998us/step - loss: -53523080.0000 - accuracy: 0.6575\n",
      "Epoch 37/200\n",
      "5946/5946 [==============================] - 6s 983us/step - loss: -59650792.0000 - accuracy: 0.6573\n",
      "Epoch 38/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -66278160.0000 - accuracy: 0.6579: 0s - loss: -66084364.0000 - accuracy: 0.65\n",
      "Epoch 39/200\n",
      "5946/5946 [==============================] - 6s 992us/step - loss: -73458264.0000 - accuracy: 0.6572\n",
      "Epoch 40/200\n",
      "5946/5946 [==============================] - ETA: 0s - loss: -81444656.0000 - accuracy: 0.6569 ETA: 0s - loss: -81659688.0 - 6s 1ms/step - loss: -81120528.0000 - accuracy: 0.6570\n",
      "Epoch 41/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -89354600.0000 - accuracy: 0.6558\n",
      "Epoch 42/200\n",
      "5946/5946 [==============================] - 6s 972us/step - loss: -98338784.0000 - accuracy: 0.65701s - loss: - - ETA: 0s - loss: -9416\n",
      "Epoch 43/200\n",
      "5946/5946 [==============================] - 6s 985us/step - loss: -107948560.0000 - accuracy: 0.6555\n",
      "Epoch 44/200\n",
      "5946/5946 [==============================] - 6s 991us/step - loss: -118190080.0000 - accuracy: 0.6561\n",
      "Epoch 45/200\n",
      "5946/5946 [==============================] - 6s 998us/step - loss: -129052392.0000 - accuracy: 0.6555\n",
      "Epoch 46/200\n",
      "5946/5946 [==============================] - 6s 997us/step - loss: -140801296.0000 - accuracy: 0.6570 2s - lo - ETA: 1s - loss: -136076576.00\n",
      "Epoch 47/200\n",
      "5946/5946 [==============================] - 6s 994us/step - loss: -153189632.0000 - accuracy: 0.6571 4s - loss: -154766480.0000 - a - ETA: 1s - loss: -154\n",
      "Epoch 48/200\n",
      "5946/5946 [==============================] - 6s 983us/step - loss: -166507296.0000 - accuracy: 0.6579\n",
      "Epoch 49/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -180526272.0000 - accuracy: 0.6572\n",
      "Epoch 50/200\n",
      "5946/5946 [==============================] - 6s 993us/step - loss: -195796064.0000 - accuracy: 0.6588\n",
      "Epoch 51/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -211554688.0000 - accuracy: 0.6582A: 0s - loss: -203727728.0000 - acc\n",
      "Epoch 52/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -228208656.0000 - accuracy: 0.6593A: 3s - loss: -230986496.0000  - ETA: 3s - loss: -223465648.0000 - accurac\n",
      "Epoch 53/200\n",
      "5946/5946 [==============================] - 6s 975us/step - loss: -246292896.0000 - accuracy: 0.6602\n",
      "Epoch 54/200\n",
      "5946/5946 [==============================] - 6s 978us/step - loss: -264807344.0000 - accuracy: 0.6589\n",
      "Epoch 55/200\n",
      "5946/5946 [==============================] - 6s 962us/step - loss: -284755392.0000 - accuracy: 0.6590 4s - loss: \n",
      "Epoch 56/200\n",
      "5946/5946 [==============================] - 6s 987us/step - loss: -305734816.0000 - accuracy: 0.6584 2s -\n",
      "Epoch 57/200\n",
      "5946/5946 [==============================] - 6s 971us/step - loss: -328167552.0000 - accuracy: 0.6591\n",
      "Epoch 58/200\n",
      "5946/5946 [==============================] - 6s 992us/step - loss: -351319904.0000 - accuracy: 0.6599\n",
      "Epoch 59/200\n",
      "5946/5946 [==============================] - 6s 990us/step - loss: -376434144.0000 - accuracy: 0.6616\n",
      "Epoch 60/200\n",
      "5946/5946 [==============================] - 6s 995us/step - loss: -401698528.0000 - accuracy: 0.6597 1s - loss: -388359104.0000 - accuracy: 0.6 - ETA: 1s - loss: -395552480.0\n",
      "Epoch 61/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -428956896.0000 - accuracy: 0.6604A:\n",
      "Epoch 62/200\n",
      "5946/5946 [==============================] - 6s 953us/step - loss: -457855936.0000 - accuracy: 0.6602\n",
      "Epoch 63/200\n",
      "5946/5946 [==============================] - 6s 968us/step - loss: -487065216.0000 - accuracy: 0.6585\n",
      "Epoch 64/200\n",
      "5946/5946 [==============================] - 6s 968us/step - loss: -518663360.0000 - accuracy: 0.6614 0s - loss: -508638240.0000 - accuracy: 0\n",
      "Epoch 65/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -551853312.0000 - accuracy: 0.6609\n",
      "Epoch 66/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5946/5946 [==============================] - 6s 976us/step - loss: -586363840.0000 - accuracy: 0.6608\n",
      "Epoch 67/200\n",
      "5946/5946 [==============================] - 6s 984us/step - loss: -621802752.0000 - accuracy: 0.6602\n",
      "Epoch 68/200\n",
      "5946/5946 [==============================] - 6s 982us/step - loss: -659925632.0000 - accuracy: 0.6611 2\n",
      "Epoch 69/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -698909952.0000 - accuracy: 0.6605A: 0s - loss: -679379840.0000 - accur\n",
      "Epoch 70/200\n",
      "5946/5946 [==============================] - 6s 981us/step - loss: -739625280.0000 - accuracy: 0.6598\n",
      "Epoch 71/200\n",
      "5946/5946 [==============================] - 6s 989us/step - loss: -784234688.0000 - accuracy: 0.6601 3s - loss: - ETA: 1s - \n",
      "Epoch 72/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -827767616.0000 - accuracy: 0.6606\n",
      "Epoch 73/200\n",
      "5946/5946 [==============================] - 6s 988us/step - loss: -873701376.0000 - accuracy: 0.6604 4s -\n",
      "Epoch 74/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -922580992.0000 - accuracy: 0.6603A: 4s - loss: \n",
      "Epoch 75/200\n",
      "5946/5946 [==============================] - 6s 998us/step - loss: -972777024.0000 - accuracy: 0.6616\n",
      "Epoch 76/200\n",
      "5946/5946 [==============================] - 6s 998us/step - loss: -1025539712.0000 - accuracy: 0.6599\n",
      "Epoch 77/200\n",
      "5946/5946 [==============================] - 6s 989us/step - loss: -1080264192.0000 - accuracy: 0.6606\n",
      "Epoch 78/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -1137556992.0000 - accuracy: 0.6608\n",
      "Epoch 79/200\n",
      "5946/5946 [==============================] - 6s 994us/step - loss: -1196732672.0000 - accuracy: 0.66111s - l\n",
      "Epoch 80/200\n",
      "5946/5946 [==============================] - 6s 973us/step - loss: -1257083264.0000 - accuracy: 0.6609\n",
      "Epoch 81/200\n",
      "5946/5946 [==============================] - 6s 979us/step - loss: -1320060800.0000 - accuracy: 0.6608\n",
      "Epoch 82/200\n",
      "5946/5946 [==============================] - 6s 975us/step - loss: -1385773056.0000 - accuracy: 0.6612\n",
      "Epoch 83/200\n",
      "5946/5946 [==============================] - 6s 982us/step - loss: -1454158592.0000 - accuracy: 0.6611\n",
      "Epoch 84/200\n",
      "5946/5946 [==============================] - 6s 986us/step - loss: -1525530624.0000 - accuracy: 0.6607\n",
      "Epoch 85/200\n",
      "5946/5946 [==============================] - 6s 976us/step - loss: -1599687296.0000 - accuracy: 0.6615\n",
      "Epoch 86/200\n",
      "5946/5946 [==============================] - 6s 976us/step - loss: -1674429440.0000 - accuracy: 0.66071s - loss: -1645870336.0 - ETA: 0s - loss: -1680243584\n",
      "Epoch 87/200\n",
      "5946/5946 [==============================] - 6s 994us/step - loss: -1753473536.0000 - accuracy: 0.6607\n",
      "Epoch 88/200\n",
      "5946/5946 [==============================] - 6s 998us/step - loss: -1834314240.0000 - accuracy: 0.6613\n",
      "Epoch 89/200\n",
      "5946/5946 [==============================] - 6s 995us/step - loss: -1917991040.0000 - accuracy: 0.6610\n",
      "Epoch 90/200\n",
      "5946/5946 [==============================] - 6s 982us/step - loss: -2005816832.0000 - accuracy: 0.6611\n",
      "Epoch 91/200\n",
      "5946/5946 [==============================] - 6s 940us/step - loss: -2094964224.0000 - accuracy: 0.6614\n",
      "Epoch 92/200\n",
      "5946/5946 [==============================] - 6s 957us/step - loss: -2189320448.0000 - accuracy: 0.6608\n",
      "Epoch 93/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -2283073024.0000 - accuracy: 0.6606\n",
      "Epoch 94/200\n",
      "5946/5946 [==============================] - 6s 998us/step - loss: -2381842688.0000 - accuracy: 0.66084s - loss: -2618105088.0000  - ETA: 1s - l - ETA: 0s - loss: -2382905856.0000 - accuracy: 0.66\n",
      "Epoch 95/200\n",
      "5946/5946 [==============================] - 6s 992us/step - loss: -2484504320.0000 - accuracy: 0.6612\n",
      "Epoch 96/200\n",
      "5946/5946 [==============================] - 6s 977us/step - loss: -2589458688.0000 - accuracy: 0.66062s - l\n",
      "Epoch 97/200\n",
      "5946/5946 [==============================] - 6s 966us/step - loss: -2703106304.0000 - accuracy: 0.6611\n",
      "Epoch 98/200\n",
      "5946/5946 [==============================] - 6s 965us/step - loss: -2811657984.0000 - accuracy: 0.66190s - loss: -2880387072.0000 - accuracy\n",
      "Epoch 99/200\n",
      "5946/5946 [==============================] - 6s 977us/step - loss: -2927102720.0000 - accuracy: 0.6611\n",
      "Epoch 100/200\n",
      "5946/5946 [==============================] - 6s 970us/step - loss: -3044759040.0000 - accuracy: 0.6609\n",
      "Epoch 101/200\n",
      "5946/5946 [==============================] - 6s 976us/step - loss: -3167659008.0000 - accuracy: 0.6608\n",
      "Epoch 102/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -3293469184.0000 - accuracy: 0.6602\n",
      "Epoch 103/200\n",
      "5946/5946 [==============================] - 6s 990us/step - loss: -3423766784.0000 - accuracy: 0.6603\n",
      "Epoch 104/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -3556114432.0000 - accuracy: 0.6618: 1s - ETA: 0s - loss: -36300720\n",
      "Epoch 105/200\n",
      "5946/5946 [==============================] - 6s 991us/step - loss: -3694145536.0000 - accuracy: 0.6608\n",
      "Epoch 106/200\n",
      "5946/5946 [==============================] - ETA: 0s - loss: -3853174528.0000 - accuracy: 0.6600 ETA: 0s - loss: -3818251008.0000 - accuracy - 6s 1ms/step - loss: -3835455232.0000 - accuracy: 0.6601\n",
      "Epoch 107/200\n",
      "5946/5946 [==============================] - 6s 993us/step - loss: -3984887040.0000 - accuracy: 0.6612\n",
      "Epoch 108/200\n",
      "5946/5946 [==============================] - 6s 991us/step - loss: -4133219584.0000 - accuracy: 0.6615\n",
      "Epoch 109/200\n",
      "5946/5946 [==============================] - 6s 971us/step - loss: -4287479040.0000 - accuracy: 0.66060s - loss: -41\n",
      "Epoch 110/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -4445618176.0000 - accuracy: 0.6612\n",
      "Epoch 111/200\n",
      "5946/5946 [==============================] - 6s 985us/step - loss: -4606774272.0000 - accuracy: 0.6611\n",
      "Epoch 112/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -4773126144.0000 - accuracy: 0.6614\n",
      "Epoch 113/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -4943652352.0000 - accuracy: 0.6612\n",
      "Epoch 114/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -5120789504.0000 - accuracy: 0.6611: 0s - loss: -5053008896\n",
      "Epoch 115/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -5300417024.0000 - accuracy: 0.6607\n",
      "Epoch 116/200\n",
      "5946/5946 [==============================] - 6s 999us/step - loss: -5488723968.0000 - accuracy: 0.6612\n",
      "Epoch 117/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -5677399552.0000 - accuracy: 0.6609\n",
      "Epoch 118/200\n",
      "5946/5946 [==============================] - 6s 984us/step - loss: -5873975296.0000 - accuracy: 0.6616\n",
      "Epoch 119/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -6075684352.0000 - accuracy: 0.6610\n",
      "Epoch 120/200\n",
      "5946/5946 [==============================] - 6s 994us/step - loss: -6277212160.0000 - accuracy: 0.6616\n",
      "Epoch 121/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -6488787456.0000 - accuracy: 0.6621\n",
      "Epoch 122/200\n",
      "5946/5946 [==============================] - 6s 999us/step - loss: -6701563904.0000 - accuracy: 0.6607\n",
      "Epoch 123/200\n",
      "5946/5946 [==============================] - 6s 989us/step - loss: -6923859968.0000 - accuracy: 0.6604\n",
      "Epoch 124/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -7150436864.0000 - accuracy: 0.6609\n",
      "Epoch 125/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -7379182080.0000 - accuracy: 0.6611\n",
      "Epoch 126/200\n",
      "5946/5946 [==============================] - 6s 995us/step - loss: -7616320512.0000 - accuracy: 0.6623\n",
      "Epoch 127/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -7857689600.0000 - accuracy: 0.6613\n",
      "Epoch 128/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -8108265984.0000 - accuracy: 0.6615\n",
      "Epoch 129/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -8362051072.0000 - accuracy: 0.6612: \n",
      "Epoch 130/200\n",
      "5946/5946 [==============================] - 6s 992us/step - loss: -8623372288.0000 - accuracy: 0.6617\n",
      "Epoch 131/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -8888787968.0000 - accuracy: 0.6615\n",
      "Epoch 132/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5946/5946 [==============================] - 6s 998us/step - loss: -9158582272.0000 - accuracy: 0.6611\n",
      "Epoch 133/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -9437185024.0000 - accuracy: 0.6613\n",
      "Epoch 134/200\n",
      "5946/5946 [==============================] - 6s 982us/step - loss: -9725131776.0000 - accuracy: 0.6614\n",
      "Epoch 135/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -10014705664.0000 - accuracy: 0.6608A: 1s - loss: -1026173440\n",
      "Epoch 136/200\n",
      "5946/5946 [==============================] - 6s 999us/step - loss: -10312660992.0000 - accuracy: 0.6613s - loss: -8914323456.000\n",
      "Epoch 137/200\n",
      "5946/5946 [==============================] - 6s 985us/step - loss: -10617051136.0000 - accuracy: 0.6617 0s - loss: -10635720704.0000 - accuracy: 0.66\n",
      "Epoch 138/200\n",
      "5946/5946 [==============================] - 6s 999us/step - loss: -10927378432.0000 - accuracy: 0.6613\n",
      "Epoch 139/200\n",
      "5946/5946 [==============================] - 6s 991us/step - loss: -11253977088.0000 - accuracy: 0.6616 0s - loss: -11321926656.0000 - \n",
      "Epoch 140/200\n",
      "5946/5946 [==============================] - 6s 998us/step - loss: -11573722112.0000 - accuracy: 0.6618\n",
      "Epoch 141/200\n",
      "5946/5946 [==============================] - 6s 983us/step - loss: -11903338496.0000 - accuracy: 0.6620\n",
      "Epoch 142/200\n",
      "5946/5946 [==============================] - 6s 968us/step - loss: -12242649088.0000 - accuracy: 0.6617 4s - loss: -13007803392.00 - ETA: 3s - loss: -12434041856.0000 - acc - ETA: 2s - loss: -1268 - ETA: 0s - loss: -12102927360.0000 - ac\n",
      "Epoch 143/200\n",
      "5946/5946 [==============================] - 6s 978us/step - loss: -12587939840.0000 - accuracy: 0.6616\n",
      "Epoch 144/200\n",
      "5946/5946 [==============================] - 6s 997us/step - loss: -12937188352.0000 - accuracy: 0.6616 1s - loss: -13262966784.0000 - accuracy: 0 - ETA: 1s - loss: -1309\n",
      "Epoch 145/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -13298025472.0000 - accuracy: 0.6613A: 1s - loss: -12949127168.0000 - a - ETA: 0s - loss: -13152742400.0000 - accurac - ETA: 0s - loss: -13012731904.0000 - accur\n",
      "Epoch 146/200\n",
      "5946/5946 [==============================] - 6s 976us/step - loss: -13669060608.0000 - accuracy: 0.6609\n",
      "Epoch 147/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -14040290304.0000 - accuracy: 0.6619A: 3s - loss: -13980576768.0000 - accuracy: 0.65 - ETA: 3s - loss: -13916765184.0000 - accuracy:  - ETA: 0s - loss: -14079012864.0000 - accuracy: 0.6\n",
      "Epoch 148/200\n",
      "5946/5946 [==============================] - 6s 961us/step - loss: -14428626944.0000 - accuracy: 0.6618 0s - loss: -14382362624.0000 - accuracy: 0\n",
      "Epoch 149/200\n",
      "5946/5946 [==============================] - 6s 994us/step - loss: -14816192512.0000 - accuracy: 0.6612\n",
      "Epoch 150/200\n",
      "5946/5946 [==============================] - 6s 991us/step - loss: -15217900544.0000 - accuracy: 0.6615\n",
      "Epoch 151/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -15620480000.0000 - accuracy: 0.6617\n",
      "Epoch 152/200\n",
      "5946/5946 [==============================] - 6s 984us/step - loss: -16038770688.0000 - accuracy: 0.6613 - ETA: 0s - loss: -15818205184.0000 - accuracy\n",
      "Epoch 153/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -16459809792.0000 - accuracy: 0.6610\n",
      "Epoch 154/200\n",
      "5946/5946 [==============================] - 6s 999us/step - loss: -16894447616.0000 - accuracy: 0.6617 0s - loss: -17017186304.0000 - accuracy:\n",
      "Epoch 155/200\n",
      "5946/5946 [==============================] - 6s 985us/step - loss: -17340309504.0000 - accuracy: 0.6616\n",
      "Epoch 156/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -17785157632.0000 - accuracy: 0.6618\n",
      "Epoch 157/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -18246352896.0000 - accuracy: 0.6615\n",
      "Epoch 158/200\n",
      "5946/5946 [==============================] - 6s 966us/step - loss: -18717384704.0000 - accuracy: 0.6610 0s - loss: -18361513984.0000 - acc\n",
      "Epoch 159/200\n",
      "5946/5946 [==============================] - 6s 996us/step - loss: -19192991744.0000 - accuracy: 0.6618\n",
      "Epoch 160/200\n",
      "5946/5946 [==============================] - 6s 991us/step - loss: -19667062784.0000 - accuracy: 0.6624\n",
      "Epoch 161/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -20164972544.0000 - accuracy: 0.6614 ETA: 1s - loss: -216616488\n",
      "Epoch 162/200\n",
      "5946/5946 [==============================] - 6s 997us/step - loss: -20652783616.0000 - accuracy: 0.6620 1s - loss: -\n",
      "Epoch 163/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -21167958016.0000 - accuracy: 0.6615A: 2s - loss: -20867770368.0000 - accuracy - ETA: 2s - - ETA: 0s - loss: -21205878784.0000 - accuracy: 0.661\n",
      "Epoch 164/200\n",
      "5946/5946 [==============================] - 6s 997us/step - loss: -21680596992.0000 - accuracy: 0.6614 1s - loss: -2131\n",
      "Epoch 165/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -22208501760.0000 - accuracy: 0.6619A: 3s - lo - ETA: 1s - loss:\n",
      "Epoch 166/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -22742781952.0000 - accuracy: 0.6617\n",
      "Epoch 167/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -23304912896.0000 - accuracy: 0.6613A: 3s - loss: - - ETA: 1s - loss: -2513393\n",
      "Epoch 168/200\n",
      "5946/5946 [==============================] - 6s 994us/step - loss: -23849066496.0000 - accuracy: 0.6621\n",
      "Epoch 169/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -24423032832.0000 - accuracy: 0.6617A: 2s - loss: -24207865856.0000 - accurac - ETA: 2s - loss: -23999090688.0000 - accuracy: - ETA: 1s - loss\n",
      "Epoch 170/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -25003403264.0000 - accuracy: 0.6616A: 5s - loss: -25261871 - ETA: 4s - loss: -21 - ETA: 2s - ETA: 0s - loss: -24788461568.0000 - accuracy: 0.6\n",
      "Epoch 171/200\n",
      "5946/5946 [==============================] - 6s 995us/step - loss: -25584562176.0000 - accuracy: 0.6614\n",
      "Epoch 172/200\n",
      "5946/5946 [==============================] - 6s 992us/step - loss: -26182846464.0000 - accuracy: 0.6621\n",
      "Epoch 173/200\n",
      "5946/5946 [==============================] - 6s 995us/step - loss: -26795831296.0000 - accuracy: 0.6620\n",
      "Epoch 174/200\n",
      "5946/5946 [==============================] - 6s 993us/step - loss: -27422111744.0000 - accuracy: 0.6619\n",
      "Epoch 175/200\n",
      "5946/5946 [==============================] - 6s 975us/step - loss: -28056107008.0000 - accuracy: 0.6619\n",
      "Epoch 176/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -28699172864.0000 - accuracy: 0.6620A: 3s - loss: -27704954880 - ETA: 2s -\n",
      "Epoch 177/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -29362413568.0000 - accuracy: 0.6623\n",
      "Epoch 178/200\n",
      "5946/5946 [==============================] - 6s 998us/step - loss: -30033403904.0000 - accuracy: 0.6620 5s - loss: -37596221 - ETA: 1s - loss: -332052\n",
      "Epoch 179/200\n",
      "5946/5946 [==============================] - 6s 989us/step - loss: -30690570240.0000 - accuracy: 0.6618 0s - loss: -31535724544.0000 - accurac - ETA: 0s - loss: -30861486080.0000 - accuracy: 0.6\n",
      "Epoch 180/200\n",
      "5946/5946 [==============================] - 6s 987us/step - loss: -31385999360.0000 - accuracy: 0.6620\n",
      "Epoch 181/200\n",
      "5946/5946 [==============================] - 6s 992us/step - loss: -32087619584.0000 - accuracy: 0.6615 4s - loss: -32440621056.000 - ETA: 3s - ETA: 1s - loss: -3\n",
      "Epoch 182/200\n",
      "5946/5946 [==============================] - 6s 991us/step - loss: -32800196608.0000 - accuracy: 0.6619\n",
      "Epoch 183/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: -33516216320.0000 - accuracy: 0.6619A: 2s - loss: -32425117696.0000 - ETA: 1s - loss: -322984\n",
      "Epoch 184/200\n",
      "5946/5946 [==============================] - 6s 991us/step - loss: -34249768960.0000 - accuracy: 0.6619\n",
      "Epoch 185/200\n",
      "5946/5946 [==============================] - 6s 990us/step - loss: -34994597888.0000 - accuracy: 0.6619\n",
      "Epoch 186/200\n",
      "5946/5946 [==============================] - 6s 997us/step - loss: -35746971648.0000 - accuracy: 0.6615 0s - loss: -35387850752.0000\n",
      "Epoch 187/200\n",
      "5946/5946 [==============================] - 6s 993us/step - loss: -36521910272.0000 - accuracy: 0.6614\n",
      "Epoch 188/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5946/5946 [==============================] - 6s 987us/step - loss: -37311774720.0000 - accuracy: 0.6618\n",
      "Epoch 189/200\n",
      "5946/5946 [==============================] - 6s 980us/step - loss: -38112612352.0000 - accuracy: 0.6617 0s - loss: -38431465472.0000 - \n",
      "Epoch 190/200\n",
      "5946/5946 [==============================] - 6s 992us/step - loss: -38917435392.0000 - accuracy: 0.6614 4s - l - ETA: 2s - loss: -40035622912 - ETA: 1s - loss: -40537223\n",
      "Epoch 191/200\n",
      "5946/5946 [==============================] - 6s 988us/step - loss: -39733329920.0000 - accuracy: 0.6618\n",
      "Epoch 192/200\n",
      "5946/5946 [==============================] - 6s 999us/step - loss: -40570384384.0000 - accuracy: 0.6616\n",
      "Epoch 193/200\n",
      "5946/5946 [==============================] - 6s 997us/step - loss: -41425838080.0000 - accuracy: 0.6614 2s - loss: -38385659904.0000 - accuracy: 0. - ETA: 2s - l\n",
      "Epoch 194/200\n",
      "5946/5946 [==============================] - 6s 992us/step - loss: -42275827712.0000 - accuracy: 0.6621\n",
      "Epoch 195/200\n",
      "5946/5946 [==============================] - 6s 994us/step - loss: -43146174464.0000 - accuracy: 0.6617\n",
      "Epoch 196/200\n",
      "5946/5946 [==============================] - 6s 996us/step - loss: -44026585088.0000 - accuracy: 0.6624\n",
      "Epoch 197/200\n",
      "5946/5946 [==============================] - 6s 991us/step - loss: -44930764800.0000 - accuracy: 0.6614\n",
      "Epoch 198/200\n",
      "5946/5946 [==============================] - 6s 982us/step - loss: -45834231808.0000 - accuracy: 0.6622  - ETA: 0s - loss: -45307568128.0000 \n",
      "Epoch 199/200\n",
      "5946/5946 [==============================] - 6s 985us/step - loss: -46776115200.0000 - accuracy: 0.6619\n",
      "Epoch 200/200\n",
      "5946/5946 [==============================] - 6s 986us/step - loss: -47722225664.0000 - accuracy: 0.6614\n"
     ]
    }
   ],
   "source": [
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "fit_model = nn.fit(X_train_scaled,y_train, batch_size=32, epochs=200, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "943f04dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1982/1982 - 1s - loss: -3.7684e+10 - accuracy: 0.7973\n",
      "Loss: -37683994624.0, Accuracy: 0.7973036766052246\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65eec9c",
   "metadata": {},
   "source": [
    "## Attempt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e25c31da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_012</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_012  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0           0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1           0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2           0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3           0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4           0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  Veggies  HvyAlcoholConsump  \\\n",
       "0                   0.0           0.0     0.0      1.0                0.0   \n",
       "1                   0.0           1.0     0.0      0.0                0.0   \n",
       "2                   0.0           0.0     1.0      0.0                0.0   \n",
       "3                   0.0           1.0     1.0      1.0                0.0   \n",
       "4                   0.0           1.0     1.0      1.0                0.0   \n",
       "\n",
       "   AnyHealthcare  NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex  \\\n",
       "0            1.0          0.0      5.0      18.0      15.0       1.0  0.0   \n",
       "1            0.0          1.0      3.0       0.0       0.0       0.0  0.0   \n",
       "2            1.0          1.0      5.0      30.0      30.0       1.0  0.0   \n",
       "3            1.0          0.0      2.0       0.0       0.0       0.0  0.0   \n",
       "4            1.0          0.0      2.0       3.0       0.0       0.0  0.0   \n",
       "\n",
       "    Age  \n",
       "0   9.0  \n",
       "1   7.0  \n",
       "2   9.0  \n",
       "3  11.0  \n",
       "4  11.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modded = df.drop(columns=[\"Education\", \"Income\"])\n",
    "df_modded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caf3cb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = df_modded[\"Diabetes_012\"].values\n",
    "X = df_modded.drop(columns=\"Diabetes_012\").values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9011ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25988521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 120)               2400      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                6050      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 30)                1530      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 10,011\n",
      "Trainable params: 10,011\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 120\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 30\n",
    "nn2 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn2.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn2.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn2.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn2.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "190328dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5946/5946 [==============================] - 6s 982us/step - loss: 0.3962 - accuracy: 0.7154\n",
      "Epoch 2/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3927 - accuracy: 0.7219\n",
      "Epoch 3/200\n",
      "5946/5946 [==============================] - 6s 981us/step - loss: 0.3917 - accuracy: 0.7227\n",
      "Epoch 4/200\n",
      "5946/5946 [==============================] - 6s 974us/step - loss: 0.3910 - accuracy: 0.7240\n",
      "Epoch 5/200\n",
      "5946/5946 [==============================] - 6s 969us/step - loss: 0.3905 - accuracy: 0.7214\n",
      "Epoch 6/200\n",
      "5946/5946 [==============================] - 6s 992us/step - loss: 0.3898 - accuracy: 0.7226\n",
      "Epoch 7/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3894 - accuracy: 0.7242\n",
      "Epoch 8/200\n",
      "5946/5946 [==============================] - 6s 944us/step - loss: 0.3888 - accuracy: 0.7245\n",
      "Epoch 9/200\n",
      "5946/5946 [==============================] - 6s 933us/step - loss: 0.3883 - accuracy: 0.7250\n",
      "Epoch 10/200\n",
      "5946/5946 [==============================] - 6s 984us/step - loss: 0.3878 - accuracy: 0.7263\n",
      "Epoch 11/200\n",
      "5946/5946 [==============================] - 6s 978us/step - loss: 0.3873 - accuracy: 0.7296\n",
      "Epoch 12/200\n",
      "5946/5946 [==============================] - 6s 969us/step - loss: 0.3867 - accuracy: 0.72740s - loss: 0.3872 - accuracy\n",
      "Epoch 13/200\n",
      "5946/5946 [==============================] - 6s 925us/step - loss: 0.3861 - accuracy: 0.7277\n",
      "Epoch 14/200\n",
      "5946/5946 [==============================] - 6s 938us/step - loss: 0.3856 - accuracy: 0.72870s - loss: 0.3864 -  - ETA: 0s - loss: 0\n",
      "Epoch 15/200\n",
      "5946/5946 [==============================] - 6s 975us/step - loss: 0.3847 - accuracy: 0.7294\n",
      "Epoch 16/200\n",
      "5946/5946 [==============================] - 6s 972us/step - loss: 0.3842 - accuracy: 0.7309\n",
      "Epoch 17/200\n",
      "5946/5946 [==============================] - 6s 978us/step - loss: 0.3837 - accuracy: 0.72921s - loss: 0.3836 - ac\n",
      "Epoch 18/200\n",
      "5946/5946 [==============================] - 6s 981us/step - loss: 0.3831 - accuracy: 0.7297\n",
      "Epoch 19/200\n",
      "5946/5946 [==============================] - 6s 972us/step - loss: 0.3823 - accuracy: 0.7316\n",
      "Epoch 20/200\n",
      "5946/5946 [==============================] - 6s 969us/step - loss: 0.3819 - accuracy: 0.7325\n",
      "Epoch 21/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3809 - accuracy: 0.7328\n",
      "Epoch 22/200\n",
      "5946/5946 [==============================] - 6s 993us/step - loss: 0.3802 - accuracy: 0.73400s - los\n",
      "Epoch 23/200\n",
      "5946/5946 [==============================] - 6s 997us/step - loss: 0.3801 - accuracy: 0.7323\n",
      "Epoch 24/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3794 - accuracy: 0.7332\n",
      "Epoch 25/200\n",
      "5946/5946 [==============================] - 6s 968us/step - loss: 0.3790 - accuracy: 0.7348\n",
      "Epoch 26/200\n",
      "5946/5946 [==============================] - 6s 952us/step - loss: 0.3785 - accuracy: 0.7346\n",
      "Epoch 27/200\n",
      "5946/5946 [==============================] - 6s 954us/step - loss: 0.3779 - accuracy: 0.7360\n",
      "Epoch 28/200\n",
      "5946/5946 [==============================] - 6s 942us/step - loss: 0.3776 - accuracy: 0.7369\n",
      "Epoch 29/200\n",
      "5946/5946 [==============================] - 6s 958us/step - loss: 0.3766 - accuracy: 0.73601s - loss: 0.376 - ETA: 0s - loss: 0.376 - ETA: 0s - loss: 0.3767 - accuracy: 0.\n",
      "Epoch 30/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3763 - accuracy: 0.7379: 0s - loss: 0.3764 - \n",
      "Epoch 31/200\n",
      "5946/5946 [==============================] - 6s 998us/step - loss: 0.3754 - accuracy: 0.7380\n",
      "Epoch 32/200\n",
      "5946/5946 [==============================] - 6s 966us/step - loss: 0.3750 - accuracy: 0.7371\n",
      "Epoch 33/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3749 - accuracy: 0.7394\n",
      "Epoch 34/200\n",
      "5946/5946 [==============================] - 6s 974us/step - loss: 0.3743 - accuracy: 0.73741s - loss: 0.3741 \n",
      "Epoch 35/200\n",
      "5946/5946 [==============================] - 6s 979us/step - loss: 0.3734 - accuracy: 0.7407\n",
      "Epoch 36/200\n",
      "5946/5946 [==============================] - 6s 974us/step - loss: 0.3731 - accuracy: 0.7412\n",
      "Epoch 37/200\n",
      "5946/5946 [==============================] - 6s 967us/step - loss: 0.3726 - accuracy: 0.74080s - l\n",
      "Epoch 38/200\n",
      "5946/5946 [==============================] - 6s 973us/step - loss: 0.3721 - accuracy: 0.74050s - loss: 0.3721 - accuracy: 0.\n",
      "Epoch 39/200\n",
      "5946/5946 [==============================] - 6s 965us/step - loss: 0.3720 - accuracy: 0.7416\n",
      "Epoch 40/200\n",
      "5946/5946 [==============================] - 6s 966us/step - loss: 0.3716 - accuracy: 0.7417\n",
      "Epoch 41/200\n",
      "5946/5946 [==============================] - 6s 985us/step - loss: 0.3710 - accuracy: 0.7434\n",
      "Epoch 42/200\n",
      "5946/5946 [==============================] - 6s 971us/step - loss: 0.3704 - accuracy: 0.7419\n",
      "Epoch 43/200\n",
      "5946/5946 [==============================] - 6s 963us/step - loss: 0.3702 - accuracy: 0.7435\n",
      "Epoch 44/200\n",
      "5946/5946 [==============================] - 6s 953us/step - loss: 0.3699 - accuracy: 0.74380s\n",
      "Epoch 45/200\n",
      "5946/5946 [==============================] - 6s 930us/step - loss: 0.3695 - accuracy: 0.7438\n",
      "Epoch 46/200\n",
      "5946/5946 [==============================] - 6s 936us/step - loss: 0.3692 - accuracy: 0.7441\n",
      "Epoch 47/200\n",
      "5946/5946 [==============================] - 6s 967us/step - loss: 0.3691 - accuracy: 0.7439\n",
      "Epoch 48/200\n",
      "5946/5946 [==============================] - 6s 926us/step - loss: 0.3686 - accuracy: 0.7447\n",
      "Epoch 49/200\n",
      "5946/5946 [==============================] - 6s 957us/step - loss: 0.3679 - accuracy: 0.7460\n",
      "Epoch 50/200\n",
      "5946/5946 [==============================] - 6s 969us/step - loss: 0.3679 - accuracy: 0.7448\n",
      "Epoch 51/200\n",
      "5946/5946 [==============================] - 6s 971us/step - loss: 0.3675 - accuracy: 0.7459\n",
      "Epoch 52/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3673 - accuracy: 0.7453: 0s - loss: 0.3671 - accuracy: 0.\n",
      "Epoch 53/200\n",
      "5946/5946 [==============================] - 6s 970us/step - loss: 0.3670 - accuracy: 0.7464\n",
      "Epoch 54/200\n",
      "5946/5946 [==============================] - 6s 967us/step - loss: 0.3667 - accuracy: 0.7477\n",
      "Epoch 55/200\n",
      "5946/5946 [==============================] - 6s 970us/step - loss: 0.3665 - accuracy: 0.74632s - los - ETA: 1s - loss: 0.3667 - accuracy: 0.74 - ETA: 1s - l - ETA: 0s - l\n",
      "Epoch 56/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3663 - accuracy: 0.7480\n",
      "Epoch 57/200\n",
      "5946/5946 [==============================] - 6s 968us/step - loss: 0.3651 - accuracy: 0.74680s - loss: 0.3660 - accu - ETA: 0s - loss: 0.3656 - accura\n",
      "Epoch 58/200\n",
      "5946/5946 [==============================] - 6s 946us/step - loss: 0.3654 - accuracy: 0.7482\n",
      "Epoch 59/200\n",
      "5946/5946 [==============================] - 6s 938us/step - loss: 0.3650 - accuracy: 0.7485\n",
      "Epoch 60/200\n",
      "5946/5946 [==============================] - 6s 984us/step - loss: 0.3651 - accuracy: 0.7495\n",
      "Epoch 61/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3646 - accuracy: 0.7485\n",
      "Epoch 62/200\n",
      "5946/5946 [==============================] - 6s 982us/step - loss: 0.3643 - accuracy: 0.74970s - loss: 0.3644 - accuracy - ETA: 0s - loss: 0.3645 - accuracy: \n",
      "Epoch 63/200\n",
      "5946/5946 [==============================] - 6s 971us/step - loss: 0.3639 - accuracy: 0.7481\n",
      "Epoch 64/200\n",
      "5946/5946 [==============================] - 6s 980us/step - loss: 0.3637 - accuracy: 0.7489\n",
      "Epoch 65/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3637 - accuracy: 0.7478\n",
      "Epoch 66/200\n",
      "5946/5946 [==============================] - 6s 961us/step - loss: 0.3632 - accuracy: 0.7500\n",
      "Epoch 67/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3635 - accuracy: 0.7494\n",
      "Epoch 68/200\n",
      "5946/5946 [==============================] - 6s 987us/step - loss: 0.3632 - accuracy: 0.7500\n",
      "Epoch 69/200\n",
      "5946/5946 [==============================] - 6s 980us/step - loss: 0.3630 - accuracy: 0.75040s - loss: 0.3626 \n",
      "Epoch 70/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3624 - accuracy: 0.7510: 0s - loss: 0.361\n",
      "Epoch 71/200\n",
      "5946/5946 [==============================] - 6s 989us/step - loss: 0.3616 - accuracy: 0.7510\n",
      "Epoch 72/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3620 - accuracy: 0.7511\n",
      "Epoch 73/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5946/5946 [==============================] - 6s 966us/step - loss: 0.3620 - accuracy: 0.7503\n",
      "Epoch 74/200\n",
      "5946/5946 [==============================] - 6s 982us/step - loss: 0.3613 - accuracy: 0.7517\n",
      "Epoch 75/200\n",
      "5946/5946 [==============================] - 6s 970us/step - loss: 0.3614 - accuracy: 0.7508\n",
      "Epoch 76/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3617 - accuracy: 0.7513\n",
      "Epoch 77/200\n",
      "5946/5946 [==============================] - 6s 973us/step - loss: 0.3607 - accuracy: 0.7526\n",
      "Epoch 78/200\n",
      "5946/5946 [==============================] - 6s 988us/step - loss: 0.3612 - accuracy: 0.7514\n",
      "Epoch 79/200\n",
      "5946/5946 [==============================] - 6s 977us/step - loss: 0.3603 - accuracy: 0.7516\n",
      "Epoch 80/200\n",
      "5946/5946 [==============================] - 6s 978us/step - loss: 0.3609 - accuracy: 0.7508\n",
      "Epoch 81/200\n",
      "5946/5946 [==============================] - 6s 958us/step - loss: 0.3608 - accuracy: 0.75170s - loss: 0.3\n",
      "Epoch 82/200\n",
      "5946/5946 [==============================] - 6s 956us/step - loss: 0.3603 - accuracy: 0.7519\n",
      "Epoch 83/200\n",
      "5946/5946 [==============================] - 6s 933us/step - loss: 0.3603 - accuracy: 0.7512\n",
      "Epoch 84/200\n",
      "5946/5946 [==============================] - 5s 906us/step - loss: 0.3598 - accuracy: 0.7536\n",
      "Epoch 85/200\n",
      "5946/5946 [==============================] - 6s 947us/step - loss: 0.3595 - accuracy: 0.75221s - loss: 0.3571 - \n",
      "Epoch 86/200\n",
      "5946/5946 [==============================] - 6s 990us/step - loss: 0.3600 - accuracy: 0.7522\n",
      "Epoch 87/200\n",
      "5946/5946 [==============================] - 6s 961us/step - loss: 0.3604 - accuracy: 0.7519\n",
      "Epoch 88/200\n",
      "5946/5946 [==============================] - 5s 922us/step - loss: 0.3592 - accuracy: 0.7531\n",
      "Epoch 89/200\n",
      "5946/5946 [==============================] - 6s 972us/step - loss: 0.3592 - accuracy: 0.75240s - loss: 0.3596 - accuracy: \n",
      "Epoch 90/200\n",
      "5946/5946 [==============================] - 6s 951us/step - loss: 0.3593 - accuracy: 0.7523\n",
      "Epoch 91/200\n",
      "5946/5946 [==============================] - 5s 919us/step - loss: 0.3584 - accuracy: 0.7533\n",
      "Epoch 92/200\n",
      "5946/5946 [==============================] - 5s 923us/step - loss: 0.3585 - accuracy: 0.7522\n",
      "Epoch 93/200\n",
      "5946/5946 [==============================] - 5s 921us/step - loss: 0.3582 - accuracy: 0.7535\n",
      "Epoch 94/200\n",
      "5946/5946 [==============================] - 6s 990us/step - loss: 0.3582 - accuracy: 0.7534\n",
      "Epoch 95/200\n",
      "5946/5946 [==============================] - 5s 924us/step - loss: 0.3584 - accuracy: 0.7532\n",
      "Epoch 96/200\n",
      "5946/5946 [==============================] - 6s 985us/step - loss: 0.3578 - accuracy: 0.7529\n",
      "Epoch 97/200\n",
      "5946/5946 [==============================] - 6s 966us/step - loss: 0.3573 - accuracy: 0.7537\n",
      "Epoch 98/200\n",
      "5946/5946 [==============================] - 6s 973us/step - loss: 0.3575 - accuracy: 0.7540\n",
      "Epoch 99/200\n",
      "5946/5946 [==============================] - 6s 996us/step - loss: 0.3573 - accuracy: 0.7534\n",
      "Epoch 100/200\n",
      "5946/5946 [==============================] - 6s 948us/step - loss: 0.3577 - accuracy: 0.7533\n"
     ]
    }
   ],
   "source": [
    "nn2.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "fit_model = nn2.fit(X_train_scaled, y_train, batch_size=32, epochs=200, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a0aae56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1982/1982 - 1s - loss: 0.4119 - accuracy: 0.7346\n",
      "Loss: 0.41191360354423523, Accuracy: 0.734626293182373\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn2.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ccb768",
   "metadata": {},
   "source": [
    "## Attempt 3\n",
    "### Similar to Attempt 1 but Batch size is larger and different loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e0c5f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = df[\"Diabetes_012\"].values\n",
    "X = df.drop(columns=\"Diabetes_012\").values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c1554ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 120)               2640      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 50)                6050      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 30)                1530      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 10,251\n",
      "Trainable params: 10,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 120\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 30\n",
    "nn3 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn3.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn3.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn3.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn3.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a57affef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5946/5946 [==============================] - 6s 986us/step - loss: 0.3958 - accuracy: 0.7185\n",
      "Epoch 2/200\n",
      "5946/5946 [==============================] - 6s 944us/step - loss: 0.3918 - accuracy: 0.7240\n",
      "Epoch 3/200\n",
      "5946/5946 [==============================] - 6s 990us/step - loss: 0.3909 - accuracy: 0.7260\n",
      "Epoch 4/200\n",
      "5946/5946 [==============================] - 6s 979us/step - loss: 0.3901 - accuracy: 0.7256\n",
      "Epoch 5/200\n",
      "5946/5946 [==============================] - 6s 965us/step - loss: 0.3893 - accuracy: 0.72631s - loss: 0.389\n",
      "Epoch 6/200\n",
      "5946/5946 [==============================] - 6s 982us/step - loss: 0.3887 - accuracy: 0.7265\n",
      "Epoch 7/200\n",
      "5946/5946 [==============================] - 6s 965us/step - loss: 0.3881 - accuracy: 0.7292\n",
      "Epoch 8/200\n",
      "5946/5946 [==============================] - 6s 975us/step - loss: 0.3874 - accuracy: 0.72581s - loss: 0.3874 - accuracy:  - ETA: 1s - loss: 0 - ETA: 0s - loss: 0.3870 - accuracy - ETA: 0s - loss: 0.3870 - accu\n",
      "Epoch 9/200\n",
      "5946/5946 [==============================] - 6s 977us/step - loss: 0.3867 - accuracy: 0.72775s\n",
      "Epoch 10/200\n",
      "5946/5946 [==============================] - 6s 980us/step - loss: 0.3861 - accuracy: 0.7273\n",
      "Epoch 11/200\n",
      "5946/5946 [==============================] - 6s 981us/step - loss: 0.3851 - accuracy: 0.7281\n",
      "Epoch 12/200\n",
      "5946/5946 [==============================] - 6s 937us/step - loss: 0.3842 - accuracy: 0.7312\n",
      "Epoch 13/200\n",
      "5946/5946 [==============================] - 6s 964us/step - loss: 0.3836 - accuracy: 0.73080s - loss: 0.382\n",
      "Epoch 14/200\n",
      "5946/5946 [==============================] - 6s 973us/step - loss: 0.3830 - accuracy: 0.7312\n",
      "Epoch 15/200\n",
      "5946/5946 [==============================] - 6s 982us/step - loss: 0.3817 - accuracy: 0.7341\n",
      "Epoch 16/200\n",
      "5946/5946 [==============================] - 6s 994us/step - loss: 0.3814 - accuracy: 0.7348\n",
      "Epoch 17/200\n",
      "5946/5946 [==============================] - 6s 971us/step - loss: 0.3802 - accuracy: 0.7358\n",
      "Epoch 18/200\n",
      "5946/5946 [==============================] - 6s 976us/step - loss: 0.3796 - accuracy: 0.7369\n",
      "Epoch 19/200\n",
      "5946/5946 [==============================] - 6s 983us/step - loss: 0.3785 - accuracy: 0.7390\n",
      "Epoch 20/200\n",
      "5946/5946 [==============================] - 6s 976us/step - loss: 0.3773 - accuracy: 0.7407\n",
      "Epoch 21/200\n",
      "5946/5946 [==============================] - 6s 964us/step - loss: 0.3767 - accuracy: 0.7444\n",
      "Epoch 22/200\n",
      "5946/5946 [==============================] - 6s 981us/step - loss: 0.3760 - accuracy: 0.7436\n",
      "Epoch 23/200\n",
      "5946/5946 [==============================] - 6s 987us/step - loss: 0.3748 - accuracy: 0.7445\n",
      "Epoch 24/200\n",
      "5946/5946 [==============================] - 6s 947us/step - loss: 0.3743 - accuracy: 0.7472\n",
      "Epoch 25/200\n",
      "5946/5946 [==============================] - 6s 962us/step - loss: 0.3734 - accuracy: 0.7486\n",
      "Epoch 26/200\n",
      "5946/5946 [==============================] - 6s 950us/step - loss: 0.3724 - accuracy: 0.7499\n",
      "Epoch 27/200\n",
      "5946/5946 [==============================] - 6s 957us/step - loss: 0.3718 - accuracy: 0.7513\n",
      "Epoch 28/200\n",
      "5946/5946 [==============================] - 6s 962us/step - loss: 0.3715 - accuracy: 0.7514\n",
      "Epoch 29/200\n",
      "5946/5946 [==============================] - 6s 957us/step - loss: 0.3708 - accuracy: 0.75130s - loss: 0.370\n",
      "Epoch 30/200\n",
      "5946/5946 [==============================] - 6s 963us/step - loss: 0.3702 - accuracy: 0.7518\n",
      "Epoch 31/200\n",
      "5946/5946 [==============================] - 6s 959us/step - loss: 0.3694 - accuracy: 0.75440s - loss: 0.3692 - \n",
      "Epoch 32/200\n",
      "5946/5946 [==============================] - 6s 961us/step - loss: 0.3689 - accuracy: 0.7529\n",
      "Epoch 33/200\n",
      "5946/5946 [==============================] - 6s 958us/step - loss: 0.3678 - accuracy: 0.7554\n",
      "Epoch 34/200\n",
      "5946/5946 [==============================] - 6s 951us/step - loss: 0.3675 - accuracy: 0.7564\n",
      "Epoch 35/200\n",
      "5946/5946 [==============================] - 6s 968us/step - loss: 0.3668 - accuracy: 0.7560\n",
      "Epoch 36/200\n",
      "5946/5946 [==============================] - 6s 975us/step - loss: 0.3660 - accuracy: 0.75790s - l\n",
      "Epoch 37/200\n",
      "5946/5946 [==============================] - 6s 975us/step - loss: 0.3657 - accuracy: 0.7594\n",
      "Epoch 38/200\n",
      "5946/5946 [==============================] - 6s 967us/step - loss: 0.3649 - accuracy: 0.7591\n",
      "Epoch 39/200\n",
      "5946/5946 [==============================] - ETA: 0s - loss: 0.3644 - accuracy: 0.76 - 6s 967us/step - loss: 0.3644 - accuracy: 0.7603\n",
      "Epoch 40/200\n",
      "5946/5946 [==============================] - 6s 960us/step - loss: 0.3648 - accuracy: 0.7581\n",
      "Epoch 41/200\n",
      "5946/5946 [==============================] - 6s 956us/step - loss: 0.3639 - accuracy: 0.7607\n",
      "Epoch 42/200\n",
      "5946/5946 [==============================] - 6s 954us/step - loss: 0.3633 - accuracy: 0.7599\n",
      "Epoch 43/200\n",
      "5946/5946 [==============================] - 6s 966us/step - loss: 0.3627 - accuracy: 0.7602\n",
      "Epoch 44/200\n",
      "5946/5946 [==============================] - 6s 946us/step - loss: 0.3625 - accuracy: 0.7615\n",
      "Epoch 45/200\n",
      "5946/5946 [==============================] - 6s 951us/step - loss: 0.3619 - accuracy: 0.7609\n",
      "Epoch 46/200\n",
      "5946/5946 [==============================] - 6s 956us/step - loss: 0.3612 - accuracy: 0.7631\n",
      "Epoch 47/200\n",
      "5946/5946 [==============================] - 6s 958us/step - loss: 0.3607 - accuracy: 0.7619\n",
      "Epoch 48/200\n",
      "5946/5946 [==============================] - ETA: 0s - loss: 0.3605 - accuracy: 0.76 - 6s 959us/step - loss: 0.3608 - accuracy: 0.7603\n",
      "Epoch 49/200\n",
      "5946/5946 [==============================] - 6s 954us/step - loss: 0.3600 - accuracy: 0.76080s - l\n",
      "Epoch 50/200\n",
      "5946/5946 [==============================] - 6s 957us/step - loss: 0.3595 - accuracy: 0.7612\n",
      "Epoch 51/200\n",
      "5946/5946 [==============================] - 6s 959us/step - loss: 0.3597 - accuracy: 0.7615\n",
      "Epoch 52/200\n",
      "5946/5946 [==============================] - 6s 967us/step - loss: 0.3586 - accuracy: 0.7617\n",
      "Epoch 53/200\n",
      "5946/5946 [==============================] - 6s 955us/step - loss: 0.3585 - accuracy: 0.7616\n",
      "Epoch 54/200\n",
      "5946/5946 [==============================] - 6s 952us/step - loss: 0.3581 - accuracy: 0.7615\n",
      "Epoch 55/200\n",
      "5946/5946 [==============================] - 6s 960us/step - loss: 0.3579 - accuracy: 0.76150s - loss: 0.3573 - ac\n",
      "Epoch 56/200\n",
      "5946/5946 [==============================] - 6s 959us/step - loss: 0.3576 - accuracy: 0.7619\n",
      "Epoch 57/200\n",
      "5946/5946 [==============================] - 6s 962us/step - loss: 0.3577 - accuracy: 0.7621\n",
      "Epoch 58/200\n",
      "5946/5946 [==============================] - 6s 975us/step - loss: 0.3571 - accuracy: 0.7624\n",
      "Epoch 59/200\n",
      "5946/5946 [==============================] - 6s 960us/step - loss: 0.3572 - accuracy: 0.76180s - loss: 0.3562 - accuracy\n",
      "Epoch 60/200\n",
      "5946/5946 [==============================] - 6s 963us/step - loss: 0.3564 - accuracy: 0.76260s - loss: 0.3558 - accura\n",
      "Epoch 61/200\n",
      "5946/5946 [==============================] - 6s 947us/step - loss: 0.3564 - accuracy: 0.7626\n",
      "Epoch 62/200\n",
      "5946/5946 [==============================] - 5s 923us/step - loss: 0.3558 - accuracy: 0.76250s - loss: 0.3\n",
      "Epoch 63/200\n",
      "5946/5946 [==============================] - 5s 916us/step - loss: 0.3550 - accuracy: 0.7627\n",
      "Epoch 64/200\n",
      "5946/5946 [==============================] - 5s 916us/step - loss: 0.3553 - accuracy: 0.7630\n",
      "Epoch 65/200\n",
      "5946/5946 [==============================] - 5s 905us/step - loss: 0.3554 - accuracy: 0.7632\n",
      "Epoch 66/200\n",
      "5946/5946 [==============================] - 5s 913us/step - loss: 0.3546 - accuracy: 0.7641\n",
      "Epoch 67/200\n",
      "5946/5946 [==============================] - 5s 911us/step - loss: 0.3540 - accuracy: 0.7644\n",
      "Epoch 68/200\n",
      "5946/5946 [==============================] - 5s 911us/step - loss: 0.3541 - accuracy: 0.7643\n",
      "Epoch 69/200\n",
      "5946/5946 [==============================] - 5s 912us/step - loss: 0.3543 - accuracy: 0.7640\n",
      "Epoch 70/200\n",
      "5946/5946 [==============================] - 6s 950us/step - loss: 0.3540 - accuracy: 0.76380s - loss: 0\n",
      "Epoch 71/200\n",
      "5946/5946 [==============================] - 6s 970us/step - loss: 0.3536 - accuracy: 0.7652\n",
      "Epoch 72/200\n",
      "5946/5946 [==============================] - 6s 955us/step - loss: 0.3540 - accuracy: 0.7639\n",
      "Epoch 73/200\n",
      "5946/5946 [==============================] - 6s 968us/step - loss: 0.3538 - accuracy: 0.7643\n",
      "Epoch 74/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5946/5946 [==============================] - 6s 937us/step - loss: 0.3528 - accuracy: 0.76490s - loss: 0.352\n",
      "Epoch 75/200\n",
      "5946/5946 [==============================] - 6s 944us/step - loss: 0.3531 - accuracy: 0.7644\n",
      "Epoch 76/200\n",
      "5946/5946 [==============================] - 6s 945us/step - loss: 0.3527 - accuracy: 0.7651\n",
      "Epoch 77/200\n",
      "5946/5946 [==============================] - 6s 939us/step - loss: 0.3519 - accuracy: 0.7658\n",
      "Epoch 78/200\n",
      "5946/5946 [==============================] - 6s 949us/step - loss: 0.3518 - accuracy: 0.7647\n",
      "Epoch 79/200\n",
      "5946/5946 [==============================] - 6s 955us/step - loss: 0.3518 - accuracy: 0.7656\n",
      "Epoch 80/200\n",
      "5946/5946 [==============================] - 6s 958us/step - loss: 0.3512 - accuracy: 0.7654\n",
      "Epoch 81/200\n",
      "5946/5946 [==============================] - 6s 947us/step - loss: 0.3516 - accuracy: 0.76490s - loss: 0.3516 \n",
      "Epoch 82/200\n",
      "5946/5946 [==============================] - 6s 966us/step - loss: 0.3508 - accuracy: 0.7651\n",
      "Epoch 83/200\n",
      "5946/5946 [==============================] - 6s 964us/step - loss: 0.3508 - accuracy: 0.7659\n",
      "Epoch 84/200\n",
      "5946/5946 [==============================] - 6s 958us/step - loss: 0.3507 - accuracy: 0.7652\n",
      "Epoch 85/200\n",
      "5946/5946 [==============================] - 6s 952us/step - loss: 0.3507 - accuracy: 0.7659\n",
      "Epoch 86/200\n",
      "5946/5946 [==============================] - 6s 949us/step - loss: 0.3510 - accuracy: 0.7656\n",
      "Epoch 87/200\n",
      "5946/5946 [==============================] - 6s 955us/step - loss: 0.3505 - accuracy: 0.7648\n",
      "Epoch 88/200\n",
      "5946/5946 [==============================] - 6s 955us/step - loss: 0.3503 - accuracy: 0.7659\n",
      "Epoch 89/200\n",
      "5946/5946 [==============================] - 6s 959us/step - loss: 0.3496 - accuracy: 0.76650s - loss: 0.3500 - \n",
      "Epoch 90/200\n",
      "5946/5946 [==============================] - 6s 951us/step - loss: 0.3492 - accuracy: 0.76730s - loss: 0.3493 - accuracy: \n",
      "Epoch 91/200\n",
      "5946/5946 [==============================] - 6s 953us/step - loss: 0.3494 - accuracy: 0.7658\n",
      "Epoch 92/200\n",
      "5946/5946 [==============================] - 6s 965us/step - loss: 0.3488 - accuracy: 0.7668\n",
      "Epoch 93/200\n",
      "5946/5946 [==============================] - 6s 950us/step - loss: 0.3482 - accuracy: 0.76720s - loss: 0.3481 - accuracy\n",
      "Epoch 94/200\n",
      "5946/5946 [==============================] - 6s 958us/step - loss: 0.3488 - accuracy: 0.7663\n",
      "Epoch 95/200\n",
      "5946/5946 [==============================] - 6s 953us/step - loss: 0.3491 - accuracy: 0.7664\n",
      "Epoch 96/200\n",
      "5946/5946 [==============================] - 6s 956us/step - loss: 0.3487 - accuracy: 0.7666\n"
     ]
    }
   ],
   "source": [
    "nn3.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "fit_model = nn3.fit(X_train_scaled,y_train, batch_size=32, epochs=200, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf3a3266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1982/1982 - 1s - loss: 0.4151 - accuracy: 0.7377\n",
      "Loss: 0.41514310240745544, Accuracy: 0.7377483248710632\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn3.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729028e0",
   "metadata": {},
   "source": [
    "## Attempt 4\n",
    "### Kept columns above 0.05 of importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe16f3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = df[\"Diabetes_012\"].values\n",
    "X = df.drop(columns=['Diabetes_012', 'BMI', 'Age', 'Income', 'PhysHlth', 'Education', 'GenHlth', 'MentHlth']).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56b7c0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 120)               1800      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 50)                6050      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 30)                1530      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 9,411\n",
      "Trainable params: 9,411\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 120\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 30\n",
    "nn4 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn4.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn4.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef60173a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2973/2973 [==============================] - 3s 984us/step - loss: 0.4246 - accuracy: 0.7134\n",
      "Epoch 2/100\n",
      "2973/2973 [==============================] - 3s 952us/step - loss: 0.4223 - accuracy: 0.7181\n",
      "Epoch 3/100\n",
      "2973/2973 [==============================] - 3s 941us/step - loss: 0.4219 - accuracy: 0.71690s - loss: 0.4219 - accuracy: 0.71\n",
      "Epoch 4/100\n",
      "2973/2973 [==============================] - 3s 951us/step - loss: 0.4216 - accuracy: 0.7188\n",
      "Epoch 5/100\n",
      "2973/2973 [==============================] - 3s 960us/step - loss: 0.4213 - accuracy: 0.7182\n",
      "Epoch 6/100\n",
      "2973/2973 [==============================] - 3s 937us/step - loss: 0.4212 - accuracy: 0.7153\n",
      "Epoch 7/100\n",
      "2973/2973 [==============================] - 3s 959us/step - loss: 0.4211 - accuracy: 0.7185\n",
      "Epoch 8/100\n",
      "2973/2973 [==============================] - 3s 915us/step - loss: 0.4210 - accuracy: 0.7183\n",
      "Epoch 9/100\n",
      "2973/2973 [==============================] - 3s 906us/step - loss: 0.4209 - accuracy: 0.7177\n",
      "Epoch 10/100\n",
      "2973/2973 [==============================] - 3s 949us/step - loss: 0.4208 - accuracy: 0.7174\n",
      "Epoch 11/100\n",
      "2973/2973 [==============================] - 3s 970us/step - loss: 0.4207 - accuracy: 0.7178\n",
      "Epoch 12/100\n",
      "2973/2973 [==============================] - 3s 967us/step - loss: 0.4204 - accuracy: 0.7179\n",
      "Epoch 13/100\n",
      "2973/2973 [==============================] - 3s 977us/step - loss: 0.4204 - accuracy: 0.7179\n",
      "Epoch 14/100\n",
      "2973/2973 [==============================] - 3s 985us/step - loss: 0.4203 - accuracy: 0.7188\n",
      "Epoch 15/100\n",
      "2973/2973 [==============================] - 3s 984us/step - loss: 0.4203 - accuracy: 0.71750s - loss: 0.4199 - ac\n",
      "Epoch 16/100\n",
      "2973/2973 [==============================] - 3s 972us/step - loss: 0.4200 - accuracy: 0.7198\n",
      "Epoch 17/100\n",
      "2973/2973 [==============================] - 3s 981us/step - loss: 0.4199 - accuracy: 0.71860s\n",
      "Epoch 18/100\n",
      "2973/2973 [==============================] - 3s 984us/step - loss: 0.4199 - accuracy: 0.7226\n",
      "Epoch 19/100\n",
      "2973/2973 [==============================] - 3s 984us/step - loss: 0.4197 - accuracy: 0.7171\n",
      "Epoch 20/100\n",
      "2973/2973 [==============================] - 3s 976us/step - loss: 0.4196 - accuracy: 0.7202\n",
      "Epoch 21/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4195 - accuracy: 0.7224\n",
      "Epoch 22/100\n",
      "2973/2973 [==============================] - 3s 925us/step - loss: 0.4194 - accuracy: 0.7211\n",
      "Epoch 23/100\n",
      "2973/2973 [==============================] - 3s 1000us/step - loss: 0.4193 - accuracy: 0.7224\n",
      "Epoch 24/100\n",
      "2973/2973 [==============================] - 3s 993us/step - loss: 0.4191 - accuracy: 0.72160s - loss: 0.4191 - accuracy: \n",
      "Epoch 25/100\n",
      "2973/2973 [==============================] - 3s 978us/step - loss: 0.4191 - accuracy: 0.7223\n",
      "Epoch 26/100\n",
      "2973/2973 [==============================] - 3s 987us/step - loss: 0.4189 - accuracy: 0.7212\n",
      "Epoch 27/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4187 - accuracy: 0.7213\n",
      "Epoch 28/100\n",
      "2973/2973 [==============================] - 3s 957us/step - loss: 0.4187 - accuracy: 0.7240\n",
      "Epoch 29/100\n",
      "2973/2973 [==============================] - 3s 978us/step - loss: 0.4186 - accuracy: 0.7229\n",
      "Epoch 30/100\n",
      "2973/2973 [==============================] - 3s 992us/step - loss: 0.4186 - accuracy: 0.7223\n",
      "Epoch 31/100\n",
      "2973/2973 [==============================] - 3s 988us/step - loss: 0.4184 - accuracy: 0.7227\n",
      "Epoch 32/100\n",
      "2973/2973 [==============================] - 3s 953us/step - loss: 0.4183 - accuracy: 0.7229\n",
      "Epoch 33/100\n",
      "2973/2973 [==============================] - 3s 990us/step - loss: 0.4182 - accuracy: 0.7257\n",
      "Epoch 34/100\n",
      "2973/2973 [==============================] - 3s 997us/step - loss: 0.4181 - accuracy: 0.7188\n",
      "Epoch 35/100\n",
      "2973/2973 [==============================] - 3s 994us/step - loss: 0.4181 - accuracy: 0.72202s - loss: 0.417 - ETA: 1s - los\n",
      "Epoch 36/100\n",
      "2973/2973 [==============================] - 3s 998us/step - loss: 0.4179 - accuracy: 0.7218\n",
      "Epoch 37/100\n",
      "2973/2973 [==============================] - 3s 989us/step - loss: 0.4179 - accuracy: 0.7216\n",
      "Epoch 38/100\n",
      "2973/2973 [==============================] - 3s 976us/step - loss: 0.4177 - accuracy: 0.7184\n",
      "Epoch 39/100\n",
      "2973/2973 [==============================] - 3s 991us/step - loss: 0.4177 - accuracy: 0.7184\n",
      "Epoch 40/100\n",
      "2973/2973 [==============================] - 3s 963us/step - loss: 0.4175 - accuracy: 0.7211\n",
      "Epoch 41/100\n",
      "2973/2973 [==============================] - 3s 982us/step - loss: 0.4175 - accuracy: 0.7183\n",
      "Epoch 42/100\n",
      "2973/2973 [==============================] - 3s 991us/step - loss: 0.4174 - accuracy: 0.71931s - loss: 0.4 - ETA: 0s - loss:\n",
      "Epoch 43/100\n",
      "2973/2973 [==============================] - 3s 958us/step - loss: 0.4172 - accuracy: 0.7204\n",
      "Epoch 44/100\n",
      "2973/2973 [==============================] - 3s 949us/step - loss: 0.4172 - accuracy: 0.7213\n",
      "Epoch 45/100\n",
      "2973/2973 [==============================] - 3s 976us/step - loss: 0.4171 - accuracy: 0.7166\n",
      "Epoch 46/100\n",
      "2973/2973 [==============================] - 3s 958us/step - loss: 0.4169 - accuracy: 0.7207\n",
      "Epoch 47/100\n",
      "2973/2973 [==============================] - 3s 968us/step - loss: 0.4169 - accuracy: 0.7191\n",
      "Epoch 48/100\n",
      "2973/2973 [==============================] - 3s 973us/step - loss: 0.4170 - accuracy: 0.7183\n",
      "Epoch 49/100\n",
      "2973/2973 [==============================] - 3s 968us/step - loss: 0.4169 - accuracy: 0.7195\n",
      "Epoch 50/100\n",
      "2973/2973 [==============================] - 3s 979us/step - loss: 0.4166 - accuracy: 0.72070s - loss: 0.4 - ETA: 0s - loss: 0.4165 - accuracy: \n",
      "Epoch 51/100\n",
      "2973/2973 [==============================] - 3s 982us/step - loss: 0.4168 - accuracy: 0.7197\n",
      "Epoch 52/100\n",
      "2973/2973 [==============================] - 3s 987us/step - loss: 0.4165 - accuracy: 0.7200\n",
      "Epoch 53/100\n",
      "2973/2973 [==============================] - 3s 968us/step - loss: 0.4167 - accuracy: 0.7173\n",
      "Epoch 54/100\n",
      "2973/2973 [==============================] - 3s 932us/step - loss: 0.4165 - accuracy: 0.7164\n",
      "Epoch 55/100\n",
      "2973/2973 [==============================] - 3s 988us/step - loss: 0.4166 - accuracy: 0.7159\n",
      "Epoch 56/100\n",
      "2973/2973 [==============================] - 3s 975us/step - loss: 0.4164 - accuracy: 0.71860s - loss: 0.4161 - accuracy: \n",
      "Epoch 57/100\n",
      "2973/2973 [==============================] - 3s 980us/step - loss: 0.4164 - accuracy: 0.7170\n",
      "Epoch 58/100\n",
      "2973/2973 [==============================] - 3s 966us/step - loss: 0.4164 - accuracy: 0.71880s - loss: 0.4154 - accu\n",
      "Epoch 59/100\n",
      "2973/2973 [==============================] - 3s 966us/step - loss: 0.4163 - accuracy: 0.7189\n",
      "Epoch 60/100\n",
      "2973/2973 [==============================] - 3s 987us/step - loss: 0.4162 - accuracy: 0.7162\n",
      "Epoch 61/100\n",
      "2973/2973 [==============================] - 3s 974us/step - loss: 0.4162 - accuracy: 0.7167\n",
      "Epoch 62/100\n",
      "2973/2973 [==============================] - 3s 991us/step - loss: 0.4160 - accuracy: 0.7167\n",
      "Epoch 63/100\n",
      "2973/2973 [==============================] - 3s 973us/step - loss: 0.4160 - accuracy: 0.7173\n",
      "Epoch 64/100\n",
      "2973/2973 [==============================] - ETA: 0s - loss: 0.4160 - accuracy: 0.71 - 3s 981us/step - loss: 0.4160 - accuracy: 0.7190\n",
      "Epoch 65/100\n",
      "2973/2973 [==============================] - 3s 983us/step - loss: 0.4161 - accuracy: 0.71700s\n",
      "Epoch 66/100\n",
      "2973/2973 [==============================] - 3s 980us/step - loss: 0.4159 - accuracy: 0.7178\n",
      "Epoch 67/100\n",
      "2973/2973 [==============================] - 3s 980us/step - loss: 0.4159 - accuracy: 0.7159\n",
      "Epoch 68/100\n",
      "2973/2973 [==============================] - 3s 946us/step - loss: 0.4158 - accuracy: 0.7209\n",
      "Epoch 69/100\n",
      "2973/2973 [==============================] - 3s 964us/step - loss: 0.4158 - accuracy: 0.7176\n",
      "Epoch 70/100\n",
      "2973/2973 [==============================] - 3s 966us/step - loss: 0.4159 - accuracy: 0.7210\n",
      "Epoch 71/100\n",
      "2973/2973 [==============================] - 3s 960us/step - loss: 0.4157 - accuracy: 0.7202\n",
      "Epoch 72/100\n",
      "2973/2973 [==============================] - 3s 979us/step - loss: 0.4156 - accuracy: 0.71790s - loss: 0.415\n",
      "Epoch 73/100\n",
      "2973/2973 [==============================] - 3s 982us/step - loss: 0.4159 - accuracy: 0.7169\n",
      "Epoch 74/100\n",
      "2973/2973 [==============================] - 3s 976us/step - loss: 0.4156 - accuracy: 0.7173\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2973/2973 [==============================] - 3s 984us/step - loss: 0.4157 - accuracy: 0.7172\n"
     ]
    }
   ],
   "source": [
    "nn4.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "fit_model = nn4.fit(X_train_scaled,y_train, batch_size = 64, epochs=100, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7405ceb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1982/1982 - 1s - loss: 0.4229 - accuracy: 0.7140\n",
      "Loss: 0.42289119958877563, Accuracy: 0.714049220085144\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn4.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9763a006",
   "metadata": {},
   "source": [
    "## Attempt 5\n",
    "### LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14a20768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0883b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = df[\"Diabetes_012\"].values\n",
    "X = df.drop(columns=['Diabetes_012', 'BMI', 'Age', 'Income', 'PhysHlth', 'Education', 'GenHlth', 'MentHlth']).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96e6a24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 120)               1800      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 50)                6050      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 30)                1530      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 9,411\n",
      "Trainable params: 9,411\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 120\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 30\n",
    "nn5 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# Second hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# Third hidden layer\n",
    "nn5.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# Output layer\n",
    "nn5.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e22791e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4242 - accuracy: 0.7130\n",
      "Epoch 2/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4224 - accuracy: 0.7200: 0s - loss: 0.4216 - \n",
      "Epoch 3/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4220 - accuracy: 0.7185\n",
      "Epoch 4/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4217 - accuracy: 0.7169\n",
      "Epoch 5/100\n",
      "2973/2973 [==============================] - 3s 998us/step - loss: 0.4216 - accuracy: 0.7166\n",
      "Epoch 6/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4214 - accuracy: 0.7182\n",
      "Epoch 7/100\n",
      "2973/2973 [==============================] - 3s 983us/step - loss: 0.4212 - accuracy: 0.7175\n",
      "Epoch 8/100\n",
      "2973/2973 [==============================] - 3s 993us/step - loss: 0.4211 - accuracy: 0.7162\n",
      "Epoch 9/100\n",
      "2973/2973 [==============================] - 3s 997us/step - loss: 0.4210 - accuracy: 0.71730s - loss: 0.4212 - accuracy: 0.71\n",
      "Epoch 10/100\n",
      "2973/2973 [==============================] - 3s 991us/step - loss: 0.4209 - accuracy: 0.7168\n",
      "Epoch 11/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4208 - accuracy: 0.7169\n",
      "Epoch 12/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4207 - accuracy: 0.7160\n",
      "Epoch 13/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4207 - accuracy: 0.7176\n",
      "Epoch 14/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4206 - accuracy: 0.7146\n",
      "Epoch 15/100\n",
      "2973/2973 [==============================] - 3s 974us/step - loss: 0.4205 - accuracy: 0.7158\n",
      "Epoch 16/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4204 - accuracy: 0.7182\n",
      "Epoch 17/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4203 - accuracy: 0.7161\n",
      "Epoch 18/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4201 - accuracy: 0.7198\n",
      "Epoch 19/100\n",
      "2973/2973 [==============================] - 3s 998us/step - loss: 0.4201 - accuracy: 0.7177\n",
      "Epoch 20/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4199 - accuracy: 0.7192: 0s - loss: 0.4\n",
      "Epoch 21/100\n",
      "2973/2973 [==============================] - 3s 993us/step - loss: 0.4199 - accuracy: 0.7193\n",
      "Epoch 22/100\n",
      "2973/2973 [==============================] - 3s 993us/step - loss: 0.4199 - accuracy: 0.7191\n",
      "Epoch 23/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4196 - accuracy: 0.7178\n",
      "Epoch 24/100\n",
      "2973/2973 [==============================] - 3s 996us/step - loss: 0.4197 - accuracy: 0.7191\n",
      "Epoch 25/100\n",
      "2973/2973 [==============================] - 3s 987us/step - loss: 0.4196 - accuracy: 0.7176\n",
      "Epoch 26/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4194 - accuracy: 0.7181\n",
      "Epoch 27/100\n",
      "2973/2973 [==============================] - 3s 990us/step - loss: 0.4195 - accuracy: 0.7189\n",
      "Epoch 28/100\n",
      "2973/2973 [==============================] - 3s 995us/step - loss: 0.4194 - accuracy: 0.7191\n",
      "Epoch 29/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4192 - accuracy: 0.7214\n",
      "Epoch 30/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4192 - accuracy: 0.7204\n",
      "Epoch 31/100\n",
      "2973/2973 [==============================] - 3s 999us/step - loss: 0.4191 - accuracy: 0.7214\n",
      "Epoch 32/100\n",
      "2973/2973 [==============================] - 3s 998us/step - loss: 0.4190 - accuracy: 0.7219\n",
      "Epoch 33/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4189 - accuracy: 0.7228\n",
      "Epoch 34/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4189 - accuracy: 0.7220: 1s - loss: 0.4196 - accu - ETA: 0s -\n",
      "Epoch 35/100\n",
      "2973/2973 [==============================] - 3s 997us/step - loss: 0.4188 - accuracy: 0.7200\n",
      "Epoch 36/100\n",
      "2973/2973 [==============================] - 3s 993us/step - loss: 0.4187 - accuracy: 0.7212\n",
      "Epoch 37/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4186 - accuracy: 0.7220\n",
      "Epoch 38/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4187 - accuracy: 0.7214\n",
      "Epoch 39/100\n",
      "2973/2973 [==============================] - 3s 998us/step - loss: 0.4185 - accuracy: 0.7215\n",
      "Epoch 40/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4183 - accuracy: 0.7229\n",
      "Epoch 41/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4184 - accuracy: 0.7219\n",
      "Epoch 42/100\n",
      "2973/2973 [==============================] - 3s 997us/step - loss: 0.4183 - accuracy: 0.7206\n",
      "Epoch 43/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4182 - accuracy: 0.7204: 0s - loss: 0\n",
      "Epoch 44/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4182 - accuracy: 0.7216\n",
      "Epoch 45/100\n",
      "2973/2973 [==============================] - 3s 996us/step - loss: 0.4181 - accuracy: 0.72240s - loss: 0.4183 - accuracy\n",
      "Epoch 46/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4180 - accuracy: 0.7214\n",
      "Epoch 47/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4181 - accuracy: 0.7206\n",
      "Epoch 48/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4179 - accuracy: 0.7208\n",
      "Epoch 49/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4178 - accuracy: 0.7222\n",
      "Epoch 50/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4178 - accuracy: 0.7222\n",
      "Epoch 51/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4178 - accuracy: 0.7219: 0s - loss: 0\n",
      "Epoch 52/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4177 - accuracy: 0.7225: 0s - loss: 0.4173 - accuracy - ETA: 0s - loss: 0.417\n",
      "Epoch 53/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4177 - accuracy: 0.7217\n",
      "Epoch 54/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4175 - accuracy: 0.7207: 0s - loss: 0.4\n",
      "Epoch 55/100\n",
      "2973/2973 [==============================] - 3s 995us/step - loss: 0.4175 - accuracy: 0.7222\n",
      "Epoch 56/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4174 - accuracy: 0.7212\n",
      "Epoch 57/100\n",
      "2973/2973 [==============================] - 3s 997us/step - loss: 0.4175 - accuracy: 0.7228\n",
      "Epoch 58/100\n",
      "2973/2973 [==============================] - 3s 987us/step - loss: 0.4174 - accuracy: 0.7230\n",
      "Epoch 59/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4174 - accuracy: 0.7203\n",
      "Epoch 60/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4173 - accuracy: 0.7226: 0s - los\n",
      "Epoch 61/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4171 - accuracy: 0.7220\n",
      "Epoch 62/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4172 - accuracy: 0.7219\n",
      "Epoch 63/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4171 - accuracy: 0.7232\n",
      "Epoch 64/100\n",
      "2973/2973 [==============================] - 3s 996us/step - loss: 0.4171 - accuracy: 0.7233\n",
      "Epoch 65/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4170 - accuracy: 0.7222\n",
      "Epoch 66/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4169 - accuracy: 0.7230: 1s\n",
      "Epoch 67/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4169 - accuracy: 0.7220\n",
      "Epoch 68/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4169 - accuracy: 0.7221\n",
      "Epoch 69/100\n",
      "2973/2973 [==============================] - 3s 999us/step - loss: 0.4168 - accuracy: 0.7220\n",
      "Epoch 70/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4168 - accuracy: 0.7227\n",
      "Epoch 71/100\n",
      "2973/2973 [==============================] - 3s 998us/step - loss: 0.4168 - accuracy: 0.72290s - loss:\n",
      "Epoch 72/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4168 - accuracy: 0.7231\n",
      "Epoch 73/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4166 - accuracy: 0.7235\n",
      "Epoch 74/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4165 - accuracy: 0.7240\n",
      "Epoch 75/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4166 - accuracy: 0.7218\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4165 - accuracy: 0.7232\n",
      "Epoch 77/100\n",
      "2973/2973 [==============================] - 3s 987us/step - loss: 0.4165 - accuracy: 0.7228\n",
      "Epoch 78/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4165 - accuracy: 0.7226\n",
      "Epoch 79/100\n",
      "2973/2973 [==============================] - 3s 1ms/step - loss: 0.4165 - accuracy: 0.7236\n"
     ]
    }
   ],
   "source": [
    "nn5.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "fit_model = nn5.fit(X_train_scaled,y_train, batch_size = 64, epochs=100, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc7b2749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1982/1982 - 1s - loss: 0.4226 - accuracy: 0.7032\n",
      "Loss: 0.4226335883140564, Accuracy: 0.7031851410865784\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn5.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debde28a",
   "metadata": {},
   "source": [
    "## Attempt 6\n",
    "### Batch size decreased. Nodes increased. Keeping 7 most important. LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f829eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = df[\"Diabetes_012\"].values\n",
    "X = df.drop(columns=['Diabetes_012', 'BMI', 'Age', 'Income', 'PhysHlth', 'Education', 'GenHlth', 'MentHlth']).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "043bb1ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 120)               1800      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 80)                9680      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 14,761\n",
      "Trainable params: 14,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 120\n",
    "hidden_nodes_layer2 = 80\n",
    "hidden_nodes_layer3 = 40\n",
    "nn6 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"sigmoid\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# Third hidden layer\n",
    "nn6.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# Output layer\n",
    "nn6.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50405737",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11892/11892 [==============================] - 12s 954us/step - loss: 0.4257 - accuracy: 0.7174\n",
      "Epoch 2/100\n",
      "11892/11892 [==============================] - 11s 943us/step - loss: 0.4234 - accuracy: 0.7141s - loss: 0.4234 - accuracy: 0.71\n",
      "Epoch 3/100\n",
      "11892/11892 [==============================] - 11s 953us/step - loss: 0.4229 - accuracy: 0.7161\n",
      "Epoch 4/100\n",
      "11892/11892 [==============================] - 11s 950us/step - loss: 0.4225 - accuracy: 0.7110\n",
      "Epoch 5/100\n",
      "11892/11892 [==============================] - 11s 950us/step - loss: 0.4222 - accuracy: 0.7122\n",
      "Epoch 6/100\n",
      "11892/11892 [==============================] - 11s 954us/step - loss: 0.4221 - accuracy: 0.7157\n",
      "Epoch 7/100\n",
      "11892/11892 [==============================] - 11s 951us/step - loss: 0.4219 - accuracy: 0.7134\n",
      "Epoch 8/100\n",
      "11892/11892 [==============================] - 11s 954us/step - loss: 0.4219 - accuracy: 0.7127\n",
      "Epoch 9/100\n",
      "11892/11892 [==============================] - ETA: 0s - loss: 0.4217 - accuracy: 0.71 - 11s 955us/step - loss: 0.4217 - accuracy: 0.7131\n",
      "Epoch 10/100\n",
      "11892/11892 [==============================] - 11s 953us/step - loss: 0.4217 - accuracy: 0.7151\n",
      "Epoch 11/100\n",
      "11892/11892 [==============================] - 11s 955us/step - loss: 0.4215 - accuracy: 0.7141\n",
      "Epoch 12/100\n",
      "11892/11892 [==============================] - 11s 951us/step - loss: 0.4214 - accuracy: 0.7163\n",
      "Epoch 13/100\n",
      "11892/11892 [==============================] - 11s 949us/step - loss: 0.4214 - accuracy: 0.7153s - loss: 0.4213 - ac\n",
      "Epoch 14/100\n",
      "11892/11892 [==============================] - 11s 944us/step - loss: 0.4212 - accuracy: 0.7141\n",
      "Epoch 15/100\n",
      "11892/11892 [==============================] - 11s 949us/step - loss: 0.4211 - accuracy: 0.7159\n",
      "Epoch 16/100\n",
      "11892/11892 [==============================] - 11s 947us/step - loss: 0.4211 - accuracy: 0.7156\n",
      "Epoch 17/100\n",
      "11892/11892 [==============================] - 11s 951us/step - loss: 0.4211 - accuracy: 0.7155\n",
      "Epoch 18/100\n",
      "11892/11892 [==============================] - 11s 954us/step - loss: 0.4210 - accuracy: 0.7151\n",
      "Epoch 19/100\n",
      "11892/11892 [==============================] - 11s 960us/step - loss: 0.4209 - accuracy: 0.7163s - loss: 0.4210 - accuracy: 0.71\n",
      "Epoch 20/100\n",
      "11892/11892 [==============================] - 12s 999us/step - loss: 0.4208 - accuracy: 0.7143\n",
      "Epoch 21/100\n",
      "11892/11892 [==============================] - 12s 985us/step - loss: 0.4208 - accuracy: 0.7161\n",
      "Epoch 22/100\n",
      "11892/11892 [==============================] - 11s 948us/step - loss: 0.4209 - accuracy: 0.7162\n",
      "Epoch 23/100\n",
      "11892/11892 [==============================] - 11s 951us/step - loss: 0.4208 - accuracy: 0.7164\n",
      "Epoch 24/100\n",
      "11892/11892 [==============================] - 11s 954us/step - loss: 0.4207 - accuracy: 0.7169\n",
      "Epoch 25/100\n",
      "11892/11892 [==============================] - 11s 950us/step - loss: 0.4205 - accuracy: 0.7167\n",
      "Epoch 26/100\n",
      "11892/11892 [==============================] - 11s 950us/step - loss: 0.4205 - accuracy: 0.7171s - loss: 0.420 -\n",
      "Epoch 27/100\n",
      "11892/11892 [==============================] - 11s 948us/step - loss: 0.4206 - accuracy: 0.7167\n",
      "Epoch 28/100\n",
      "11892/11892 [==============================] - 11s 946us/step - loss: 0.4204 - accuracy: 0.7176\n",
      "Epoch 29/100\n",
      "11892/11892 [==============================] - 11s 953us/step - loss: 0.4205 - accuracy: 0.7185\n",
      "Epoch 30/100\n",
      "11892/11892 [==============================] - 11s 944us/step - loss: 0.4203 - accuracy: 0.7171\n",
      "Epoch 31/100\n",
      "11892/11892 [==============================] - 11s 950us/step - loss: 0.4203 - accuracy: 0.7163s -\n",
      "Epoch 32/100\n",
      "11892/11892 [==============================] - 11s 953us/step - loss: 0.4202 - accuracy: 0.7196\n",
      "Epoch 33/100\n",
      "11892/11892 [==============================] - 11s 948us/step - loss: 0.4201 - accuracy: 0.7181\n",
      "Epoch 34/100\n",
      "11892/11892 [==============================] - 11s 950us/step - loss: 0.4200 - accuracy: 0.7178\n",
      "Epoch 35/100\n",
      "11892/11892 [==============================] - 11s 954us/step - loss: 0.4200 - accuracy: 0.7189\n",
      "Epoch 36/100\n",
      "11892/11892 [==============================] - 11s 950us/step - loss: 0.4199 - accuracy: 0.7174\n",
      "Epoch 37/100\n",
      "11892/11892 [==============================] - 11s 950us/step - loss: 0.4199 - accuracy: 0.7183s\n",
      "Epoch 38/100\n",
      "11892/11892 [==============================] - 11s 951us/step - loss: 0.4198 - accuracy: 0.7170\n",
      "Epoch 39/100\n",
      "11892/11892 [==============================] - 11s 949us/step - loss: 0.4197 - accuracy: 0.7185\n",
      "Epoch 40/100\n",
      "11892/11892 [==============================] - 11s 952us/step - loss: 0.4196 - accuracy: 0.7190\n",
      "Epoch 41/100\n",
      "11892/11892 [==============================] - 11s 947us/step - loss: 0.4196 - accuracy: 0.7189\n",
      "Epoch 42/100\n",
      "11892/11892 [==============================] - 11s 949us/step - loss: 0.4196 - accuracy: 0.7185\n",
      "Epoch 43/100\n",
      "11892/11892 [==============================] - 11s 945us/step - loss: 0.4194 - accuracy: 0.7188\n",
      "Epoch 44/100\n",
      "11892/11892 [==============================] - 11s 947us/step - loss: 0.4194 - accuracy: 0.7199\n",
      "Epoch 45/100\n",
      "11892/11892 [==============================] - 11s 951us/step - loss: 0.4193 - accuracy: 0.7185\n",
      "Epoch 46/100\n",
      "11892/11892 [==============================] - 11s 951us/step - loss: 0.4192 - accuracy: 0.7188\n",
      "Epoch 47/100\n",
      "11892/11892 [==============================] - 11s 947us/step - loss: 0.4192 - accuracy: 0.7200\n",
      "Epoch 48/100\n",
      "11892/11892 [==============================] - 11s 950us/step - loss: 0.4191 - accuracy: 0.7188\n",
      "Epoch 49/100\n",
      "11892/11892 [==============================] - 11s 946us/step - loss: 0.4190 - accuracy: 0.7210\n",
      "Epoch 50/100\n",
      "11892/11892 [==============================] - 11s 946us/step - loss: 0.4189 - accuracy: 0.7194\n",
      "Epoch 51/100\n",
      "11892/11892 [==============================] - 11s 950us/step - loss: 0.4187 - accuracy: 0.7204s\n",
      "Epoch 52/100\n",
      "11892/11892 [==============================] - 11s 955us/step - loss: 0.4188 - accuracy: 0.7203\n",
      "Epoch 53/100\n",
      "11892/11892 [==============================] - 11s 953us/step - loss: 0.4187 - accuracy: 0.7191\n",
      "Epoch 54/100\n",
      "11892/11892 [==============================] - 11s 957us/step - loss: 0.4186 - accuracy: 0.7202\n",
      "Epoch 55/100\n",
      "11892/11892 [==============================] - 11s 949us/step - loss: 0.4186 - accuracy: 0.7188\n",
      "Epoch 56/100\n",
      "11892/11892 [==============================] - 11s 948us/step - loss: 0.4183 - accuracy: 0.7191\n",
      "Epoch 57/100\n",
      "11892/11892 [==============================] - 11s 944us/step - loss: 0.4183 - accuracy: 0.7207\n",
      "Epoch 58/100\n",
      "11892/11892 [==============================] - 11s 951us/step - loss: 0.4184 - accuracy: 0.7209\n",
      "Epoch 59/100\n",
      "11892/11892 [==============================] - 11s 954us/step - loss: 0.4182 - accuracy: 0.7208\n",
      "Epoch 60/100\n",
      "11892/11892 [==============================] - 11s 950us/step - loss: 0.4182 - accuracy: 0.7204\n",
      "Epoch 61/100\n",
      "11892/11892 [==============================] - 12s 969us/step - loss: 0.4181 - accuracy: 0.7193\n",
      "Epoch 62/100\n",
      "11892/11892 [==============================] - 11s 966us/step - loss: 0.4179 - accuracy: 0.7203s - loss: 0.4185 -  - ETA: 0s - loss: 0.4\n",
      "Epoch 63/100\n",
      "11892/11892 [==============================] - 11s 954us/step - loss: 0.4180 - accuracy: 0.7220\n",
      "Epoch 64/100\n",
      "11892/11892 [==============================] - 11s 959us/step - loss: 0.4178 - accuracy: 0.7216s - ETA: 0s - ETA: 0s - loss: 0.4179 - accuracy: 0.\n",
      "Epoch 65/100\n",
      "11892/11892 [==============================] - 11s 957us/step - loss: 0.4177 - accuracy: 0.7214\n",
      "Epoch 66/100\n",
      "11892/11892 [==============================] - 11s 959us/step - loss: 0.4177 - accuracy: 0.7208\n",
      "Epoch 67/100\n",
      "11892/11892 [==============================] - 11s 958us/step - loss: 0.4176 - accuracy: 0.7211\n",
      "Epoch 68/100\n",
      "11892/11892 [==============================] - 11s 966us/step - loss: 0.4176 - accuracy: 0.7213\n",
      "Epoch 69/100\n",
      "11892/11892 [==============================] - 11s 963us/step - loss: 0.4173 - accuracy: 0.7215\n",
      "Epoch 70/100\n",
      "11892/11892 [==============================] - 11s 964us/step - loss: 0.4173 - accuracy: 0.7209s - l\n",
      "Epoch 71/100\n",
      "11892/11892 [==============================] - ETA: 0s - loss: 0.4173 - accuracy: 0.7218 ETA: 0s - loss: 0.4169 - accuracy:  - 11s 964us/step - loss: 0.4171 - accuracy: 0.7218\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11892/11892 [==============================] - 11s 961us/step - loss: 0.4173 - accuracy: 0.7217\n",
      "Epoch 73/100\n",
      "11892/11892 [==============================] - 11s 958us/step - loss: 0.4172 - accuracy: 0.7208\n",
      "Epoch 74/100\n",
      "11892/11892 [==============================] - 11s 957us/step - loss: 0.4172 - accuracy: 0.7201\n"
     ]
    }
   ],
   "source": [
    "nn6.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "fit_model = nn6.fit(X_train_scaled,y_train, batch_size = 16, epochs=100, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd25cbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1982/1982 - 1s - loss: 0.4212 - accuracy: 0.7294\n",
      "Loss: 0.42117616534233093, Accuracy: 0.7294386625289917\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn6.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabf1a34",
   "metadata": {},
   "source": [
    "## Attempt 7\n",
    "### Removing pre diabetes. Batch default. Keeping all the columns. Similar to Attempt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bec55b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_012</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_012  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0           0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1           0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2           0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3           0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4           0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                   0.0           0.0     0.0  ...            1.0   \n",
       "1                   0.0           1.0     0.0  ...            0.0   \n",
       "2                   0.0           0.0     1.0  ...            1.0   \n",
       "3                   0.0           1.0     1.0  ...            1.0   \n",
       "4                   0.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
       "0          0.0      5.0      18.0      15.0       1.0  0.0   9.0        4.0   \n",
       "1          1.0      3.0       0.0       0.0       0.0  0.0   7.0        6.0   \n",
       "2          1.0      5.0      30.0      30.0       1.0  0.0   9.0        4.0   \n",
       "3          0.0      2.0       0.0       0.0       0.0  0.0  11.0        3.0   \n",
       "4          0.0      2.0       3.0       0.0       0.0  0.0  11.0        5.0   \n",
       "\n",
       "   Income  \n",
       "0     3.0  \n",
       "1     1.0  \n",
       "2     8.0  \n",
       "3     6.0  \n",
       "4     4.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_pre = df[df[\"Diabetes_012\"] != 1]\n",
    "df_no_pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a1e889a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = df_no_pre[\"Diabetes_012\"].values\n",
    "X = df_no_pre.drop(columns=['Diabetes_012']).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af02732f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 120)               2640      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 50)                6050      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 30)                1530      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 10,251\n",
      "Trainable params: 10,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 120\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 30\n",
    "nn7 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn7.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# Second hidden layer\n",
    "nn7.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# Third hidden layer\n",
    "nn7.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# Output layer\n",
    "nn7.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a0b7231",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5838/5838 [==============================] - 6s 984us/step - loss: 0.3940 - accuracy: 0.7300\n",
      "Epoch 2/100\n",
      "5838/5838 [==============================] - 6s 971us/step - loss: 0.3905 - accuracy: 0.7370\n",
      "Epoch 3/100\n",
      "5838/5838 [==============================] - 6s 966us/step - loss: 0.3895 - accuracy: 0.73810s - loss: 0.3892 - accuracy: \n",
      "Epoch 4/100\n",
      "5838/5838 [==============================] - 6s 964us/step - loss: 0.3888 - accuracy: 0.7404\n",
      "Epoch 5/100\n",
      "5838/5838 [==============================] - 6s 968us/step - loss: 0.3880 - accuracy: 0.7403\n",
      "Epoch 6/100\n",
      "5838/5838 [==============================] - 6s 961us/step - loss: 0.3876 - accuracy: 0.74090s - los\n",
      "Epoch 7/100\n",
      "5838/5838 [==============================] - 6s 958us/step - loss: 0.3870 - accuracy: 0.7404\n",
      "Epoch 8/100\n",
      "5838/5838 [==============================] - 6s 955us/step - loss: 0.3865 - accuracy: 0.7423\n",
      "Epoch 9/100\n",
      "5838/5838 [==============================] - 6s 943us/step - loss: 0.3859 - accuracy: 0.74190s - loss: 0.3863 - accuracy\n",
      "Epoch 10/100\n",
      "5838/5838 [==============================] - 6s 953us/step - loss: 0.3856 - accuracy: 0.74290s - loss: 0.3854 - accura - ETA: 0s - loss: 0.3853 - accuracy: \n",
      "Epoch 11/100\n",
      "5838/5838 [==============================] - 6s 969us/step - loss: 0.3850 - accuracy: 0.7430\n",
      "Epoch 12/100\n",
      "5838/5838 [==============================] - 6s 964us/step - loss: 0.3844 - accuracy: 0.7419\n",
      "Epoch 13/100\n",
      "5838/5838 [==============================] - 6s 961us/step - loss: 0.3841 - accuracy: 0.7438\n",
      "Epoch 14/100\n",
      "5838/5838 [==============================] - 6s 961us/step - loss: 0.3834 - accuracy: 0.7442\n",
      "Epoch 15/100\n",
      "5838/5838 [==============================] - 6s 959us/step - loss: 0.3827 - accuracy: 0.7446\n",
      "Epoch 16/100\n",
      "5838/5838 [==============================] - 6s 965us/step - loss: 0.3822 - accuracy: 0.7457\n",
      "Epoch 17/100\n",
      "5838/5838 [==============================] - 6s 963us/step - loss: 0.3818 - accuracy: 0.7444\n",
      "Epoch 18/100\n",
      "5838/5838 [==============================] - 6s 959us/step - loss: 0.3810 - accuracy: 0.7459\n",
      "Epoch 19/100\n",
      "5838/5838 [==============================] - 6s 976us/step - loss: 0.3805 - accuracy: 0.7471\n",
      "Epoch 20/100\n",
      "5838/5838 [==============================] - 6s 975us/step - loss: 0.3798 - accuracy: 0.7467\n",
      "Epoch 21/100\n",
      "5838/5838 [==============================] - 6s 961us/step - loss: 0.3792 - accuracy: 0.7472\n",
      "Epoch 22/100\n",
      "5838/5838 [==============================] - 6s 960us/step - loss: 0.3787 - accuracy: 0.7488\n",
      "Epoch 23/100\n",
      "5838/5838 [==============================] - 6s 962us/step - loss: 0.3780 - accuracy: 0.74830s - l\n",
      "Epoch 24/100\n",
      "5838/5838 [==============================] - 6s 964us/step - loss: 0.3771 - accuracy: 0.7490\n",
      "Epoch 25/100\n",
      "5838/5838 [==============================] - 6s 953us/step - loss: 0.3766 - accuracy: 0.7504\n",
      "Epoch 26/100\n",
      "5838/5838 [==============================] - 6s 964us/step - loss: 0.3762 - accuracy: 0.75020s - loss: 0.3757 - accuracy\n",
      "Epoch 27/100\n",
      "5838/5838 [==============================] - 6s 957us/step - loss: 0.3755 - accuracy: 0.7492\n",
      "Epoch 28/100\n",
      "5838/5838 [==============================] - 6s 954us/step - loss: 0.3748 - accuracy: 0.7511\n",
      "Epoch 29/100\n",
      "5838/5838 [==============================] - 6s 962us/step - loss: 0.3740 - accuracy: 0.7521\n",
      "Epoch 30/100\n",
      "5838/5838 [==============================] - 6s 956us/step - loss: 0.3735 - accuracy: 0.7518\n",
      "Epoch 31/100\n",
      "5838/5838 [==============================] - 6s 965us/step - loss: 0.3730 - accuracy: 0.7520\n",
      "Epoch 32/100\n",
      "5838/5838 [==============================] - 6s 954us/step - loss: 0.3722 - accuracy: 0.7530\n",
      "Epoch 33/100\n",
      "5838/5838 [==============================] - 6s 968us/step - loss: 0.3719 - accuracy: 0.75320s - loss: 0.3711 - \n",
      "Epoch 34/100\n",
      "5838/5838 [==============================] - 6s 944us/step - loss: 0.3710 - accuracy: 0.7527\n",
      "Epoch 35/100\n",
      "5838/5838 [==============================] - 6s 961us/step - loss: 0.3704 - accuracy: 0.75451s - loss: 0.3687 - \n",
      "Epoch 36/100\n",
      "5838/5838 [==============================] - 6s 953us/step - loss: 0.3699 - accuracy: 0.7543\n",
      "Epoch 37/100\n",
      "5838/5838 [==============================] - 6s 958us/step - loss: 0.3692 - accuracy: 0.7546\n",
      "Epoch 38/100\n",
      "5838/5838 [==============================] - 6s 949us/step - loss: 0.3684 - accuracy: 0.7550\n",
      "Epoch 39/100\n",
      "5838/5838 [==============================] - 6s 959us/step - loss: 0.3679 - accuracy: 0.7549\n",
      "Epoch 40/100\n",
      "5838/5838 [==============================] - 6s 958us/step - loss: 0.3672 - accuracy: 0.7568\n",
      "Epoch 41/100\n",
      "5838/5838 [==============================] - 6s 964us/step - loss: 0.3670 - accuracy: 0.7563\n",
      "Epoch 42/100\n",
      "5838/5838 [==============================] - 6s 952us/step - loss: 0.3661 - accuracy: 0.7559\n",
      "Epoch 43/100\n",
      "5838/5838 [==============================] - 6s 943us/step - loss: 0.3658 - accuracy: 0.75711s - loss: 0.3671 - accuracy - ETA: 1s - loss:\n",
      "Epoch 44/100\n",
      "5838/5838 [==============================] - 6s 948us/step - loss: 0.3656 - accuracy: 0.7567\n",
      "Epoch 45/100\n",
      "5838/5838 [==============================] - 6s 974us/step - loss: 0.3651 - accuracy: 0.7570\n",
      "Epoch 46/100\n",
      "5838/5838 [==============================] - 6s 984us/step - loss: 0.3642 - accuracy: 0.7574\n",
      "Epoch 47/100\n",
      "5838/5838 [==============================] - 6s 988us/step - loss: 0.3640 - accuracy: 0.7579\n",
      "Epoch 48/100\n",
      "5838/5838 [==============================] - 6s 953us/step - loss: 0.3636 - accuracy: 0.7576\n",
      "Epoch 49/100\n",
      "5838/5838 [==============================] - 6s 952us/step - loss: 0.3629 - accuracy: 0.75740s - loss: 0.3629 - accuracy: \n",
      "Epoch 50/100\n",
      "5838/5838 [==============================] - 6s 942us/step - loss: 0.3621 - accuracy: 0.7582\n",
      "Epoch 51/100\n",
      "5838/5838 [==============================] - 6s 952us/step - loss: 0.3620 - accuracy: 0.7583\n",
      "Epoch 52/100\n",
      "5838/5838 [==============================] - 6s 946us/step - loss: 0.3615 - accuracy: 0.7590\n",
      "Epoch 53/100\n",
      "5838/5838 [==============================] - 6s 951us/step - loss: 0.3612 - accuracy: 0.7589\n",
      "Epoch 54/100\n",
      "5838/5838 [==============================] - 6s 959us/step - loss: 0.3609 - accuracy: 0.7590\n",
      "Epoch 55/100\n",
      "5838/5838 [==============================] - 5s 933us/step - loss: 0.3606 - accuracy: 0.7592\n",
      "Epoch 56/100\n",
      "5838/5838 [==============================] - 6s 944us/step - loss: 0.3601 - accuracy: 0.75881s - loss: 0.3592 - accuracy:  - ETA\n",
      "Epoch 57/100\n",
      "5838/5838 [==============================] - 6s 959us/step - loss: 0.3594 - accuracy: 0.7600\n",
      "Epoch 58/100\n",
      "5838/5838 [==============================] - 5s 933us/step - loss: 0.3591 - accuracy: 0.7596\n",
      "Epoch 59/100\n",
      "5838/5838 [==============================] - 6s 950us/step - loss: 0.3585 - accuracy: 0.7597\n",
      "Epoch 60/100\n",
      "5838/5838 [==============================] - 6s 950us/step - loss: 0.3581 - accuracy: 0.7603\n",
      "Epoch 61/100\n",
      "5838/5838 [==============================] - 6s 958us/step - loss: 0.3575 - accuracy: 0.7601\n",
      "Epoch 62/100\n",
      "5838/5838 [==============================] - 6s 952us/step - loss: 0.3577 - accuracy: 0.7603\n",
      "Epoch 63/100\n",
      "5838/5838 [==============================] - 6s 972us/step - loss: 0.3573 - accuracy: 0.76070s - loss: 0.3577 - ac\n",
      "Epoch 64/100\n",
      "5838/5838 [==============================] - 6s 959us/step - loss: 0.3572 - accuracy: 0.7609\n",
      "Epoch 65/100\n",
      "5838/5838 [==============================] - 6s 954us/step - loss: 0.3567 - accuracy: 0.76120s - loss: 0.3 - ETA: 0s - loss: 0.3565 - accuracy\n",
      "Epoch 66/100\n",
      "5838/5838 [==============================] - 6s 949us/step - loss: 0.3560 - accuracy: 0.7613\n",
      "Epoch 67/100\n",
      "5838/5838 [==============================] - 6s 959us/step - loss: 0.3563 - accuracy: 0.7597\n",
      "Epoch 68/100\n",
      "5838/5838 [==============================] - 5s 937us/step - loss: 0.3557 - accuracy: 0.7612\n",
      "Epoch 69/100\n",
      "5838/5838 [==============================] - 6s 959us/step - loss: 0.3553 - accuracy: 0.7621\n",
      "Epoch 70/100\n",
      "5838/5838 [==============================] - 5s 940us/step - loss: 0.3551 - accuracy: 0.7615\n",
      "Epoch 71/100\n",
      "5838/5838 [==============================] - 5s 942us/step - loss: 0.3548 - accuracy: 0.7613\n",
      "Epoch 72/100\n",
      "5838/5838 [==============================] - 6s 957us/step - loss: 0.3548 - accuracy: 0.76170s -\n",
      "Epoch 73/100\n",
      "5838/5838 [==============================] - 6s 950us/step - loss: 0.3541 - accuracy: 0.7617\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5838/5838 [==============================] - 6s 948us/step - loss: 0.3545 - accuracy: 0.7625\n",
      "Epoch 75/100\n",
      "5838/5838 [==============================] - 5s 937us/step - loss: 0.3538 - accuracy: 0.7623\n",
      "Epoch 76/100\n",
      "5838/5838 [==============================] - 6s 943us/step - loss: 0.3534 - accuracy: 0.7621\n",
      "Epoch 77/100\n",
      "5838/5838 [==============================] - 6s 952us/step - loss: 0.3535 - accuracy: 0.7625\n",
      "Epoch 78/100\n",
      "5838/5838 [==============================] - 5s 939us/step - loss: 0.3528 - accuracy: 0.7622\n",
      "Epoch 79/100\n",
      "5838/5838 [==============================] - 5s 942us/step - loss: 0.3525 - accuracy: 0.7629\n",
      "Epoch 80/100\n",
      "5838/5838 [==============================] - 6s 950us/step - loss: 0.3524 - accuracy: 0.7630\n",
      "Epoch 81/100\n",
      "5838/5838 [==============================] - 5s 942us/step - loss: 0.3519 - accuracy: 0.7633\n",
      "Epoch 82/100\n",
      "5838/5838 [==============================] - 6s 957us/step - loss: 0.3518 - accuracy: 0.7634\n",
      "Epoch 83/100\n",
      "5838/5838 [==============================] - 6s 945us/step - loss: 0.3513 - accuracy: 0.7634\n",
      "Epoch 84/100\n",
      "5838/5838 [==============================] - 6s 955us/step - loss: 0.3508 - accuracy: 0.7636\n",
      "Epoch 85/100\n",
      "5838/5838 [==============================] - 5s 941us/step - loss: 0.3508 - accuracy: 0.76361s - - ETA: 0s - loss: 0.3503 - \n",
      "Epoch 86/100\n",
      "5838/5838 [==============================] - 6s 945us/step - loss: 0.3507 - accuracy: 0.7640\n",
      "Epoch 87/100\n",
      "5838/5838 [==============================] - 6s 954us/step - loss: 0.3503 - accuracy: 0.7631\n",
      "Epoch 88/100\n",
      "5838/5838 [==============================] - 6s 952us/step - loss: 0.3507 - accuracy: 0.7626\n",
      "Epoch 89/100\n",
      "5838/5838 [==============================] - 6s 946us/step - loss: 0.3500 - accuracy: 0.76380s - loss: 0.3498 - ac\n",
      "Epoch 90/100\n",
      "5838/5838 [==============================] - 5s 942us/step - loss: 0.3497 - accuracy: 0.7639\n",
      "Epoch 91/100\n",
      "5838/5838 [==============================] - 6s 951us/step - loss: 0.3492 - accuracy: 0.7648\n",
      "Epoch 92/100\n",
      "5838/5838 [==============================] - 6s 955us/step - loss: 0.3494 - accuracy: 0.76360s - loss: 0.3491 \n",
      "Epoch 93/100\n",
      "5838/5838 [==============================] - 6s 965us/step - loss: 0.3492 - accuracy: 0.7639\n",
      "Epoch 94/100\n",
      "5838/5838 [==============================] - 6s 948us/step - loss: 0.3491 - accuracy: 0.7642\n",
      "Epoch 95/100\n",
      "5838/5838 [==============================] - 6s 956us/step - loss: 0.3486 - accuracy: 0.76430s - loss: 0.3483 - accuracy: \n",
      "Epoch 96/100\n",
      "5838/5838 [==============================] - 6s 942us/step - loss: 0.3482 - accuracy: 0.7657\n",
      "Epoch 97/100\n",
      "5838/5838 [==============================] - 5s 941us/step - loss: 0.3483 - accuracy: 0.7649\n",
      "Epoch 98/100\n",
      "5838/5838 [==============================] - 6s 949us/step - loss: 0.3484 - accuracy: 0.7641\n",
      "Epoch 99/100\n",
      "5838/5838 [==============================] - 6s 944us/step - loss: 0.3476 - accuracy: 0.76480s - loss: 0.3473 - accu\n",
      "Epoch 100/100\n",
      "5838/5838 [==============================] - 6s 971us/step - loss: 0.3477 - accuracy: 0.7635\n"
     ]
    }
   ],
   "source": [
    "nn7.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "fit_model = nn7.fit(X_train_scaled,y_train, batch_size = 32, epochs=100, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34a389a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1946/1946 - 1s - loss: 0.4240 - accuracy: 0.7370\n",
      "Loss: 0.4239537715911865, Accuracy: 0.7369706034660339\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn7.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113c05ed",
   "metadata": {},
   "source": [
    "## Attempt 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff4dff85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_012</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_012  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0           0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1           0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2           0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3           0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4           0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                   0.0           0.0     0.0  ...            1.0   \n",
       "1                   0.0           1.0     0.0  ...            0.0   \n",
       "2                   0.0           0.0     1.0  ...            1.0   \n",
       "3                   0.0           1.0     1.0  ...            1.0   \n",
       "4                   0.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
       "0          0.0      5.0      18.0      15.0       1.0  0.0   9.0        4.0   \n",
       "1          1.0      3.0       0.0       0.0       0.0  0.0   7.0        6.0   \n",
       "2          1.0      5.0      30.0      30.0       1.0  0.0   9.0        4.0   \n",
       "3          0.0      2.0       0.0       0.0       0.0  0.0  11.0        3.0   \n",
       "4          0.0      2.0       3.0       0.0       0.0  0.0  11.0        5.0   \n",
       "\n",
       "   Income  \n",
       "0     3.0  \n",
       "1     1.0  \n",
       "2     8.0  \n",
       "3     6.0  \n",
       "4     4.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_pre = df[df[\"Diabetes_012\"] != 1]\n",
    "df_no_pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7b1847cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = df_no_pre[\"Diabetes_012\"].values\n",
    "X = df_no_pre.drop(columns=['Diabetes_012']).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a2dbc3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 120)               2640      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 50)                6050      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 30)                1530      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 10,251\n",
      "Trainable params: 10,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 120\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 30\n",
    "nn8 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn8.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# Second hidden layer\n",
    "nn8.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# Third hidden layer\n",
    "nn8.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# Output layer\n",
    "nn8.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a9a734ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5838/5838 [==============================] - 6s 967us/step - loss: 0.3940 - accuracy: 0.7309\n",
      "Epoch 2/200\n",
      "5838/5838 [==============================] - 6s 960us/step - loss: 0.3905 - accuracy: 0.73780s -\n",
      "Epoch 3/200\n",
      "5838/5838 [==============================] - 6s 958us/step - loss: 0.3896 - accuracy: 0.74010s - loss: 0.3895 - accuracy\n",
      "Epoch 4/200\n",
      "5838/5838 [==============================] - 6s 968us/step - loss: 0.3886 - accuracy: 0.7367\n",
      "Epoch 5/200\n",
      "5838/5838 [==============================] - 6s 970us/step - loss: 0.3882 - accuracy: 0.7382\n",
      "Epoch 6/200\n",
      "5838/5838 [==============================] - 6s 954us/step - loss: 0.3875 - accuracy: 0.74050s - loss: 0.387\n",
      "Epoch 7/200\n",
      "5838/5838 [==============================] - 6s 958us/step - loss: 0.3871 - accuracy: 0.73740s - loss: 0.3870 - accuracy: 0.\n",
      "Epoch 8/200\n",
      "5838/5838 [==============================] - 6s 961us/step - loss: 0.3865 - accuracy: 0.7416\n",
      "Epoch 9/200\n",
      "5838/5838 [==============================] - 6s 959us/step - loss: 0.3860 - accuracy: 0.7401\n",
      "Epoch 10/200\n",
      "5838/5838 [==============================] - 6s 970us/step - loss: 0.3854 - accuracy: 0.74100s - loss: 0.3854 - accu\n",
      "Epoch 11/200\n",
      "5838/5838 [==============================] - 6s 972us/step - loss: 0.3848 - accuracy: 0.7425\n",
      "Epoch 12/200\n",
      "5838/5838 [==============================] - 6s 967us/step - loss: 0.3844 - accuracy: 0.7425\n",
      "Epoch 13/200\n",
      "5838/5838 [==============================] - 6s 960us/step - loss: 0.3837 - accuracy: 0.7435\n",
      "Epoch 14/200\n",
      "5838/5838 [==============================] - 6s 958us/step - loss: 0.3831 - accuracy: 0.7447\n",
      "Epoch 15/200\n",
      "5838/5838 [==============================] - 6s 969us/step - loss: 0.3827 - accuracy: 0.7444\n",
      "Epoch 16/200\n",
      "5838/5838 [==============================] - 6s 958us/step - loss: 0.3822 - accuracy: 0.7458\n",
      "Epoch 17/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3815 - accuracy: 0.7470\n",
      "Epoch 18/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3811 - accuracy: 0.7481: 0s - loss: 0.3807 - accuracy\n",
      "Epoch 19/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3804 - accuracy: 0.7477\n",
      "Epoch 20/200\n",
      "5838/5838 [==============================] - 6s 989us/step - loss: 0.3795 - accuracy: 0.7489\n",
      "Epoch 21/200\n",
      "5838/5838 [==============================] - 6s 982us/step - loss: 0.3788 - accuracy: 0.7499\n",
      "Epoch 22/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3782 - accuracy: 0.7507\n",
      "Epoch 23/200\n",
      "5838/5838 [==============================] - 6s 967us/step - loss: 0.3777 - accuracy: 0.7506\n",
      "Epoch 24/200\n",
      "5838/5838 [==============================] - 6s 960us/step - loss: 0.3771 - accuracy: 0.75150s - los\n",
      "Epoch 25/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3764 - accuracy: 0.7522\n",
      "Epoch 26/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3756 - accuracy: 0.7525: 0s - loss: 0.3\n",
      "Epoch 27/200\n",
      "5838/5838 [==============================] - 6s 950us/step - loss: 0.3749 - accuracy: 0.7530\n",
      "Epoch 28/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3744 - accuracy: 0.7539\n",
      "Epoch 29/200\n",
      "5838/5838 [==============================] - 6s 964us/step - loss: 0.3736 - accuracy: 0.7543\n",
      "Epoch 30/200\n",
      "5838/5838 [==============================] - 5s 903us/step - loss: 0.3732 - accuracy: 0.7547\n",
      "Epoch 31/200\n",
      "5838/5838 [==============================] - 5s 855us/step - loss: 0.3724 - accuracy: 0.7557\n",
      "Epoch 32/200\n",
      "5838/5838 [==============================] - 5s 880us/step - loss: 0.3718 - accuracy: 0.7563\n",
      "Epoch 33/200\n",
      "5838/5838 [==============================] - 5s 854us/step - loss: 0.3712 - accuracy: 0.7560\n",
      "Epoch 34/200\n",
      "5838/5838 [==============================] - 5s 875us/step - loss: 0.3709 - accuracy: 0.7567\n",
      "Epoch 35/200\n",
      "5838/5838 [==============================] - 5s 851us/step - loss: 0.3702 - accuracy: 0.7575\n",
      "Epoch 36/200\n",
      "5838/5838 [==============================] - 5s 868us/step - loss: 0.3697 - accuracy: 0.75770s - loss: 0.3698 - \n",
      "Epoch 37/200\n",
      "5838/5838 [==============================] - 5s 859us/step - loss: 0.3693 - accuracy: 0.7577\n",
      "Epoch 38/200\n",
      "5838/5838 [==============================] - 5s 864us/step - loss: 0.3688 - accuracy: 0.7581\n",
      "Epoch 39/200\n",
      "5838/5838 [==============================] - 5s 854us/step - loss: 0.3681 - accuracy: 0.7587\n",
      "Epoch 40/200\n",
      "5838/5838 [==============================] - 5s 866us/step - loss: 0.3673 - accuracy: 0.75960s - loss: 0.3673 - \n",
      "Epoch 41/200\n",
      "5838/5838 [==============================] - 5s 861us/step - loss: 0.3671 - accuracy: 0.7601\n",
      "Epoch 42/200\n",
      "5838/5838 [==============================] - 5s 854us/step - loss: 0.3665 - accuracy: 0.7603\n",
      "Epoch 43/200\n",
      "5838/5838 [==============================] - 5s 873us/step - loss: 0.3662 - accuracy: 0.7604\n",
      "Epoch 44/200\n",
      "5838/5838 [==============================] - 5s 856us/step - loss: 0.3657 - accuracy: 0.7607\n",
      "Epoch 45/200\n",
      "5838/5838 [==============================] - 5s 864us/step - loss: 0.3649 - accuracy: 0.76140s - loss: 0.3647 - accuracy: \n",
      "Epoch 46/200\n",
      "5838/5838 [==============================] - 5s 862us/step - loss: 0.3642 - accuracy: 0.7611\n",
      "Epoch 47/200\n",
      "5838/5838 [==============================] - 5s 873us/step - loss: 0.3640 - accuracy: 0.7610\n",
      "Epoch 48/200\n",
      "5838/5838 [==============================] - 5s 864us/step - loss: 0.3637 - accuracy: 0.7613\n",
      "Epoch 49/200\n",
      "5838/5838 [==============================] - 5s 863us/step - loss: 0.3631 - accuracy: 0.7616\n",
      "Epoch 50/200\n",
      "5838/5838 [==============================] - 5s 852us/step - loss: 0.3625 - accuracy: 0.7629\n",
      "Epoch 51/200\n",
      "5838/5838 [==============================] - 5s 884us/step - loss: 0.3625 - accuracy: 0.7623\n",
      "Epoch 52/200\n",
      "5838/5838 [==============================] - 5s 850us/step - loss: 0.3617 - accuracy: 0.7632\n",
      "Epoch 53/200\n",
      "5838/5838 [==============================] - 5s 871us/step - loss: 0.3611 - accuracy: 0.7633\n",
      "Epoch 54/200\n",
      "5838/5838 [==============================] - 5s 859us/step - loss: 0.3611 - accuracy: 0.7623\n",
      "Epoch 55/200\n",
      "5838/5838 [==============================] - 5s 869us/step - loss: 0.3605 - accuracy: 0.7630\n",
      "Epoch 56/200\n",
      "5838/5838 [==============================] - 5s 861us/step - loss: 0.3601 - accuracy: 0.7639\n",
      "Epoch 57/200\n",
      "5838/5838 [==============================] - 5s 866us/step - loss: 0.3595 - accuracy: 0.76390s - l\n",
      "Epoch 58/200\n",
      "5838/5838 [==============================] - 5s 849us/step - loss: 0.3591 - accuracy: 0.7640\n",
      "Epoch 59/200\n",
      "5838/5838 [==============================] - 5s 874us/step - loss: 0.3586 - accuracy: 0.7642\n",
      "Epoch 60/200\n",
      "5838/5838 [==============================] - 5s 853us/step - loss: 0.3585 - accuracy: 0.7646\n",
      "Epoch 61/200\n",
      "5838/5838 [==============================] - 5s 874us/step - loss: 0.3584 - accuracy: 0.7646\n",
      "Epoch 62/200\n",
      "5838/5838 [==============================] - 5s 867us/step - loss: 0.3577 - accuracy: 0.7643\n",
      "Epoch 63/200\n",
      "5838/5838 [==============================] - 5s 871us/step - loss: 0.3574 - accuracy: 0.7636\n",
      "Epoch 64/200\n",
      "5838/5838 [==============================] - 5s 859us/step - loss: 0.3572 - accuracy: 0.7652\n",
      "Epoch 65/200\n",
      "5838/5838 [==============================] - 5s 871us/step - loss: 0.3565 - accuracy: 0.7653\n",
      "Epoch 66/200\n",
      "5838/5838 [==============================] - 5s 840us/step - loss: 0.3563 - accuracy: 0.7650\n",
      "Epoch 67/200\n",
      "5838/5838 [==============================] - 5s 866us/step - loss: 0.3560 - accuracy: 0.7662\n",
      "Epoch 68/200\n",
      "5838/5838 [==============================] - 5s 853us/step - loss: 0.3558 - accuracy: 0.7655\n",
      "Epoch 69/200\n",
      "5838/5838 [==============================] - 5s 859us/step - loss: 0.3554 - accuracy: 0.7659\n",
      "Epoch 70/200\n",
      "5838/5838 [==============================] - 5s 876us/step - loss: 0.3550 - accuracy: 0.7656\n",
      "Epoch 71/200\n",
      "5838/5838 [==============================] - 5s 855us/step - loss: 0.3546 - accuracy: 0.7658\n",
      "Epoch 72/200\n",
      "5838/5838 [==============================] - 5s 864us/step - loss: 0.3540 - accuracy: 0.76650s - loss: 0.3544 - accuracy\n",
      "Epoch 73/200\n",
      "5838/5838 [==============================] - 5s 859us/step - loss: 0.3542 - accuracy: 0.7659\n",
      "Epoch 74/200\n",
      "5838/5838 [==============================] - 5s 866us/step - loss: 0.3540 - accuracy: 0.7663\n",
      "Epoch 75/200\n",
      "5838/5838 [==============================] - 5s 854us/step - loss: 0.3536 - accuracy: 0.7672\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5838/5838 [==============================] - 5s 872us/step - loss: 0.3537 - accuracy: 0.7663\n",
      "Epoch 77/200\n",
      "5838/5838 [==============================] - 5s 866us/step - loss: 0.3530 - accuracy: 0.7662\n",
      "Epoch 78/200\n",
      "5838/5838 [==============================] - 5s 859us/step - loss: 0.3526 - accuracy: 0.7667\n",
      "Epoch 79/200\n",
      "5838/5838 [==============================] - 5s 851us/step - loss: 0.3526 - accuracy: 0.7666\n",
      "Epoch 80/200\n",
      "5838/5838 [==============================] - 5s 860us/step - loss: 0.3524 - accuracy: 0.7674\n",
      "Epoch 81/200\n",
      "5838/5838 [==============================] - 5s 852us/step - loss: 0.3523 - accuracy: 0.7666\n",
      "Epoch 82/200\n",
      "5838/5838 [==============================] - 5s 866us/step - loss: 0.3516 - accuracy: 0.7683\n",
      "Epoch 83/200\n",
      "5838/5838 [==============================] - 5s 850us/step - loss: 0.3516 - accuracy: 0.7680\n",
      "Epoch 84/200\n",
      "5838/5838 [==============================] - 5s 860us/step - loss: 0.3514 - accuracy: 0.7668\n",
      "Epoch 85/200\n",
      "5838/5838 [==============================] - 5s 851us/step - loss: 0.3510 - accuracy: 0.7677\n",
      "Epoch 86/200\n",
      "5838/5838 [==============================] - 5s 857us/step - loss: 0.3506 - accuracy: 0.7679\n",
      "Epoch 87/200\n",
      "5838/5838 [==============================] - 5s 851us/step - loss: 0.3503 - accuracy: 0.7680\n",
      "Epoch 88/200\n",
      "5838/5838 [==============================] - 5s 866us/step - loss: 0.3505 - accuracy: 0.7679\n",
      "Epoch 89/200\n",
      "5838/5838 [==============================] - 5s 850us/step - loss: 0.3499 - accuracy: 0.7683\n",
      "Epoch 90/200\n",
      "5838/5838 [==============================] - 5s 867us/step - loss: 0.3497 - accuracy: 0.7684\n",
      "Epoch 91/200\n",
      "5838/5838 [==============================] - 5s 851us/step - loss: 0.3492 - accuracy: 0.7688\n",
      "Epoch 92/200\n",
      "5838/5838 [==============================] - 5s 861us/step - loss: 0.3495 - accuracy: 0.7684\n",
      "Epoch 93/200\n",
      "5838/5838 [==============================] - 5s 860us/step - loss: 0.3489 - accuracy: 0.7685\n",
      "Epoch 94/200\n",
      "5838/5838 [==============================] - 5s 860us/step - loss: 0.3490 - accuracy: 0.7684\n",
      "Epoch 95/200\n",
      "5838/5838 [==============================] - 5s 864us/step - loss: 0.3485 - accuracy: 0.7678\n",
      "Epoch 96/200\n",
      "5838/5838 [==============================] - 5s 857us/step - loss: 0.3482 - accuracy: 0.7681\n",
      "Epoch 97/200\n",
      "5838/5838 [==============================] - 5s 856us/step - loss: 0.3478 - accuracy: 0.7688\n",
      "Epoch 98/200\n",
      "5838/5838 [==============================] - 5s 851us/step - loss: 0.3483 - accuracy: 0.7678\n",
      "Epoch 99/200\n",
      "5838/5838 [==============================] - 5s 858us/step - loss: 0.3476 - accuracy: 0.7690\n",
      "Epoch 100/200\n",
      "5838/5838 [==============================] - 5s 862us/step - loss: 0.3474 - accuracy: 0.7693\n",
      "Epoch 101/200\n",
      "5838/5838 [==============================] - 5s 860us/step - loss: 0.3474 - accuracy: 0.7688\n",
      "Epoch 102/200\n",
      "5838/5838 [==============================] - 5s 846us/step - loss: 0.3473 - accuracy: 0.7688\n",
      "Epoch 103/200\n",
      "5838/5838 [==============================] - 5s 856us/step - loss: 0.3470 - accuracy: 0.7686\n",
      "Epoch 104/200\n",
      "5838/5838 [==============================] - 5s 864us/step - loss: 0.3467 - accuracy: 0.7692\n",
      "Epoch 105/200\n",
      "5838/5838 [==============================] - 5s 870us/step - loss: 0.3466 - accuracy: 0.76940s - loss: 0.3460 \n",
      "Epoch 106/200\n",
      "5838/5838 [==============================] - 5s 863us/step - loss: 0.3463 - accuracy: 0.7697\n",
      "Epoch 107/200\n",
      "5838/5838 [==============================] - 5s 848us/step - loss: 0.3465 - accuracy: 0.7700\n",
      "Epoch 108/200\n",
      "5838/5838 [==============================] - 5s 854us/step - loss: 0.3457 - accuracy: 0.7696\n",
      "Epoch 109/200\n",
      "5838/5838 [==============================] - 5s 853us/step - loss: 0.3461 - accuracy: 0.7692\n",
      "Epoch 110/200\n",
      "5838/5838 [==============================] - 5s 856us/step - loss: 0.3456 - accuracy: 0.7692\n",
      "Epoch 111/200\n",
      "5838/5838 [==============================] - 5s 863us/step - loss: 0.3458 - accuracy: 0.7694\n",
      "Epoch 112/200\n",
      "5838/5838 [==============================] - 5s 845us/step - loss: 0.3454 - accuracy: 0.7694\n",
      "Epoch 113/200\n",
      "5838/5838 [==============================] - 5s 864us/step - loss: 0.3451 - accuracy: 0.7699\n",
      "Epoch 114/200\n",
      "5838/5838 [==============================] - 5s 856us/step - loss: 0.3452 - accuracy: 0.7695\n",
      "Epoch 115/200\n",
      "5838/5838 [==============================] - 5s 857us/step - loss: 0.3447 - accuracy: 0.76980s - loss: 0.3452 - accuracy: \n",
      "Epoch 116/200\n",
      "5838/5838 [==============================] - 5s 852us/step - loss: 0.3448 - accuracy: 0.7698\n",
      "Epoch 117/200\n",
      "5838/5838 [==============================] - 5s 852us/step - loss: 0.3447 - accuracy: 0.7703\n",
      "Epoch 118/200\n",
      "5838/5838 [==============================] - 5s 865us/step - loss: 0.3443 - accuracy: 0.7701\n",
      "Epoch 119/200\n",
      "5838/5838 [==============================] - 5s 850us/step - loss: 0.3446 - accuracy: 0.76940s - loss: 0.3448 \n",
      "Epoch 120/200\n",
      "5838/5838 [==============================] - 5s 867us/step - loss: 0.3439 - accuracy: 0.7701\n",
      "Epoch 121/200\n",
      "5838/5838 [==============================] - 5s 868us/step - loss: 0.3442 - accuracy: 0.7700\n",
      "Epoch 122/200\n",
      "5838/5838 [==============================] - 5s 877us/step - loss: 0.3442 - accuracy: 0.7700\n",
      "Epoch 123/200\n",
      "5838/5838 [==============================] - 5s 839us/step - loss: 0.3435 - accuracy: 0.7701\n",
      "Epoch 124/200\n",
      "5838/5838 [==============================] - 6s 946us/step - loss: 0.3433 - accuracy: 0.7710\n",
      "Epoch 125/200\n",
      "5838/5838 [==============================] - 6s 966us/step - loss: 0.3433 - accuracy: 0.77070s - loss: 0.3437 - accuracy: 0. - ETA: 0s -\n",
      "Epoch 126/200\n",
      "5838/5838 [==============================] - 6s 977us/step - loss: 0.3435 - accuracy: 0.7702 - ETA: 0s - loss: 0.3428 - accu\n",
      "Epoch 127/200\n",
      "5838/5838 [==============================] - 6s 965us/step - loss: 0.3430 - accuracy: 0.7709\n",
      "Epoch 128/200\n",
      "5838/5838 [==============================] - 6s 982us/step - loss: 0.3430 - accuracy: 0.77052s - - ETA: 0s - loss: 0.3433 - accura\n",
      "Epoch 129/200\n",
      "5838/5838 [==============================] - 6s 984us/step - loss: 0.3429 - accuracy: 0.7706\n",
      "Epoch 130/200\n",
      "5838/5838 [==============================] - 6s 971us/step - loss: 0.3425 - accuracy: 0.7701\n",
      "Epoch 131/200\n",
      "5838/5838 [==============================] - 6s 965us/step - loss: 0.3425 - accuracy: 0.77071s - loss: 0.3425 - accu - ETA: 0s - l\n",
      "Epoch 132/200\n",
      "5838/5838 [==============================] - 5s 850us/step - loss: 0.3423 - accuracy: 0.7711\n",
      "Epoch 133/200\n",
      "5838/5838 [==============================] - 5s 861us/step - loss: 0.3421 - accuracy: 0.77050s - los\n",
      "Epoch 134/200\n",
      "5838/5838 [==============================] - 5s 885us/step - loss: 0.3421 - accuracy: 0.7699\n",
      "Epoch 135/200\n",
      "5838/5838 [==============================] - 5s 851us/step - loss: 0.3417 - accuracy: 0.77050s - loss: 0.3420 - accu\n",
      "Epoch 136/200\n",
      "5838/5838 [==============================] - 5s 849us/step - loss: 0.3416 - accuracy: 0.77080s - loss: 0.3416 - accuracy: 0.77\n",
      "Epoch 137/200\n",
      "5838/5838 [==============================] - 5s 835us/step - loss: 0.3413 - accuracy: 0.77040s\n",
      "Epoch 138/200\n",
      "5838/5838 [==============================] - 5s 862us/step - loss: 0.3414 - accuracy: 0.7701\n",
      "Epoch 139/200\n",
      "5838/5838 [==============================] - 5s 841us/step - loss: 0.3414 - accuracy: 0.77050s - loss: 0.3407 - ac\n",
      "Epoch 140/200\n",
      "5838/5838 [==============================] - 5s 860us/step - loss: 0.3412 - accuracy: 0.7711\n",
      "Epoch 141/200\n",
      "5838/5838 [==============================] - 5s 860us/step - loss: 0.3410 - accuracy: 0.7712\n",
      "Epoch 142/200\n",
      "5838/5838 [==============================] - 5s 864us/step - loss: 0.3403 - accuracy: 0.7713\n",
      "Epoch 143/200\n",
      "5838/5838 [==============================] - 5s 845us/step - loss: 0.3409 - accuracy: 0.7706\n",
      "Epoch 144/200\n",
      "5838/5838 [==============================] - 5s 849us/step - loss: 0.3405 - accuracy: 0.7717\n",
      "Epoch 145/200\n",
      "5838/5838 [==============================] - 5s 831us/step - loss: 0.3411 - accuracy: 0.7701\n"
     ]
    }
   ],
   "source": [
    "nn8.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "fit_model = nn8.fit(X_train_scaled,y_train, batch_size = 32, epochs=200, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "983897e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1946/1946 - 1s - loss: 0.4287 - accuracy: 0.7499\n",
      "Loss: 0.4287489056587219, Accuracy: 0.7498514652252197\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn8.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eee5ef",
   "metadata": {},
   "source": [
    "## Attempt 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1691d483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_012</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_012  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0           0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1           0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2           0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3           0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4           0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                   0.0           0.0     0.0  ...            1.0   \n",
       "1                   0.0           1.0     0.0  ...            0.0   \n",
       "2                   0.0           0.0     1.0  ...            1.0   \n",
       "3                   0.0           1.0     1.0  ...            1.0   \n",
       "4                   0.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
       "0          0.0      5.0      18.0      15.0       1.0  0.0   9.0        4.0   \n",
       "1          1.0      3.0       0.0       0.0       0.0  0.0   7.0        6.0   \n",
       "2          1.0      5.0      30.0      30.0       1.0  0.0   9.0        4.0   \n",
       "3          0.0      2.0       0.0       0.0       0.0  0.0  11.0        3.0   \n",
       "4          0.0      2.0       3.0       0.0       0.0  0.0  11.0        5.0   \n",
       "\n",
       "   Income  \n",
       "0     3.0  \n",
       "1     1.0  \n",
       "2     8.0  \n",
       "3     6.0  \n",
       "4     4.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_pre = df[df[\"Diabetes_012\"] != 1]\n",
    "df_no_pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "337a3af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = df_no_pre[\"Diabetes_012\"].values\n",
    "X = df_no_pre.drop(columns=['Diabetes_012']).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4e3da99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 120)               2640      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 50)                6050      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 30)                1530      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 10,251\n",
      "Trainable params: 10,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 120\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 30\n",
    "nn9 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn9.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# Second hidden layer\n",
    "nn9.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# Third hidden layer\n",
    "nn9.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# Output layer\n",
    "nn9.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn9.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0e62bc81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "11675/11675 [==============================] - 10s 826us/step - loss: 0.3941 - accuracy: 0.7340\n",
      "Epoch 2/200\n",
      "11675/11675 [==============================] - 10s 838us/step - loss: 0.3908 - accuracy: 0.7383\n",
      "Epoch 3/200\n",
      "11675/11675 [==============================] - 10s 826us/step - loss: 0.3897 - accuracy: 0.7405\n",
      "Epoch 4/200\n",
      "11675/11675 [==============================] - 9s 808us/step - loss: 0.3890 - accuracy: 0.7418\n",
      "Epoch 5/200\n",
      "11675/11675 [==============================] - 10s 820us/step - loss: 0.3886 - accuracy: 0.7414\n",
      "Epoch 6/200\n",
      "11675/11675 [==============================] - 10s 816us/step - loss: 0.3879 - accuracy: 0.7392\n",
      "Epoch 7/200\n",
      "11675/11675 [==============================] - 10s 836us/step - loss: 0.3876 - accuracy: 0.7433\n",
      "Epoch 8/200\n",
      "11675/11675 [==============================] - 10s 823us/step - loss: 0.3872 - accuracy: 0.7423\n",
      "Epoch 9/200\n",
      "11675/11675 [==============================] - 10s 820us/step - loss: 0.3866 - accuracy: 0.7416\n",
      "Epoch 10/200\n",
      "11675/11675 [==============================] - 10s 834us/step - loss: 0.3864 - accuracy: 0.7395s - los - ETA: 0s - loss: 0.3\n",
      "Epoch 11/200\n",
      "11675/11675 [==============================] - 10s 822us/step - loss: 0.3859 - accuracy: 0.7418\n",
      "Epoch 12/200\n",
      "11675/11675 [==============================] - 10s 817us/step - loss: 0.3855 - accuracy: 0.7436s - loss: 0.384\n",
      "Epoch 13/200\n",
      "11675/11675 [==============================] - 9s 813us/step - loss: 0.3852 - accuracy: 0.7435\n",
      "Epoch 14/200\n",
      "11675/11675 [==============================] - 10s 832us/step - loss: 0.3846 - accuracy: 0.7436\n",
      "Epoch 15/200\n",
      "11675/11675 [==============================] - 10s 817us/step - loss: 0.3843 - accuracy: 0.7447\n",
      "Epoch 16/200\n",
      "11675/11675 [==============================] - 10s 822us/step - loss: 0.3837 - accuracy: 0.7445\n",
      "Epoch 17/200\n",
      "11675/11675 [==============================] - 9s 811us/step - loss: 0.3833 - accuracy: 0.7451\n",
      "Epoch 18/200\n",
      "11675/11675 [==============================] - 10s 820us/step - loss: 0.3828 - accuracy: 0.7469\n",
      "Epoch 19/200\n",
      "11675/11675 [==============================] - 10s 831us/step - loss: 0.3822 - accuracy: 0.7462\n",
      "Epoch 20/200\n",
      "11675/11675 [==============================] - 10s 853us/step - loss: 0.3819 - accuracy: 0.7483\n",
      "Epoch 21/200\n",
      "11675/11675 [==============================] - 10s 827us/step - loss: 0.3814 - accuracy: 0.7470s - loss: 0\n",
      "Epoch 22/200\n",
      "11675/11675 [==============================] - ETA: 0s - loss: 0.3809 - accuracy: 0.74 - 10s 817us/step - loss: 0.3808 - accuracy: 0.7489\n",
      "Epoch 23/200\n",
      "11675/11675 [==============================] - 10s 818us/step - loss: 0.3803 - accuracy: 0.7498\n",
      "Epoch 24/200\n",
      "11675/11675 [==============================] - 10s 814us/step - loss: 0.3798 - accuracy: 0.7496s - loss: 0.3797 - accuracy: 0.74\n",
      "Epoch 25/200\n",
      "11675/11675 [==============================] - 10s 818us/step - loss: 0.3793 - accuracy: 0.7496\n",
      "Epoch 26/200\n",
      "11675/11675 [==============================] - 10s 834us/step - loss: 0.3784 - accuracy: 0.7519\n",
      "Epoch 27/200\n",
      "11675/11675 [==============================] - 10s 829us/step - loss: 0.3782 - accuracy: 0.7521\n",
      "Epoch 28/200\n",
      "11675/11675 [==============================] - 10s 820us/step - loss: 0.3774 - accuracy: 0.7522\n",
      "Epoch 29/200\n",
      "11675/11675 [==============================] - 10s 820us/step - loss: 0.3771 - accuracy: 0.7536s - loss: 0.3767 - \n",
      "Epoch 30/200\n",
      "11675/11675 [==============================] - 10s 819us/step - loss: 0.3762 - accuracy: 0.7520\n",
      "Epoch 31/200\n",
      "11675/11675 [==============================] - 9s 813us/step - loss: 0.3757 - accuracy: 0.75410s - loss: 0.3757 \n",
      "Epoch 32/200\n",
      "11675/11675 [==============================] - 10s 818us/step - loss: 0.3754 - accuracy: 0.7543\n",
      "Epoch 33/200\n",
      "11675/11675 [==============================] - 10s 817us/step - loss: 0.3750 - accuracy: 0.7559\n",
      "Epoch 34/200\n",
      "11675/11675 [==============================] - 10s 816us/step - loss: 0.3745 - accuracy: 0.7557\n",
      "Epoch 35/200\n",
      "11675/11675 [==============================] - 10s 818us/step - loss: 0.3738 - accuracy: 0.7553\n",
      "Epoch 36/200\n",
      "11675/11675 [==============================] - 9s 811us/step - loss: 0.3735 - accuracy: 0.7559\n",
      "Epoch 37/200\n",
      "11675/11675 [==============================] - 10s 823us/step - loss: 0.3729 - accuracy: 0.7554\n",
      "Epoch 38/200\n",
      "11675/11675 [==============================] - 10s 872us/step - loss: 0.3725 - accuracy: 0.7565\n",
      "Epoch 39/200\n",
      "11675/11675 [==============================] - 10s 839us/step - loss: 0.3717 - accuracy: 0.7579\n",
      "Epoch 40/200\n",
      "11675/11675 [==============================] - 10s 823us/step - loss: 0.3714 - accuracy: 0.7583\n",
      "Epoch 41/200\n",
      "11675/11675 [==============================] - 10s 817us/step - loss: 0.3708 - accuracy: 0.7585\n",
      "Epoch 42/200\n",
      "11675/11675 [==============================] - 10s 823us/step - loss: 0.3709 - accuracy: 0.7586\n",
      "Epoch 43/200\n",
      "11675/11675 [==============================] - 10s 818us/step - loss: 0.3700 - accuracy: 0.7590\n",
      "Epoch 44/200\n",
      "11675/11675 [==============================] - 10s 816us/step - loss: 0.3698 - accuracy: 0.7589\n",
      "Epoch 45/200\n",
      "11675/11675 [==============================] - 10s 823us/step - loss: 0.3689 - accuracy: 0.7596\n",
      "Epoch 46/200\n",
      "11675/11675 [==============================] - 10s 821us/step - loss: 0.3686 - accuracy: 0.7605\n",
      "Epoch 47/200\n",
      "11675/11675 [==============================] - 10s 833us/step - loss: 0.3685 - accuracy: 0.7594\n",
      "Epoch 48/200\n",
      "11675/11675 [==============================] - 10s 815us/step - loss: 0.3682 - accuracy: 0.7605\n",
      "Epoch 49/200\n",
      "11675/11675 [==============================] - 10s 820us/step - loss: 0.3678 - accuracy: 0.7603s - loss:\n",
      "Epoch 50/200\n",
      "11675/11675 [==============================] - 10s 825us/step - loss: 0.3673 - accuracy: 0.7609\n",
      "Epoch 51/200\n",
      "11675/11675 [==============================] - 10s 821us/step - loss: 0.3669 - accuracy: 0.7602\n",
      "Epoch 52/200\n",
      "11675/11675 [==============================] - 10s 820us/step - loss: 0.3664 - accuracy: 0.7613\n",
      "Epoch 53/200\n",
      "11675/11675 [==============================] - 10s 828us/step - loss: 0.3661 - accuracy: 0.7612\n",
      "Epoch 54/200\n",
      "11675/11675 [==============================] - 10s 824us/step - loss: 0.3658 - accuracy: 0.7611\n",
      "Epoch 55/200\n",
      "11675/11675 [==============================] - 10s 893us/step - loss: 0.3653 - accuracy: 0.7619\n",
      "Epoch 56/200\n",
      "11675/11675 [==============================] - 11s 925us/step - loss: 0.3653 - accuracy: 0.7620\n",
      "Epoch 57/200\n",
      "11675/11675 [==============================] - 11s 915us/step - loss: 0.3647 - accuracy: 0.7615\n",
      "Epoch 58/200\n",
      "11675/11675 [==============================] - 11s 900us/step - loss: 0.3644 - accuracy: 0.7623s - loss: 0.3645 - ac\n",
      "Epoch 59/200\n",
      "11675/11675 [==============================] - 11s 928us/step - loss: 0.3644 - accuracy: 0.7624\n",
      "Epoch 60/200\n",
      "11675/11675 [==============================] - 11s 937us/step - loss: 0.3642 - accuracy: 0.7624\n",
      "Epoch 61/200\n",
      "11675/11675 [==============================] - 11s 925us/step - loss: 0.3637 - accuracy: 0.7625s - loss: 0.3637 - accuracy: 0.76\n",
      "Epoch 62/200\n",
      "11675/11675 [==============================] - 11s 923us/step - loss: 0.3632 - accuracy: 0.7628s - loss: 0.3641 \n",
      "Epoch 63/200\n",
      "11675/11675 [==============================] - 11s 932us/step - loss: 0.3628 - accuracy: 0.7636\n",
      "Epoch 64/200\n",
      "11675/11675 [==============================] - 11s 927us/step - loss: 0.3624 - accuracy: 0.7639s - loss: 0.3624 \n",
      "Epoch 65/200\n",
      "11675/11675 [==============================] - 11s 920us/step - loss: 0.3623 - accuracy: 0.7641\n",
      "Epoch 66/200\n",
      "11675/11675 [==============================] - 11s 918us/step - loss: 0.3615 - accuracy: 0.7648\n",
      "Epoch 67/200\n",
      "11675/11675 [==============================] - 11s 919us/step - loss: 0.3616 - accuracy: 0.7640\n",
      "Epoch 68/200\n",
      "11675/11675 [==============================] - 11s 923us/step - loss: 0.3612 - accuracy: 0.7641\n",
      "Epoch 69/200\n",
      "11675/11675 [==============================] - 11s 922us/step - loss: 0.3610 - accuracy: 0.7638s - loss: 0.360 - ETA: 0s - loss: 0.3611 - accuracy: \n",
      "Epoch 70/200\n",
      "11675/11675 [==============================] - 11s 921us/step - loss: 0.3607 - accuracy: 0.7650\n",
      "Epoch 71/200\n",
      "11675/11675 [==============================] - 11s 924us/step - loss: 0.3604 - accuracy: 0.7651\n",
      "Epoch 72/200\n",
      "11675/11675 [==============================] - 11s 924us/step - loss: 0.3605 - accuracy: 0.7643\n",
      "Epoch 73/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11675/11675 [==============================] - 11s 914us/step - loss: 0.3599 - accuracy: 0.7646\n",
      "Epoch 74/200\n",
      "11675/11675 [==============================] - 11s 914us/step - loss: 0.3596 - accuracy: 0.7645\n",
      "Epoch 75/200\n",
      "11675/11675 [==============================] - 11s 921us/step - loss: 0.3595 - accuracy: 0.7646\n",
      "Epoch 76/200\n",
      "11675/11675 [==============================] - 11s 913us/step - loss: 0.3590 - accuracy: 0.7653\n",
      "Epoch 77/200\n",
      "11675/11675 [==============================] - 11s 910us/step - loss: 0.3589 - accuracy: 0.7656\n",
      "Epoch 78/200\n",
      "11675/11675 [==============================] - 11s 916us/step - loss: 0.3579 - accuracy: 0.7663\n",
      "Epoch 79/200\n",
      "11675/11675 [==============================] - 11s 913us/step - loss: 0.3582 - accuracy: 0.7659\n",
      "Epoch 80/200\n",
      "11675/11675 [==============================] - 11s 906us/step - loss: 0.3585 - accuracy: 0.7663\n",
      "Epoch 81/200\n",
      "11675/11675 [==============================] - 10s 891us/step - loss: 0.3579 - accuracy: 0.7653s - loss: 0\n",
      "Epoch 82/200\n",
      "11675/11675 [==============================] - 11s 910us/step - loss: 0.3581 - accuracy: 0.7657\n",
      "Epoch 83/200\n",
      "11675/11675 [==============================] - 11s 931us/step - loss: 0.3575 - accuracy: 0.7655s - loss: 0.3576 - accura\n",
      "Epoch 84/200\n",
      "11675/11675 [==============================] - 11s 912us/step - loss: 0.3575 - accuracy: 0.7651\n",
      "Epoch 85/200\n",
      "11675/11675 [==============================] - 11s 932us/step - loss: 0.3571 - accuracy: 0.7662\n",
      "Epoch 86/200\n",
      "11675/11675 [==============================] - 11s 916us/step - loss: 0.3569 - accuracy: 0.7666\n",
      "Epoch 87/200\n",
      "11675/11675 [==============================] - 11s 916us/step - loss: 0.3566 - accuracy: 0.7673s - loss: 0.3559 - accuracy:  - ETA\n",
      "Epoch 88/200\n",
      "11675/11675 [==============================] - 11s 919us/step - loss: 0.3562 - accuracy: 0.7664\n",
      "Epoch 89/200\n",
      "11675/11675 [==============================] - 11s 919us/step - loss: 0.3563 - accuracy: 0.7660s - loss:\n",
      "Epoch 90/200\n",
      "11675/11675 [==============================] - 11s 920us/step - loss: 0.3559 - accuracy: 0.7670\n",
      "Epoch 91/200\n",
      "11675/11675 [==============================] - 11s 924us/step - loss: 0.3557 - accuracy: 0.7664\n",
      "Epoch 92/200\n",
      "11675/11675 [==============================] - 11s 923us/step - loss: 0.3557 - accuracy: 0.7662\n",
      "Epoch 93/200\n",
      "11675/11675 [==============================] - 11s 921us/step - loss: 0.3551 - accuracy: 0.7670\n",
      "Epoch 94/200\n",
      "11675/11675 [==============================] - 11s 919us/step - loss: 0.3550 - accuracy: 0.7672\n",
      "Epoch 95/200\n",
      "11675/11675 [==============================] - 11s 919us/step - loss: 0.3552 - accuracy: 0.7661\n",
      "Epoch 96/200\n",
      "11675/11675 [==============================] - 11s 922us/step - loss: 0.3549 - accuracy: 0.7671\n",
      "Epoch 97/200\n",
      "11675/11675 [==============================] - 11s 922us/step - loss: 0.3545 - accuracy: 0.7668\n",
      "Epoch 98/200\n",
      "11675/11675 [==============================] - 11s 922us/step - loss: 0.3542 - accuracy: 0.7669\n",
      "Epoch 99/200\n",
      "11675/11675 [==============================] - 11s 927us/step - loss: 0.3541 - accuracy: 0.7685\n",
      "Epoch 100/200\n",
      "11675/11675 [==============================] - 11s 917us/step - loss: 0.3545 - accuracy: 0.7670\n",
      "Epoch 101/200\n",
      "11675/11675 [==============================] - 11s 918us/step - loss: 0.3539 - accuracy: 0.7670\n",
      "Epoch 102/200\n",
      "11675/11675 [==============================] - 11s 917us/step - loss: 0.3532 - accuracy: 0.7672\n",
      "Epoch 103/200\n",
      "11675/11675 [==============================] - 11s 921us/step - loss: 0.3535 - accuracy: 0.7673\n",
      "Epoch 104/200\n",
      "11675/11675 [==============================] - 11s 930us/step - loss: 0.3530 - accuracy: 0.7674\n",
      "Epoch 105/200\n",
      "11675/11675 [==============================] - 11s 924us/step - loss: 0.3533 - accuracy: 0.7680\n",
      "Epoch 106/200\n",
      "11675/11675 [==============================] - 11s 930us/step - loss: 0.3531 - accuracy: 0.7679\n",
      "Epoch 107/200\n",
      "11675/11675 [==============================] - 11s 924us/step - loss: 0.3525 - accuracy: 0.7676\n",
      "Epoch 108/200\n",
      "11675/11675 [==============================] - 11s 924us/step - loss: 0.3533 - accuracy: 0.7676\n",
      "Epoch 109/200\n",
      "11675/11675 [==============================] - 11s 919us/step - loss: 0.3522 - accuracy: 0.7671ETA: 0s - loss: 0.3521 - accuracy: \n",
      "Epoch 110/200\n",
      "11675/11675 [==============================] - 11s 920us/step - loss: 0.3523 - accuracy: 0.7678s - loss: 0.3523 - accuracy: \n",
      "Epoch 111/200\n",
      "11675/11675 [==============================] - 11s 925us/step - loss: 0.3520 - accuracy: 0.7681\n",
      "Epoch 112/200\n",
      "11675/11675 [==============================] - 11s 926us/step - loss: 0.3519 - accuracy: 0.7682\n",
      "Epoch 113/200\n",
      "11675/11675 [==============================] - 11s 924us/step - loss: 0.3523 - accuracy: 0.7678\n",
      "Epoch 114/200\n",
      "11675/11675 [==============================] - 11s 926us/step - loss: 0.3518 - accuracy: 0.7684\n",
      "Epoch 115/200\n",
      "11675/11675 [==============================] - 11s 916us/step - loss: 0.3515 - accuracy: 0.7676s - loss: 0.3516 \n",
      "Epoch 116/200\n",
      "11675/11675 [==============================] - 11s 929us/step - loss: 0.3515 - accuracy: 0.7681\n",
      "Epoch 117/200\n",
      "11675/11675 [==============================] - 11s 948us/step - loss: 0.3511 - accuracy: 0.7682\n",
      "Epoch 118/200\n",
      "11675/11675 [==============================] - 11s 939us/step - loss: 0.3512 - accuracy: 0.7681\n",
      "Epoch 119/200\n",
      "11675/11675 [==============================] - 11s 938us/step - loss: 0.3513 - accuracy: 0.7678s - loss: 0.3513 - accuracy: \n",
      "Epoch 120/200\n",
      "11675/11675 [==============================] - 11s 931us/step - loss: 0.3505 - accuracy: 0.7687s - loss: 0 - ETA: 0s - loss: 0.3502 - \n",
      "Epoch 121/200\n",
      "11675/11675 [==============================] - 11s 930us/step - loss: 0.3507 - accuracy: 0.7683s\n",
      "Epoch 122/200\n",
      "11675/11675 [==============================] - 11s 932us/step - loss: 0.3505 - accuracy: 0.7685\n",
      "Epoch 123/200\n",
      "11675/11675 [==============================] - ETA: 0s - loss: 0.3508 - accuracy: 0.76 - 11s 934us/step - loss: 0.3506 - accuracy: 0.7684\n"
     ]
    }
   ],
   "source": [
    "nn9.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "fit_model = nn9.fit(X_train_scaled,y_train, batch_size = 16, epochs=200, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fe374560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1946/1946 - 1s - loss: 0.4287 - accuracy: 0.7499\n",
      "Loss: 0.4287489056587219, Accuracy: 0.7498514652252197\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn8.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4045041",
   "metadata": {},
   "source": [
    "## Attempt 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7ebae010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = df_no_pre[\"Diabetes_012\"].values\n",
    "X = df_no_pre.drop(columns=['Diabetes_012']).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b5b79505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 120)               2640      \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 50)                6050      \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 30)                1530      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 10,251\n",
      "Trainable params: 10,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 120\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 30\n",
    "nn10 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn10.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# Second hidden layer\n",
    "nn10.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# Third hidden layer\n",
    "nn10.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# Output layer\n",
    "nn10.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5945c82a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "23349/23349 [==============================] - 22s 916us/step - loss: 0.3944 - accuracy: 0.7378\n",
      "Epoch 2/200\n",
      "23349/23349 [==============================] - 22s 923us/step - loss: 0.3910 - accuracy: 0.7443s - loss: 0.3911 - accu - E - ETA: 0s - loss: 0.3908 - accuracy: \n",
      "Epoch 3/200\n",
      "23349/23349 [==============================] - 21s 918us/step - loss: 0.3899 - accuracy: 0.7424\n",
      "Epoch 4/200\n",
      "23349/23349 [==============================] - 22s 925us/step - loss: 0.3896 - accuracy: 0.7408\n",
      "Epoch 5/200\n",
      "23349/23349 [==============================] - 22s 941us/step - loss: 0.3891 - accuracy: 0.7425\n",
      "Epoch 6/200\n",
      "23349/23349 [==============================] - 22s 949us/step - loss: 0.3885 - accuracy: 0.7429\n",
      "Epoch 7/200\n",
      "23349/23349 [==============================] - 22s 926us/step - loss: 0.3882 - accuracy: 0.7448\n",
      "Epoch 8/200\n",
      "23349/23349 [==============================] - ETA: 0s - loss: 0.3876 - accuracy: 0.7432 ETA: 0s - loss: 0.3875 - accura - 21s 917us/step - loss: 0.3877 - accuracy: 0.7432\n",
      "Epoch 9/200\n",
      "23349/23349 [==============================] - 21s 919us/step - loss: 0.3874 - accuracy: 0.7463\n",
      "Epoch 10/200\n",
      "23349/23349 [==============================] - 22s 922us/step - loss: 0.3874 - accuracy: 0.7452\n",
      "Epoch 11/200\n",
      "23349/23349 [==============================] - 21s 919us/step - loss: 0.3868 - accuracy: 0.7468\n",
      "Epoch 12/200\n",
      "23349/23349 [==============================] - 21s 916us/step - loss: 0.3864 - accuracy: 0.7456\n",
      "Epoch 13/200\n",
      "23349/23349 [==============================] - 22s 922us/step - loss: 0.3863 - accuracy: 0.7473\n",
      "Epoch 14/200\n",
      "23349/23349 [==============================] - 21s 919us/step - loss: 0.3861 - accuracy: 0.7466\n",
      "Epoch 15/200\n",
      "23349/23349 [==============================] - 21s 919us/step - loss: 0.3858 - accuracy: 0.7477s - loss: 0.3858 - accuracy: 0.74\n",
      "Epoch 16/200\n",
      "23349/23349 [==============================] - 22s 922us/step - loss: 0.3854 - accuracy: 0.7467s - loss: 0.3855 - ac\n",
      "Epoch 17/200\n",
      "23349/23349 [==============================] - 21s 921us/step - loss: 0.3851 - accuracy: 0.7486\n",
      "Epoch 18/200\n",
      "23349/23349 [==============================] - 21s 918us/step - loss: 0.3849 - accuracy: 0.7478\n",
      "Epoch 19/200\n",
      "23349/23349 [==============================] - 22s 929us/step - loss: 0.3844 - accuracy: 0.7495\n",
      "Epoch 20/200\n",
      "23349/23349 [==============================] - 22s 923us/step - loss: 0.3841 - accuracy: 0.7484s - loss: 0.3841 - accura\n",
      "Epoch 21/200\n",
      "23349/23349 [==============================] - 22s 926us/step - loss: 0.3838 - accuracy: 0.7495s - loss: 0.3838 - accuracy\n",
      "Epoch 22/200\n",
      "23349/23349 [==============================] - 21s 920us/step - loss: 0.3838 - accuracy: 0.7508\n",
      "Epoch 23/200\n",
      "23349/23349 [==============================] - 21s 920us/step - loss: 0.3832 - accuracy: 0.7524- ETA: 0s - loss: 0.3831 - accuracy\n",
      "Epoch 24/200\n",
      "23349/23349 [==============================] - 22s 926us/step - loss: 0.3827 - accuracy: 0.7542\n",
      "Epoch 25/200\n",
      "23349/23349 [==============================] - 22s 926us/step - loss: 0.3825 - accuracy: 0.7528\n",
      "Epoch 26/200\n",
      "23349/23349 [==============================] - ETA: 0s - loss: 0.3824 - accuracy: 0.7520 ETA: 0s - loss: 0.3823 -  - 22s 923us/step - loss: 0.3824 - accuracy: 0.7521\n",
      "Epoch 27/200\n",
      "23349/23349 [==============================] - 21s 920us/step - loss: 0.3819 - accuracy: 0.7546\n",
      "Epoch 28/200\n",
      "23349/23349 [==============================] - 22s 937us/step - loss: 0.3815 - accuracy: 0.7547s - los\n",
      "Epoch 29/200\n",
      "23349/23349 [==============================] - 21s 918us/step - loss: 0.3814 - accuracy: 0.7561s - loss:\n",
      "Epoch 30/200\n",
      "23349/23349 [==============================] - 22s 927us/step - loss: 0.3806 - accuracy: 0.7569s - loss: 0.3807 - accuracy - ETA: 0s - loss: 0.380\n",
      "Epoch 31/200\n",
      "23349/23349 [==============================] - 22s 941us/step - loss: 0.3807 - accuracy: 0.7553\n",
      "Epoch 32/200\n",
      "23349/23349 [==============================] - 23s 991us/step - loss: 0.3802 - accuracy: 0.7566\n",
      "Epoch 33/200\n",
      "23349/23349 [==============================] - 21s 915us/step - loss: 0.3799 - accuracy: 0.7559s - loss: 0.3802 - ac\n",
      "Epoch 34/200\n",
      "23349/23349 [==============================] - 22s 931us/step - loss: 0.3797 - accuracy: 0.7579s - loss: 0.3794 - accu\n",
      "Epoch 35/200\n",
      "23349/23349 [==============================] - 21s 911us/step - loss: 0.3797 - accuracy: 0.7558\n",
      "Epoch 36/200\n",
      "23349/23349 [==============================] - 20s 867us/step - loss: 0.3792 - accuracy: 0.7564\n",
      "Epoch 37/200\n",
      "23349/23349 [==============================] - 20s 868us/step - loss: 0.3789 - accuracy: 0.7584s\n",
      "Epoch 38/200\n",
      "23349/23349 [==============================] - 21s 888us/step - loss: 0.3783 - accuracy: 0.7577\n",
      "Epoch 39/200\n",
      "23349/23349 [==============================] - 21s 899us/step - loss: 0.3782 - accuracy: 0.7583\n",
      "Epoch 40/200\n",
      "23349/23349 [==============================] - 21s 887us/step - loss: 0.3780 - accuracy: 0.7578\n",
      "Epoch 41/200\n",
      "23349/23349 [==============================] - 20s 870us/step - loss: 0.3775 - accuracy: 0.7586\n",
      "Epoch 42/200\n",
      "23349/23349 [==============================] - 21s 899us/step - loss: 0.3770 - accuracy: 0.7596\n",
      "Epoch 43/200\n",
      "23349/23349 [==============================] - 22s 948us/step - loss: 0.3767 - accuracy: 0.7598\n",
      "Epoch 44/200\n",
      "23349/23349 [==============================] - 20s 857us/step - loss: 0.3762 - accuracy: 0.7591\n",
      "Epoch 45/200\n",
      "23349/23349 [==============================] - 24s 1ms/step - loss: 0.3757 - accuracy: 0.7603\n",
      "Epoch 46/200\n",
      "23349/23349 [==============================] - 20s 869us/step - loss: 0.3759 - accuracy: 0.7601\n",
      "Epoch 47/200\n",
      "23349/23349 [==============================] - 19s 831us/step - loss: 0.3752 - accuracy: 0.7606\n",
      "Epoch 48/200\n",
      "23349/23349 [==============================] - 20s 850us/step - loss: 0.3752 - accuracy: 0.7600\n",
      "Epoch 49/200\n",
      "23349/23349 [==============================] - 20s 861us/step - loss: 0.3746 - accuracy: 0.7595\n",
      "Epoch 50/200\n",
      "23349/23349 [==============================] - 22s 929us/step - loss: 0.3744 - accuracy: 0.7608\n",
      "Epoch 51/200\n",
      "23349/23349 [==============================] - 21s 913us/step - loss: 0.3740 - accuracy: 0.7611\n",
      "Epoch 52/200\n",
      "23349/23349 [==============================] - 22s 925us/step - loss: 0.3740 - accuracy: 0.7609s - loss: 0.3734 -  - ETA: 0s - loss:\n",
      "Epoch 53/200\n",
      "23349/23349 [==============================] - 21s 895us/step - loss: 0.3736 - accuracy: 0.7620\n",
      "Epoch 54/200\n",
      "23349/23349 [==============================] - 20s 858us/step - loss: 0.3733 - accuracy: 0.7617\n",
      "Epoch 55/200\n",
      "23349/23349 [==============================] - 21s 889us/step - loss: 0.3729 - accuracy: 0.7615\n",
      "Epoch 56/200\n",
      "23349/23349 [==============================] - 20s 844us/step - loss: 0.3727 - accuracy: 0.7613\n",
      "Epoch 57/200\n",
      "23349/23349 [==============================] - 20s 876us/step - loss: 0.3718 - accuracy: 0.7615\n",
      "Epoch 58/200\n",
      "23349/23349 [==============================] - 20s 836us/step - loss: 0.3720 - accuracy: 0.7625\n",
      "Epoch 59/200\n",
      "23349/23349 [==============================] - 20s 863us/step - loss: 0.3720 - accuracy: 0.7630\n",
      "Epoch 60/200\n",
      "23349/23349 [==============================] - 20s 848us/step - loss: 0.3716 - accuracy: 0.7628\n",
      "Epoch 61/200\n",
      "23349/23349 [==============================] - 20s 840us/step - loss: 0.3715 - accuracy: 0.7635\n",
      "Epoch 62/200\n",
      "23349/23349 [==============================] - 20s 863us/step - loss: 0.3712 - accuracy: 0.7637\n",
      "Epoch 63/200\n",
      "23349/23349 [==============================] - 20s 838us/step - loss: 0.3710 - accuracy: 0.7635\n",
      "Epoch 64/200\n",
      "23349/23349 [==============================] - 19s 831us/step - loss: 0.3706 - accuracy: 0.7640s - loss: 0.3708 - accuracy: 0.76\n",
      "Epoch 65/200\n",
      "23349/23349 [==============================] - 19s 830us/step - loss: 0.3704 - accuracy: 0.7638\n",
      "Epoch 66/200\n",
      "23349/23349 [==============================] - 20s 876us/step - loss: 0.3699 - accuracy: 0.7638\n",
      "Epoch 67/200\n",
      "23349/23349 [==============================] - 20s 861us/step - loss: 0.3698 - accuracy: 0.7642\n",
      "Epoch 68/200\n",
      "23349/23349 [==============================] - 20s 844us/step - loss: 0.3700 - accuracy: 0.7642\n",
      "Epoch 69/200\n",
      "23349/23349 [==============================] - 20s 859us/step - loss: 0.3695 - accuracy: 0.7645\n",
      "Epoch 70/200\n",
      "23349/23349 [==============================] - 20s 852us/step - loss: 0.3694 - accuracy: 0.7642\n",
      "Epoch 71/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23349/23349 [==============================] - 20s 861us/step - loss: 0.3693 - accuracy: 0.7651\n",
      "Epoch 72/200\n",
      "23349/23349 [==============================] - 19s 832us/step - loss: 0.3686 - accuracy: 0.7649\n",
      "Epoch 73/200\n",
      "23349/23349 [==============================] - 20s 853us/step - loss: 0.3685 - accuracy: 0.7642\n",
      "Epoch 74/200\n",
      "23349/23349 [==============================] - 20s 844us/step - loss: 0.3683 - accuracy: 0.7650\n",
      "Epoch 75/200\n",
      "23349/23349 [==============================] - 22s 922us/step - loss: 0.3678 - accuracy: 0.7654\n",
      "Epoch 76/200\n",
      "23349/23349 [==============================] - 22s 929us/step - loss: 0.3682 - accuracy: 0.7645\n",
      "Epoch 77/200\n",
      "23349/23349 [==============================] - 25s 1ms/step - loss: 0.3675 - accuracy: 0.7658\n",
      "Epoch 78/200\n",
      "23349/23349 [==============================] - 23s 966us/step - loss: 0.3671 - accuracy: 0.7651\n",
      "Epoch 79/200\n",
      "23349/23349 [==============================] - 21s 893us/step - loss: 0.3669 - accuracy: 0.7671\n",
      "Epoch 80/200\n",
      "23349/23349 [==============================] - 20s 835us/step - loss: 0.3669 - accuracy: 0.7667\n",
      "Epoch 81/200\n",
      "23349/23349 [==============================] - 20s 851us/step - loss: 0.3666 - accuracy: 0.7671\n",
      "Epoch 82/200\n",
      "23349/23349 [==============================] - 21s 916us/step - loss: 0.3667 - accuracy: 0.7682\n",
      "Epoch 83/200\n",
      "23349/23349 [==============================] - 20s 864us/step - loss: 0.3662 - accuracy: 0.7678\n",
      "Epoch 84/200\n",
      "23349/23349 [==============================] - 20s 852us/step - loss: 0.3667 - accuracy: 0.7673s - loss: 0.3666 - accura\n",
      "Epoch 85/200\n",
      "23349/23349 [==============================] - 20s 851us/step - loss: 0.3662 - accuracy: 0.7682s - loss: 0.3664 - accuracy\n",
      "Epoch 86/200\n",
      "23349/23349 [==============================] - 20s 877us/step - loss: 0.3663 - accuracy: 0.7682\n"
     ]
    }
   ],
   "source": [
    "nn10.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "fit_model = nn10.fit(X_train_scaled,y_train, batch_size = 8, epochs=200, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f52511f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1946/1946 - 1s - loss: 0.4287 - accuracy: 0.7499\n",
      "Loss: 0.4287489056587219, Accuracy: 0.7498514652252197\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn8.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa75bdd8",
   "metadata": {},
   "source": [
    "## Finding Columns to adjust to potentially improve training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "43b63b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes_012             2\n",
       "HighBP                   2\n",
       "HighChol                 2\n",
       "CholCheck                2\n",
       "BMI                     83\n",
       "Smoker                   2\n",
       "Stroke                   2\n",
       "HeartDiseaseorAttack     2\n",
       "PhysActivity             2\n",
       "Fruits                   2\n",
       "Veggies                  2\n",
       "HvyAlcoholConsump        2\n",
       "AnyHealthcare            2\n",
       "NoDocbcCost              2\n",
       "GenHlth                  5\n",
       "MentHlth                31\n",
       "PhysHlth                31\n",
       "DiffWalk                 2\n",
       "Sex                      2\n",
       "Age                     13\n",
       "Education                6\n",
       "Income                   8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_pre.nunique(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d9da26f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.0     11727\n",
       "29.0       155\n",
       "28.0       320\n",
       "27.0        78\n",
       "26.0        42\n",
       "25.0      1155\n",
       "24.0        31\n",
       "23.0        36\n",
       "22.0        61\n",
       "21.0       218\n",
       "20.0      3287\n",
       "19.0        16\n",
       "18.0        93\n",
       "17.0        53\n",
       "16.0        87\n",
       "15.0      5372\n",
       "14.0      1135\n",
       "13.0        41\n",
       "12.0       388\n",
       "11.0        39\n",
       "10.0      6234\n",
       "9.0         82\n",
       "8.0        626\n",
       "7.0       3037\n",
       "6.0        960\n",
       "5.0       8849\n",
       "4.0       3706\n",
       "3.0       7256\n",
       "2.0      12823\n",
       "1.0       8418\n",
       "0.0     172724\n",
       "Name: MentHlth, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_pre[\"MentHlth\"].value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "76b39b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cabon\\AppData\\Local\\Temp/ipykernel_18624/1883573589.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_no_pre['MentalHealth'] = pd.cut(df_no_pre['MentHlth'], bins=bins, labels=labels, include_lowest=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_012</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>MentalHealth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_012  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0           0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1           0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2           0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3           0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4           0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                   0.0           0.0     0.0  ...            1.0   \n",
       "1                   0.0           1.0     0.0  ...            0.0   \n",
       "2                   0.0           0.0     1.0  ...            1.0   \n",
       "3                   0.0           1.0     1.0  ...            1.0   \n",
       "4                   0.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "   NoDocbcCost  GenHlth  PhysHlth  DiffWalk  Sex   Age  Education  Income  \\\n",
       "0          0.0      5.0      15.0       1.0  0.0   9.0        4.0     3.0   \n",
       "1          1.0      3.0       0.0       0.0  0.0   7.0        6.0     1.0   \n",
       "2          1.0      5.0      30.0       1.0  0.0   9.0        4.0     8.0   \n",
       "3          0.0      2.0       0.0       0.0  0.0  11.0        3.0     6.0   \n",
       "4          0.0      2.0       0.0       0.0  0.0  11.0        5.0     4.0   \n",
       "\n",
       "   MentalHealth  \n",
       "0             4  \n",
       "1             1  \n",
       "2             6  \n",
       "3             1  \n",
       "4             1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_value = df_no_pre['MentHlth'].min()\n",
    "max_value = df_no_pre['MentHlth'].max()\n",
    "bins = np.linspace(min_value,max_value,7)\n",
    "labels = [1, 2, 3, 4, 5, 6]\n",
    "df_no_pre['MentalHealth'] = pd.cut(df_no_pre['MentHlth'], bins=bins, labels=labels, include_lowest=True)\n",
    "df_no_pre = df_no_pre.drop(columns=['MentHlth'])\n",
    "df_no_pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d17747c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.0     18842\n",
       "29.0       208\n",
       "28.0       506\n",
       "27.0        96\n",
       "26.0        65\n",
       "25.0      1300\n",
       "24.0        69\n",
       "23.0        53\n",
       "22.0        66\n",
       "21.0       645\n",
       "20.0      3194\n",
       "19.0        20\n",
       "18.0       148\n",
       "17.0        93\n",
       "16.0       109\n",
       "15.0      4775\n",
       "14.0      2525\n",
       "13.0        61\n",
       "12.0       559\n",
       "11.0        57\n",
       "10.0      5425\n",
       "9.0        174\n",
       "8.0        788\n",
       "7.0       4448\n",
       "6.0       1292\n",
       "5.0       7454\n",
       "4.0       4444\n",
       "3.0       8322\n",
       "2.0      14516\n",
       "1.0      11214\n",
       "0.0     157581\n",
       "Name: PhysHlth, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_pre[\"PhysHlth\"].value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "758c5e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_012</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>MentalHealth</th>\n",
       "      <th>PhysicalHealth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_012  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0           0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1           0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2           0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3           0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4           0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                   0.0           0.0     0.0  ...            1.0   \n",
       "1                   0.0           1.0     0.0  ...            0.0   \n",
       "2                   0.0           0.0     1.0  ...            1.0   \n",
       "3                   0.0           1.0     1.0  ...            1.0   \n",
       "4                   0.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "   NoDocbcCost  GenHlth  DiffWalk  Sex   Age  Education  Income  MentalHealth  \\\n",
       "0          0.0      5.0       1.0  0.0   9.0        4.0     3.0             4   \n",
       "1          1.0      3.0       0.0  0.0   7.0        6.0     1.0             1   \n",
       "2          1.0      5.0       1.0  0.0   9.0        4.0     8.0             6   \n",
       "3          0.0      2.0       0.0  0.0  11.0        3.0     6.0             1   \n",
       "4          0.0      2.0       0.0  0.0  11.0        5.0     4.0             1   \n",
       "\n",
       "   PhysicalHealth  \n",
       "0               3  \n",
       "1               1  \n",
       "2               6  \n",
       "3               1  \n",
       "4               1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_value = df_no_pre['PhysHlth'].min()\n",
    "max_value = df_no_pre['PhysHlth'].max()\n",
    "bins = np.linspace(min_value,max_value,7)\n",
    "labels = [1, 2, 3, 4, 5, 6]\n",
    "df_no_pre['PhysicalHealth'] = pd.cut(df_no_pre['PhysHlth'], bins=bins, labels=labels, include_lowest=True)\n",
    "df_no_pre = df_no_pre.drop(columns=['PhysHlth'])\n",
    "df_no_pre.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503b357c",
   "metadata": {},
   "source": [
    "## Attempt 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0ebe4230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = df_no_pre[\"Diabetes_012\"].values\n",
    "X = df_no_pre.drop(columns=['Diabetes_012']).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a64eef77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 120)               2640      \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 50)                6050      \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 30)                1530      \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 10,251\n",
      "Trainable params: 10,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 120\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 30\n",
    "nn11 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn11.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# Second hidden layer\n",
    "nn11.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# Third hidden layer\n",
    "nn11.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# Output layer\n",
    "nn11.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn11.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ae7c8424",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3940 - accuracy: 0.7316\n",
      "Epoch 2/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3905 - accuracy: 0.7393\n",
      "Epoch 3/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3895 - accuracy: 0.7404: 0s - loss: 0.3\n",
      "Epoch 4/200\n",
      "5838/5838 [==============================] - 6s 991us/step - loss: 0.3887 - accuracy: 0.7400\n",
      "Epoch 5/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3880 - accuracy: 0.7415\n",
      "Epoch 6/200\n",
      "5838/5838 [==============================] - 6s 997us/step - loss: 0.3876 - accuracy: 0.7404\n",
      "Epoch 7/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3870 - accuracy: 0.7425\n",
      "Epoch 8/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3863 - accuracy: 0.7423\n",
      "Epoch 9/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3861 - accuracy: 0.7422\n",
      "Epoch 10/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3855 - accuracy: 0.7423\n",
      "Epoch 11/200\n",
      "5838/5838 [==============================] - 6s 995us/step - loss: 0.3849 - accuracy: 0.7418\n",
      "Epoch 12/200\n",
      "5838/5838 [==============================] - 6s 991us/step - loss: 0.3843 - accuracy: 0.7421\n",
      "Epoch 13/200\n",
      "5838/5838 [==============================] - 6s 985us/step - loss: 0.3838 - accuracy: 0.7439\n",
      "Epoch 14/200\n",
      "5838/5838 [==============================] - 6s 998us/step - loss: 0.3835 - accuracy: 0.7430\n",
      "Epoch 15/200\n",
      "5838/5838 [==============================] - 6s 978us/step - loss: 0.3826 - accuracy: 0.7441\n",
      "Epoch 16/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3819 - accuracy: 0.7440\n",
      "Epoch 17/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3813 - accuracy: 0.7457: 0s\n",
      "Epoch 18/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3806 - accuracy: 0.7462\n",
      "Epoch 19/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3800 - accuracy: 0.7472\n",
      "Epoch 20/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3792 - accuracy: 0.7471\n",
      "Epoch 21/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3785 - accuracy: 0.7476\n",
      "Epoch 22/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3780 - accuracy: 0.7481\n",
      "Epoch 23/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3773 - accuracy: 0.7494\n",
      "Epoch 24/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3766 - accuracy: 0.7488: 0s - loss: 0.3767 - accuracy: 0.74\n",
      "Epoch 25/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3760 - accuracy: 0.7492\n",
      "Epoch 26/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3749 - accuracy: 0.7520\n",
      "Epoch 27/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3745 - accuracy: 0.7507\n",
      "Epoch 28/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3737 - accuracy: 0.7506\n",
      "Epoch 29/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3729 - accuracy: 0.7519\n",
      "Epoch 30/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3726 - accuracy: 0.7522\n",
      "Epoch 31/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3718 - accuracy: 0.7528\n",
      "Epoch 32/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3711 - accuracy: 0.7544\n",
      "Epoch 33/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3707 - accuracy: 0.7545\n",
      "Epoch 34/200\n",
      "5838/5838 [==============================] - 6s 994us/step - loss: 0.3701 - accuracy: 0.7537\n",
      "Epoch 35/200\n",
      "5838/5838 [==============================] - 6s 995us/step - loss: 0.3696 - accuracy: 0.7547\n",
      "Epoch 36/200\n",
      "5838/5838 [==============================] - 6s 990us/step - loss: 0.3689 - accuracy: 0.75490s - loss: 0.3699 - accu\n",
      "Epoch 37/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3685 - accuracy: 0.7550\n",
      "Epoch 38/200\n",
      "5838/5838 [==============================] - 6s 994us/step - loss: 0.3680 - accuracy: 0.7563\n",
      "Epoch 39/200\n",
      "5838/5838 [==============================] - 6s 996us/step - loss: 0.3669 - accuracy: 0.7569\n",
      "Epoch 40/200\n",
      "5838/5838 [==============================] - 6s 988us/step - loss: 0.3669 - accuracy: 0.7558\n",
      "Epoch 41/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3664 - accuracy: 0.7573\n",
      "Epoch 42/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3658 - accuracy: 0.7573\n",
      "Epoch 43/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3650 - accuracy: 0.7570\n",
      "Epoch 44/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3649 - accuracy: 0.7580\n",
      "Epoch 45/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3643 - accuracy: 0.7572\n",
      "Epoch 46/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3644 - accuracy: 0.7581\n",
      "Epoch 47/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3633 - accuracy: 0.7582\n",
      "Epoch 48/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3634 - accuracy: 0.7570\n",
      "Epoch 49/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3625 - accuracy: 0.7591: 0s - loss: 0.3618 - accura\n",
      "Epoch 50/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3624 - accuracy: 0.7591: 1s - loss: 0.3608 - accura - ETA: \n",
      "Epoch 51/200\n",
      "5838/5838 [==============================] - 6s 998us/step - loss: 0.3616 - accuracy: 0.7594\n",
      "Epoch 52/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3613 - accuracy: 0.7599\n",
      "Epoch 53/200\n",
      "5838/5838 [==============================] - 6s 993us/step - loss: 0.3606 - accuracy: 0.7602\n",
      "Epoch 54/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3605 - accuracy: 0.7601: 0s - loss: 0.3603 - accuracy: \n",
      "Epoch 55/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3598 - accuracy: 0.7603\n",
      "Epoch 56/200\n",
      "5838/5838 [==============================] - 6s 996us/step - loss: 0.3599 - accuracy: 0.7602\n",
      "Epoch 57/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3593 - accuracy: 0.7600\n",
      "Epoch 58/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3588 - accuracy: 0.7607\n",
      "Epoch 59/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3589 - accuracy: 0.7599\n",
      "Epoch 60/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3580 - accuracy: 0.7609\n",
      "Epoch 61/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3580 - accuracy: 0.7613\n",
      "Epoch 62/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3578 - accuracy: 0.7612\n",
      "Epoch 63/200\n",
      "5838/5838 [==============================] - 6s 990us/step - loss: 0.3568 - accuracy: 0.76162s - los - ETA: 0s - l\n",
      "Epoch 64/200\n",
      "5838/5838 [==============================] - 6s 995us/step - loss: 0.3569 - accuracy: 0.7613\n",
      "Epoch 65/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3564 - accuracy: 0.7612\n",
      "Epoch 66/200\n",
      "5838/5838 [==============================] - 6s 990us/step - loss: 0.3561 - accuracy: 0.76170s - loss: 0.354\n",
      "Epoch 67/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3555 - accuracy: 0.7611\n",
      "Epoch 68/200\n",
      "5838/5838 [==============================] - 6s 991us/step - loss: 0.3558 - accuracy: 0.7619\n",
      "Epoch 69/200\n",
      "5838/5838 [==============================] - 6s 998us/step - loss: 0.3553 - accuracy: 0.7620\n",
      "Epoch 70/200\n",
      "5838/5838 [==============================] - 6s 989us/step - loss: 0.3548 - accuracy: 0.7619\n",
      "Epoch 71/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3544 - accuracy: 0.7627\n",
      "Epoch 72/200\n",
      "5838/5838 [==============================] - 6s 993us/step - loss: 0.3544 - accuracy: 0.7633\n",
      "Epoch 73/200\n",
      "5838/5838 [==============================] - 6s 994us/step - loss: 0.3541 - accuracy: 0.7624\n",
      "Epoch 74/200\n",
      "5838/5838 [==============================] - 6s 998us/step - loss: 0.3537 - accuracy: 0.7622\n",
      "Epoch 75/200\n",
      "5838/5838 [==============================] - 6s 983us/step - loss: 0.3530 - accuracy: 0.7628\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3532 - accuracy: 0.7622: 2s - l - ETA: 0s - loss: 0\n",
      "Epoch 77/200\n",
      "5838/5838 [==============================] - 6s 979us/step - loss: 0.3528 - accuracy: 0.7624\n",
      "Epoch 78/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3527 - accuracy: 0.7625\n",
      "Epoch 79/200\n",
      "5838/5838 [==============================] - 6s 993us/step - loss: 0.3523 - accuracy: 0.76300s - loss: 0.3523 - accuracy: 0.76\n",
      "Epoch 80/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3520 - accuracy: 0.7624: 0s - los\n",
      "Epoch 81/200\n",
      "5838/5838 [==============================] - 6s 996us/step - loss: 0.3518 - accuracy: 0.7619\n",
      "Epoch 82/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3516 - accuracy: 0.7625\n",
      "Epoch 83/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3509 - accuracy: 0.7633\n",
      "Epoch 84/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3513 - accuracy: 0.7633\n",
      "Epoch 85/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3509 - accuracy: 0.7632\n",
      "Epoch 86/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3504 - accuracy: 0.7633: 0s\n",
      "Epoch 87/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3499 - accuracy: 0.7632\n",
      "Epoch 88/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3498 - accuracy: 0.7632\n",
      "Epoch 89/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3496 - accuracy: 0.7637\n",
      "Epoch 90/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3500 - accuracy: 0.7626: 0s - loss: 0.3\n",
      "Epoch 91/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3493 - accuracy: 0.7643\n",
      "Epoch 92/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3490 - accuracy: 0.7637\n",
      "Epoch 93/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3492 - accuracy: 0.7630\n",
      "Epoch 94/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3488 - accuracy: 0.7637\n",
      "Epoch 95/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3481 - accuracy: 0.7637\n",
      "Epoch 96/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3480 - accuracy: 0.7641\n",
      "Epoch 97/200\n",
      "5838/5838 [==============================] - 6s 975us/step - loss: 0.3481 - accuracy: 0.7635\n",
      "Epoch 98/200\n",
      "5838/5838 [==============================] - 6s 971us/step - loss: 0.3476 - accuracy: 0.76350s - l\n",
      "Epoch 99/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3474 - accuracy: 0.7637\n",
      "Epoch 100/200\n",
      "5838/5838 [==============================] - ETA: 0s - loss: 0.3474 - accuracy: 0.7642 ETA: 1s - l - 6s 1ms/step - loss: 0.3477 - accuracy: 0.7640\n",
      "Epoch 101/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3472 - accuracy: 0.7638: 0s - los\n",
      "Epoch 102/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3473 - accuracy: 0.7636\n",
      "Epoch 103/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3471 - accuracy: 0.7642\n",
      "Epoch 104/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3468 - accuracy: 0.7638\n",
      "Epoch 105/200\n",
      "5838/5838 [==============================] - 6s 999us/step - loss: 0.3473 - accuracy: 0.7632\n",
      "Epoch 106/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3469 - accuracy: 0.7641: 1s - loss: 0.345 - ETA: 0s - loss: 0.3462 - accuracy:  - ETA: 0s - loss:\n",
      "Epoch 107/200\n",
      "5838/5838 [==============================] - 6s 995us/step - loss: 0.3459 - accuracy: 0.76430s - loss: 0.3458 - accuracy\n",
      "Epoch 108/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3463 - accuracy: 0.7645\n",
      "Epoch 109/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3460 - accuracy: 0.7643\n",
      "Epoch 110/200\n",
      "5838/5838 [==============================] - 6s 990us/step - loss: 0.3458 - accuracy: 0.7643\n",
      "Epoch 111/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3455 - accuracy: 0.7653\n",
      "Epoch 112/200\n",
      "5838/5838 [==============================] - 6s 989us/step - loss: 0.3454 - accuracy: 0.76400s - loss: 0.3\n",
      "Epoch 113/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3450 - accuracy: 0.7650\n",
      "Epoch 114/200\n",
      "5838/5838 [==============================] - 6s 997us/step - loss: 0.3452 - accuracy: 0.7648\n",
      "Epoch 115/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3444 - accuracy: 0.7653\n",
      "Epoch 116/200\n",
      "5838/5838 [==============================] - 6s 999us/step - loss: 0.3443 - accuracy: 0.7652\n",
      "Epoch 117/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3444 - accuracy: 0.7654\n",
      "Epoch 118/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3442 - accuracy: 0.7653\n",
      "Epoch 119/200\n",
      "5838/5838 [==============================] - 6s 998us/step - loss: 0.3441 - accuracy: 0.76550s - los\n",
      "Epoch 120/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3439 - accuracy: 0.7658\n",
      "Epoch 121/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3440 - accuracy: 0.7644\n",
      "Epoch 122/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3432 - accuracy: 0.7653\n",
      "Epoch 123/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3429 - accuracy: 0.7662\n",
      "Epoch 124/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3432 - accuracy: 0.7646\n",
      "Epoch 125/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3432 - accuracy: 0.7652\n",
      "Epoch 126/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3432 - accuracy: 0.7658\n"
     ]
    }
   ],
   "source": [
    "nn11.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "fit_model = nn11.fit(X_train_scaled,y_train, batch_size = 32, epochs=200, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "17788513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1946/1946 - 1s - loss: 0.4287 - accuracy: 0.7442\n",
      "Loss: 0.42865926027297974, Accuracy: 0.7441980242729187\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn11.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039519b3",
   "metadata": {},
   "source": [
    "## Attempt 12\n",
    "### With all diabete choices but with leaky relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "88ecc0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_012</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>MentalHealth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>26-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1-5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_012  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0           0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1           0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2           0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3           0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4           0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                   0.0           0.0     0.0  ...            1.0   \n",
       "1                   0.0           1.0     0.0  ...            0.0   \n",
       "2                   0.0           0.0     1.0  ...            1.0   \n",
       "3                   0.0           1.0     1.0  ...            1.0   \n",
       "4                   0.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "   NoDocbcCost  GenHlth  PhysHlth  DiffWalk  Sex   Age  Education  Income  \\\n",
       "0          0.0      5.0      15.0       1.0  0.0   9.0        4.0     3.0   \n",
       "1          1.0      3.0       0.0       0.0  0.0   7.0        6.0     1.0   \n",
       "2          1.0      5.0      30.0       1.0  0.0   9.0        4.0     8.0   \n",
       "3          0.0      2.0       0.0       0.0  0.0  11.0        3.0     6.0   \n",
       "4          0.0      2.0       0.0       0.0  0.0  11.0        5.0     4.0   \n",
       "\n",
       "   MentalHealth  \n",
       "0         16-20  \n",
       "1           1-5  \n",
       "2         26-30  \n",
       "3           1-5  \n",
       "4           1-5  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dumb = df.copy()\n",
    "min_value = df_dumb['MentHlth'].min()\n",
    "max_value = df_dumb['MentHlth'].max()\n",
    "bins = np.linspace(min_value,max_value,7)\n",
    "labels = [\"1-5\", \"6-10\", \"11-15\", \"16-20\", \"21-25\", \"26-30\"]\n",
    "df_dumb['MentalHealth'] = pd.cut(df_dumb['MentHlth'], bins=bins, labels=labels, include_lowest=True)\n",
    "df_dumb = df_dumb.drop(columns=['MentHlth'])\n",
    "df_dumb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ecc569d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_012</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>MentalHealth</th>\n",
       "      <th>PhysicalHealth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16-20</td>\n",
       "      <td>11-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1-5</td>\n",
       "      <td>1-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>26-30</td>\n",
       "      <td>26-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1-5</td>\n",
       "      <td>1-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1-5</td>\n",
       "      <td>1-5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_012  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0           0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1           0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2           0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3           0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4           0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                   0.0           0.0     0.0  ...            1.0   \n",
       "1                   0.0           1.0     0.0  ...            0.0   \n",
       "2                   0.0           0.0     1.0  ...            1.0   \n",
       "3                   0.0           1.0     1.0  ...            1.0   \n",
       "4                   0.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "   NoDocbcCost  GenHlth  DiffWalk  Sex   Age  Education  Income  MentalHealth  \\\n",
       "0          0.0      5.0       1.0  0.0   9.0        4.0     3.0         16-20   \n",
       "1          1.0      3.0       0.0  0.0   7.0        6.0     1.0           1-5   \n",
       "2          1.0      5.0       1.0  0.0   9.0        4.0     8.0         26-30   \n",
       "3          0.0      2.0       0.0  0.0  11.0        3.0     6.0           1-5   \n",
       "4          0.0      2.0       0.0  0.0  11.0        5.0     4.0           1-5   \n",
       "\n",
       "   PhysicalHealth  \n",
       "0           11-15  \n",
       "1             1-5  \n",
       "2           26-30  \n",
       "3             1-5  \n",
       "4             1-5  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_value = df_dumb['PhysHlth'].min()\n",
    "max_value = df_dumb['PhysHlth'].max()\n",
    "bins = np.linspace(min_value,max_value,7)\n",
    "labels = [\"1-5\", \"6-10\", \"11-15\", \"16-20\", \"21-25\", \"26-30\"]\n",
    "df_dumb['PhysicalHealth'] = pd.cut(df_dumb['PhysHlth'], bins=bins, labels=labels, include_lowest=True)\n",
    "df_dumb = df_dumb.drop(columns=['PhysHlth'])\n",
    "df_dumb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f5ad9445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_012</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>MentalHealth_11-15</th>\n",
       "      <th>MentalHealth_16-20</th>\n",
       "      <th>MentalHealth_21-25</th>\n",
       "      <th>MentalHealth_26-30</th>\n",
       "      <th>PhysicalHealth_1-5</th>\n",
       "      <th>PhysicalHealth_6-10</th>\n",
       "      <th>PhysicalHealth_11-15</th>\n",
       "      <th>PhysicalHealth_16-20</th>\n",
       "      <th>PhysicalHealth_21-25</th>\n",
       "      <th>PhysicalHealth_26-30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_012  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0           0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1           0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2           0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3           0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4           0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  MentalHealth_11-15  \\\n",
       "0                   0.0           0.0     0.0  ...                   0   \n",
       "1                   0.0           1.0     0.0  ...                   0   \n",
       "2                   0.0           0.0     1.0  ...                   0   \n",
       "3                   0.0           1.0     1.0  ...                   0   \n",
       "4                   0.0           1.0     1.0  ...                   0   \n",
       "\n",
       "   MentalHealth_16-20  MentalHealth_21-25  MentalHealth_26-30  \\\n",
       "0                   1                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   1   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   PhysicalHealth_1-5  PhysicalHealth_6-10  PhysicalHealth_11-15  \\\n",
       "0                   0                    0                     1   \n",
       "1                   1                    0                     0   \n",
       "2                   0                    0                     0   \n",
       "3                   1                    0                     0   \n",
       "4                   1                    0                     0   \n",
       "\n",
       "   PhysicalHealth_16-20  PhysicalHealth_21-25  PhysicalHealth_26-30  \n",
       "0                     0                     0                     0  \n",
       "1                     0                     0                     0  \n",
       "2                     0                     0                     1  \n",
       "3                     0                     0                     0  \n",
       "4                     0                     0                     0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummies = pd.get_dummies(df_dumb)\n",
    "df_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4a98ba45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = df_dummies[\"Diabetes_012\"].values\n",
    "X = df_dummies.drop(columns=\"Diabetes_012\").values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d944a9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_44 (Dense)             (None, 120)               3840      \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 50)                6050      \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 30)                1530      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 11,451\n",
      "Trainable params: 11,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 120\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 30\n",
    "nn12 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn12.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# Second hidden layer\n",
    "nn12.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# Third hidden layer\n",
    "nn12.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# Output layer\n",
    "nn12.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn12.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e5f688c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5946/5946 [==============================] - 6s 922us/step - loss: 0.3966 - accuracy: 0.7172\n",
      "Epoch 2/200\n",
      "5946/5946 [==============================] - 5s 888us/step - loss: 0.3924 - accuracy: 0.7268\n",
      "Epoch 3/200\n",
      "5946/5946 [==============================] - 5s 912us/step - loss: 0.3912 - accuracy: 0.7284\n",
      "Epoch 4/200\n",
      "5946/5946 [==============================] - 5s 887us/step - loss: 0.3902 - accuracy: 0.7297\n",
      "Epoch 5/200\n",
      "5946/5946 [==============================] - 6s 999us/step - loss: 0.3895 - accuracy: 0.7293\n",
      "Epoch 6/200\n",
      "5946/5946 [==============================] - 5s 869us/step - loss: 0.3887 - accuracy: 0.7279\n",
      "Epoch 7/200\n",
      "5946/5946 [==============================] - 5s 882us/step - loss: 0.3882 - accuracy: 0.7283\n",
      "Epoch 8/200\n",
      "5946/5946 [==============================] - 5s 853us/step - loss: 0.3874 - accuracy: 0.72910s\n",
      "Epoch 9/200\n",
      "5946/5946 [==============================] - 5s 864us/step - loss: 0.3867 - accuracy: 0.7298\n",
      "Epoch 10/200\n",
      "5946/5946 [==============================] - 5s 896us/step - loss: 0.3863 - accuracy: 0.7297\n",
      "Epoch 11/200\n",
      "5946/5946 [==============================] - 5s 922us/step - loss: 0.3855 - accuracy: 0.7306\n",
      "Epoch 12/200\n",
      "5946/5946 [==============================] - 5s 900us/step - loss: 0.3847 - accuracy: 0.7309\n",
      "Epoch 13/200\n",
      "5946/5946 [==============================] - 5s 907us/step - loss: 0.3844 - accuracy: 0.7319\n",
      "Epoch 14/200\n",
      "5946/5946 [==============================] - 6s 934us/step - loss: 0.3834 - accuracy: 0.7327\n",
      "Epoch 15/200\n",
      "5946/5946 [==============================] - 6s 927us/step - loss: 0.3830 - accuracy: 0.7328\n",
      "Epoch 16/200\n",
      "5946/5946 [==============================] - 6s 944us/step - loss: 0.3824 - accuracy: 0.7330\n",
      "Epoch 17/200\n",
      "5946/5946 [==============================] - 6s 942us/step - loss: 0.3818 - accuracy: 0.73440s - loss: 0.3813 - ac\n",
      "Epoch 18/200\n",
      "5946/5946 [==============================] - 6s 930us/step - loss: 0.3810 - accuracy: 0.7344\n",
      "Epoch 19/200\n",
      "5946/5946 [==============================] - 5s 885us/step - loss: 0.3802 - accuracy: 0.7349\n",
      "Epoch 20/200\n",
      "5946/5946 [==============================] - 5s 924us/step - loss: 0.3793 - accuracy: 0.7359\n",
      "Epoch 21/200\n",
      "5946/5946 [==============================] - 5s 847us/step - loss: 0.3789 - accuracy: 0.7373\n",
      "Epoch 22/200\n",
      "5946/5946 [==============================] - 6s 946us/step - loss: 0.3781 - accuracy: 0.7387\n",
      "Epoch 23/200\n",
      "5946/5946 [==============================] - 6s 945us/step - loss: 0.3773 - accuracy: 0.7389\n",
      "Epoch 24/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3769 - accuracy: 0.7398\n",
      "Epoch 25/200\n",
      "5946/5946 [==============================] - 5s 883us/step - loss: 0.3758 - accuracy: 0.7391\n",
      "Epoch 26/200\n",
      "5946/5946 [==============================] - 5s 892us/step - loss: 0.3751 - accuracy: 0.7405\n",
      "Epoch 27/200\n",
      "5946/5946 [==============================] - 6s 932us/step - loss: 0.3746 - accuracy: 0.7417\n",
      "Epoch 28/200\n",
      "5946/5946 [==============================] - 5s 891us/step - loss: 0.3737 - accuracy: 0.7415\n",
      "Epoch 29/200\n",
      "5946/5946 [==============================] - 5s 897us/step - loss: 0.3733 - accuracy: 0.7430\n",
      "Epoch 30/200\n",
      "5946/5946 [==============================] - 5s 859us/step - loss: 0.3724 - accuracy: 0.7431\n",
      "Epoch 31/200\n",
      "5946/5946 [==============================] - 5s 880us/step - loss: 0.3719 - accuracy: 0.7445\n",
      "Epoch 32/200\n",
      "5946/5946 [==============================] - 5s 892us/step - loss: 0.3710 - accuracy: 0.7453\n",
      "Epoch 33/200\n",
      "5946/5946 [==============================] - 5s 889us/step - loss: 0.3705 - accuracy: 0.7456\n",
      "Epoch 34/200\n",
      "5946/5946 [==============================] - 6s 932us/step - loss: 0.3701 - accuracy: 0.7458\n",
      "Epoch 35/200\n",
      "5946/5946 [==============================] - 5s 916us/step - loss: 0.3693 - accuracy: 0.7461\n",
      "Epoch 36/200\n",
      "5946/5946 [==============================] - 6s 932us/step - loss: 0.3689 - accuracy: 0.7463\n",
      "Epoch 37/200\n",
      "5946/5946 [==============================] - 5s 913us/step - loss: 0.3680 - accuracy: 0.7472\n",
      "Epoch 38/200\n",
      "5946/5946 [==============================] - 5s 915us/step - loss: 0.3675 - accuracy: 0.7480\n",
      "Epoch 39/200\n",
      "5946/5946 [==============================] - 6s 993us/step - loss: 0.3671 - accuracy: 0.7477\n",
      "Epoch 40/200\n",
      "5946/5946 [==============================] - 6s 938us/step - loss: 0.3663 - accuracy: 0.7496\n",
      "Epoch 41/200\n",
      "5946/5946 [==============================] - 5s 890us/step - loss: 0.3658 - accuracy: 0.7485\n",
      "Epoch 42/200\n",
      "5946/5946 [==============================] - 6s 929us/step - loss: 0.3656 - accuracy: 0.7492\n",
      "Epoch 43/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3645 - accuracy: 0.7495\n",
      "Epoch 44/200\n",
      "5946/5946 [==============================] - 6s 938us/step - loss: 0.3640 - accuracy: 0.7511\n",
      "Epoch 45/200\n",
      "5946/5946 [==============================] - 6s 953us/step - loss: 0.3634 - accuracy: 0.7504\n",
      "Epoch 46/200\n",
      "5946/5946 [==============================] - 6s 953us/step - loss: 0.3633 - accuracy: 0.7507\n",
      "Epoch 47/200\n",
      "5946/5946 [==============================] - 5s 914us/step - loss: 0.3629 - accuracy: 0.7512\n",
      "Epoch 48/200\n",
      "5946/5946 [==============================] - 5s 878us/step - loss: 0.3623 - accuracy: 0.7514\n",
      "Epoch 49/200\n",
      "5946/5946 [==============================] - 5s 912us/step - loss: 0.3618 - accuracy: 0.7516\n",
      "Epoch 50/200\n",
      "5946/5946 [==============================] - 5s 906us/step - loss: 0.3614 - accuracy: 0.7523\n",
      "Epoch 51/200\n",
      "5946/5946 [==============================] - 6s 930us/step - loss: 0.3607 - accuracy: 0.7535\n",
      "Epoch 52/200\n",
      "5946/5946 [==============================] - 6s 930us/step - loss: 0.3605 - accuracy: 0.7527\n",
      "Epoch 53/200\n",
      "5946/5946 [==============================] - 5s 903us/step - loss: 0.3600 - accuracy: 0.75311s - loss: 0\n",
      "Epoch 54/200\n",
      "5946/5946 [==============================] - 6s 952us/step - loss: 0.3596 - accuracy: 0.75280s - loss: 0.3592 \n",
      "Epoch 55/200\n",
      "5946/5946 [==============================] - ETA: 0s - loss: 0.3594 - accuracy: 0.75 - 5s 916us/step - loss: 0.3594 - accuracy: 0.7531\n",
      "Epoch 56/200\n",
      "5946/5946 [==============================] - 5s 890us/step - loss: 0.3588 - accuracy: 0.75330s - loss: 0.3595 - ac\n",
      "Epoch 57/200\n",
      "5946/5946 [==============================] - 6s 928us/step - loss: 0.3582 - accuracy: 0.75382s - los\n",
      "Epoch 58/200\n",
      "5946/5946 [==============================] - 5s 839us/step - loss: 0.3577 - accuracy: 0.7534\n",
      "Epoch 59/200\n",
      "5946/5946 [==============================] - 5s 865us/step - loss: 0.3572 - accuracy: 0.7539\n",
      "Epoch 60/200\n",
      "5946/5946 [==============================] - 5s 838us/step - loss: 0.3572 - accuracy: 0.7547\n",
      "Epoch 61/200\n",
      "5946/5946 [==============================] - 5s 836us/step - loss: 0.3564 - accuracy: 0.7553\n",
      "Epoch 62/200\n",
      "5946/5946 [==============================] - 5s 817us/step - loss: 0.3562 - accuracy: 0.7548\n",
      "Epoch 63/200\n",
      "5946/5946 [==============================] - 5s 852us/step - loss: 0.3559 - accuracy: 0.7559\n",
      "Epoch 64/200\n",
      "5946/5946 [==============================] - 5s 847us/step - loss: 0.3554 - accuracy: 0.7559\n",
      "Epoch 65/200\n",
      "5946/5946 [==============================] - 5s 844us/step - loss: 0.3556 - accuracy: 0.7548\n",
      "Epoch 66/200\n",
      "5946/5946 [==============================] - 5s 823us/step - loss: 0.3550 - accuracy: 0.75560s - loss: 0.3542 - accuracy - ETA: 0s - loss: 0.3546 - accuracy: 0.\n",
      "Epoch 67/200\n",
      "5946/5946 [==============================] - 5s 839us/step - loss: 0.3546 - accuracy: 0.75560s - l\n",
      "Epoch 68/200\n",
      "5946/5946 [==============================] - 5s 827us/step - loss: 0.3541 - accuracy: 0.7560\n",
      "Epoch 69/200\n",
      "5946/5946 [==============================] - 5s 841us/step - loss: 0.3541 - accuracy: 0.7558\n",
      "Epoch 70/200\n",
      "5946/5946 [==============================] - 5s 812us/step - loss: 0.3534 - accuracy: 0.7562\n",
      "Epoch 71/200\n",
      "5946/5946 [==============================] - 5s 847us/step - loss: 0.3531 - accuracy: 0.75581s - ETA: 0s - loss:\n",
      "Epoch 72/200\n",
      "5946/5946 [==============================] - 5s 825us/step - loss: 0.3527 - accuracy: 0.7568\n",
      "Epoch 73/200\n",
      "5946/5946 [==============================] - 5s 837us/step - loss: 0.3526 - accuracy: 0.7566\n",
      "Epoch 74/200\n",
      "5946/5946 [==============================] - 5s 820us/step - loss: 0.3519 - accuracy: 0.7568\n",
      "Epoch 75/200\n",
      "5946/5946 [==============================] - 5s 819us/step - loss: 0.3521 - accuracy: 0.75630s - l\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5946/5946 [==============================] - 5s 851us/step - loss: 0.3517 - accuracy: 0.7569\n",
      "Epoch 77/200\n",
      "5946/5946 [==============================] - 5s 829us/step - loss: 0.3517 - accuracy: 0.7568\n",
      "Epoch 78/200\n",
      "5946/5946 [==============================] - 5s 830us/step - loss: 0.3510 - accuracy: 0.7574\n",
      "Epoch 79/200\n",
      "5946/5946 [==============================] - 5s 809us/step - loss: 0.3505 - accuracy: 0.7573\n",
      "Epoch 80/200\n",
      "5946/5946 [==============================] - 5s 858us/step - loss: 0.3506 - accuracy: 0.7572\n",
      "Epoch 81/200\n",
      "5946/5946 [==============================] - 5s 823us/step - loss: 0.3503 - accuracy: 0.7565\n",
      "Epoch 82/200\n",
      "5946/5946 [==============================] - 6s 940us/step - loss: 0.3503 - accuracy: 0.75760s - loss: 0.3502 - accuracy: 0.75\n",
      "Epoch 83/200\n",
      "5946/5946 [==============================] - 6s 965us/step - loss: 0.3495 - accuracy: 0.7577\n",
      "Epoch 84/200\n",
      "5946/5946 [==============================] - 6s 952us/step - loss: 0.3496 - accuracy: 0.75720s - loss: 0.3497 - accuracy: 0.75\n",
      "Epoch 85/200\n",
      "5946/5946 [==============================] - 6s 952us/step - loss: 0.3498 - accuracy: 0.7569\n",
      "Epoch 86/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3496 - accuracy: 0.7583\n"
     ]
    }
   ],
   "source": [
    "nn12.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "fit_model = nn12.fit(X_train_scaled,y_train, batch_size=32, epochs=200, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e75fab2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1982/1982 - 1s - loss: 0.4199 - accuracy: 0.7247\n",
      "Loss: 0.41990840435028076, Accuracy: 0.724676787853241\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn12.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8091e9b",
   "metadata": {},
   "source": [
    "## Attempt 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "47a4b546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_012</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>MentalHealth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_012  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0           0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1           0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2           0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3           0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4           0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                   0.0           0.0     0.0  ...            1.0   \n",
       "1                   0.0           1.0     0.0  ...            0.0   \n",
       "2                   0.0           0.0     1.0  ...            1.0   \n",
       "3                   0.0           1.0     1.0  ...            1.0   \n",
       "4                   0.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "   NoDocbcCost  GenHlth  PhysHlth  DiffWalk  Sex   Age  Education  Income  \\\n",
       "0          0.0      5.0      15.0       1.0  0.0   9.0        4.0     3.0   \n",
       "1          1.0      3.0       0.0       0.0  0.0   7.0        6.0     1.0   \n",
       "2          1.0      5.0      30.0       1.0  0.0   9.0        4.0     8.0   \n",
       "3          0.0      2.0       0.0       0.0  0.0  11.0        3.0     6.0   \n",
       "4          0.0      2.0       0.0       0.0  0.0  11.0        5.0     4.0   \n",
       "\n",
       "   MentalHealth  \n",
       "0           4.0  \n",
       "1           1.0  \n",
       "2           6.0  \n",
       "3           1.0  \n",
       "4           1.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_value = df['MentHlth'].min()\n",
    "max_value = df['MentHlth'].max()\n",
    "bins = np.linspace(min_value,max_value,7)\n",
    "labels = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]\n",
    "df['MentalHealth'] = pd.cut(df['MentHlth'], bins=bins, labels=labels, include_lowest=True)\n",
    "df = df.drop(columns=['MentHlth'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e4a6445f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_012</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>MentalHealth</th>\n",
       "      <th>PhysicalHealth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_012  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0           0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1           0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2           0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3           0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4           0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                   0.0           0.0     0.0  ...            1.0   \n",
       "1                   0.0           1.0     0.0  ...            0.0   \n",
       "2                   0.0           0.0     1.0  ...            1.0   \n",
       "3                   0.0           1.0     1.0  ...            1.0   \n",
       "4                   0.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "   NoDocbcCost  GenHlth  DiffWalk  Sex   Age  Education  Income  MentalHealth  \\\n",
       "0          0.0      5.0       1.0  0.0   9.0        4.0     3.0           4.0   \n",
       "1          1.0      3.0       0.0  0.0   7.0        6.0     1.0           1.0   \n",
       "2          1.0      5.0       1.0  0.0   9.0        4.0     8.0           6.0   \n",
       "3          0.0      2.0       0.0  0.0  11.0        3.0     6.0           1.0   \n",
       "4          0.0      2.0       0.0  0.0  11.0        5.0     4.0           1.0   \n",
       "\n",
       "   PhysicalHealth  \n",
       "0             3.0  \n",
       "1             1.0  \n",
       "2             6.0  \n",
       "3             1.0  \n",
       "4             1.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_value = df['PhysHlth'].min()\n",
    "max_value = df['PhysHlth'].max()\n",
    "bins = np.linspace(min_value,max_value,7)\n",
    "labels = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]\n",
    "df['PhysicalHealth'] = pd.cut(df['PhysHlth'], bins=bins, labels=labels, include_lowest=True)\n",
    "df = df.drop(columns=['PhysHlth'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a5d6fccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = df[\"Diabetes_012\"].values\n",
    "X = df.drop(columns=\"Diabetes_012\").values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2cb6dca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_48 (Dense)             (None, 120)               2640      \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 50)                6050      \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 30)                1530      \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 10,251\n",
      "Trainable params: 10,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 120\n",
    "hidden_nodes_layer2 = 50\n",
    "hidden_nodes_layer3 = 30\n",
    "nn13 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn13.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# Second hidden layer\n",
    "nn13.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# Third hidden layer\n",
    "nn13.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# Output layer\n",
    "nn13.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn13.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3c22ece3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5946/5946 [==============================] - 6s 968us/step - loss: 0.3956 - accuracy: 0.7202\n",
      "Epoch 2/200\n",
      "5946/5946 [==============================] - 6s 960us/step - loss: 0.3921 - accuracy: 0.7252\n",
      "Epoch 3/200\n",
      "5946/5946 [==============================] - 6s 975us/step - loss: 0.3911 - accuracy: 0.7256\n",
      "Epoch 4/200\n",
      "5946/5946 [==============================] - 6s 997us/step - loss: 0.3904 - accuracy: 0.7265\n",
      "Epoch 5/200\n",
      "5946/5946 [==============================] - 6s 948us/step - loss: 0.3896 - accuracy: 0.7291\n",
      "Epoch 6/200\n",
      "5946/5946 [==============================] - 6s 966us/step - loss: 0.3892 - accuracy: 0.7273\n",
      "Epoch 7/200\n",
      "5946/5946 [==============================] - 6s 975us/step - loss: 0.3885 - accuracy: 0.7259\n",
      "Epoch 8/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3881 - accuracy: 0.7280:  - ETA: 0s - loss: 0.3883 - accuracy: 0.\n",
      "Epoch 9/200\n",
      "5946/5946 [==============================] - 6s 965us/step - loss: 0.3875 - accuracy: 0.7275\n",
      "Epoch 10/200\n",
      "5946/5946 [==============================] - 6s 991us/step - loss: 0.3870 - accuracy: 0.7285\n",
      "Epoch 11/200\n",
      "5946/5946 [==============================] - 6s 968us/step - loss: 0.3863 - accuracy: 0.7286\n",
      "Epoch 12/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3859 - accuracy: 0.7288\n",
      "Epoch 13/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3854 - accuracy: 0.7302\n",
      "Epoch 14/200\n",
      "5946/5946 [==============================] - 6s 966us/step - loss: 0.3847 - accuracy: 0.73190s - loss: 0.3845 - ac\n",
      "Epoch 15/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3841 - accuracy: 0.7297\n",
      "Epoch 16/200\n",
      "5946/5946 [==============================] - 6s 996us/step - loss: 0.3835 - accuracy: 0.73060s - loss: 0.3818 - accura - ETA: 0s - los\n",
      "Epoch 17/200\n",
      "5946/5946 [==============================] - 6s 994us/step - loss: 0.3829 - accuracy: 0.73090s - loss: 0.3832 \n",
      "Epoch 18/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3822 - accuracy: 0.7316\n",
      "Epoch 19/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3817 - accuracy: 0.7336: 0s - loss: 0.3815 \n",
      "Epoch 20/200\n",
      "5946/5946 [==============================] - 6s 998us/step - loss: 0.3812 - accuracy: 0.7329\n",
      "Epoch 21/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3804 - accuracy: 0.7337\n",
      "Epoch 22/200\n",
      "5946/5946 [==============================] - 6s 983us/step - loss: 0.3796 - accuracy: 0.7346\n",
      "Epoch 23/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3792 - accuracy: 0.7347\n",
      "Epoch 24/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3784 - accuracy: 0.7351\n",
      "Epoch 25/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3779 - accuracy: 0.7352\n",
      "Epoch 26/200\n",
      "5946/5946 [==============================] - 6s 995us/step - loss: 0.3771 - accuracy: 0.7365\n",
      "Epoch 27/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3765 - accuracy: 0.7367\n",
      "Epoch 28/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3760 - accuracy: 0.7376\n",
      "Epoch 29/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3751 - accuracy: 0.7377\n",
      "Epoch 30/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3751 - accuracy: 0.7383\n",
      "Epoch 31/200\n",
      "5946/5946 [==============================] - 6s 959us/step - loss: 0.3741 - accuracy: 0.73950s - loss: 0.3742 - \n",
      "Epoch 32/200\n",
      "5946/5946 [==============================] - 6s 958us/step - loss: 0.3735 - accuracy: 0.7394\n",
      "Epoch 33/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3727 - accuracy: 0.7409\n",
      "Epoch 34/200\n",
      "5946/5946 [==============================] - ETA: 0s - loss: 0.3724 - accuracy: 0.74 - 6s 941us/step - loss: 0.3723 - accuracy: 0.7416\n",
      "Epoch 35/200\n",
      "5946/5946 [==============================] - 6s 985us/step - loss: 0.3717 - accuracy: 0.74150s - loss: 0.3\n",
      "Epoch 36/200\n",
      "5946/5946 [==============================] - 6s 972us/step - loss: 0.3709 - accuracy: 0.7426\n",
      "Epoch 37/200\n",
      "5946/5946 [==============================] - 6s 986us/step - loss: 0.3704 - accuracy: 0.7426\n",
      "Epoch 38/200\n",
      "5946/5946 [==============================] - 6s 959us/step - loss: 0.3695 - accuracy: 0.7419\n",
      "Epoch 39/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3691 - accuracy: 0.7440\n",
      "Epoch 40/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3690 - accuracy: 0.7443\n",
      "Epoch 41/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3685 - accuracy: 0.7442\n",
      "Epoch 42/200\n",
      "5946/5946 [==============================] - 6s 973us/step - loss: 0.3677 - accuracy: 0.7448\n",
      "Epoch 43/200\n",
      "5946/5946 [==============================] - 6s 991us/step - loss: 0.3671 - accuracy: 0.7453\n",
      "Epoch 44/200\n",
      "5946/5946 [==============================] - 6s 971us/step - loss: 0.3668 - accuracy: 0.7462\n",
      "Epoch 45/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3664 - accuracy: 0.7460\n",
      "Epoch 46/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3657 - accuracy: 0.7464\n",
      "Epoch 47/200\n",
      "5946/5946 [==============================] - 6s 967us/step - loss: 0.3656 - accuracy: 0.7469\n",
      "Epoch 48/200\n",
      "5946/5946 [==============================] - 6s 978us/step - loss: 0.3648 - accuracy: 0.7471\n",
      "Epoch 49/200\n",
      "5946/5946 [==============================] - 6s 990us/step - loss: 0.3644 - accuracy: 0.74750s - loss: 0.3\n",
      "Epoch 50/200\n",
      "5946/5946 [==============================] - 6s 969us/step - loss: 0.3640 - accuracy: 0.7478\n",
      "Epoch 51/200\n",
      "5946/5946 [==============================] - 6s 968us/step - loss: 0.3636 - accuracy: 0.7468\n",
      "Epoch 52/200\n",
      "5946/5946 [==============================] - 6s 960us/step - loss: 0.3632 - accuracy: 0.7480\n",
      "Epoch 53/200\n",
      "5946/5946 [==============================] - 6s 974us/step - loss: 0.3627 - accuracy: 0.7478\n",
      "Epoch 54/200\n",
      "5946/5946 [==============================] - 6s 963us/step - loss: 0.3625 - accuracy: 0.7496\n",
      "Epoch 55/200\n",
      "5946/5946 [==============================] - 6s 983us/step - loss: 0.3621 - accuracy: 0.7489\n",
      "Epoch 56/200\n",
      "5946/5946 [==============================] - 6s 993us/step - loss: 0.3616 - accuracy: 0.7495\n",
      "Epoch 57/200\n",
      "5946/5946 [==============================] - 6s 960us/step - loss: 0.3613 - accuracy: 0.74920s - loss: 0.3619 \n",
      "Epoch 58/200\n",
      "5946/5946 [==============================] - 6s 988us/step - loss: 0.3608 - accuracy: 0.7496\n",
      "Epoch 59/200\n",
      "5946/5946 [==============================] - 6s 972us/step - loss: 0.3605 - accuracy: 0.7505\n",
      "Epoch 60/200\n",
      "5946/5946 [==============================] - 6s 973us/step - loss: 0.3598 - accuracy: 0.7507\n",
      "Epoch 61/200\n",
      "5946/5946 [==============================] - 6s 961us/step - loss: 0.3597 - accuracy: 0.75110s - loss: 0.359\n",
      "Epoch 62/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3594 - accuracy: 0.7513\n",
      "Epoch 63/200\n",
      "5946/5946 [==============================] - 6s 980us/step - loss: 0.3589 - accuracy: 0.7505\n",
      "Epoch 64/200\n",
      "5946/5946 [==============================] - 6s 995us/step - loss: 0.3585 - accuracy: 0.75231s - loss: 0 - ETA: 0s - l\n",
      "Epoch 65/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3584 - accuracy: 0.7514\n",
      "Epoch 66/200\n",
      "5946/5946 [==============================] - 6s 979us/step - loss: 0.3581 - accuracy: 0.7515\n",
      "Epoch 67/200\n",
      "5946/5946 [==============================] - 6s 1000us/step - loss: 0.3576 - accuracy: 0.7511\n",
      "Epoch 68/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3576 - accuracy: 0.7521\n",
      "Epoch 69/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3571 - accuracy: 0.7525\n",
      "Epoch 70/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3567 - accuracy: 0.7520\n",
      "Epoch 71/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3563 - accuracy: 0.7524\n",
      "Epoch 72/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3559 - accuracy: 0.7525\n",
      "Epoch 73/200\n",
      "5946/5946 [==============================] - 6s 951us/step - loss: 0.3554 - accuracy: 0.75290s - l\n",
      "Epoch 74/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3556 - accuracy: 0.7533\n",
      "Epoch 75/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3553 - accuracy: 0.7535\n",
      "Epoch 76/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3550 - accuracy: 0.7540\n",
      "Epoch 77/200\n",
      "5946/5946 [==============================] - 6s 973us/step - loss: 0.3548 - accuracy: 0.7535\n",
      "Epoch 78/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3544 - accuracy: 0.7538\n",
      "Epoch 79/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3539 - accuracy: 0.7543: 0s - loss: 0.3539 - accuracy: 0.75\n",
      "Epoch 80/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3535 - accuracy: 0.7536\n",
      "Epoch 81/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3534 - accuracy: 0.7538\n",
      "Epoch 82/200\n",
      "5946/5946 [==============================] - 6s 987us/step - loss: 0.3534 - accuracy: 0.7536\n",
      "Epoch 83/200\n",
      "5946/5946 [==============================] - 6s 991us/step - loss: 0.3527 - accuracy: 0.7546\n",
      "Epoch 84/200\n",
      "5946/5946 [==============================] - 6s 949us/step - loss: 0.3526 - accuracy: 0.7553\n",
      "Epoch 85/200\n",
      "5946/5946 [==============================] - 6s 967us/step - loss: 0.3530 - accuracy: 0.7540\n",
      "Epoch 86/200\n",
      "5946/5946 [==============================] - 6s 991us/step - loss: 0.3522 - accuracy: 0.7551\n",
      "Epoch 87/200\n",
      "5946/5946 [==============================] - 6s 970us/step - loss: 0.3522 - accuracy: 0.7544\n",
      "Epoch 88/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3517 - accuracy: 0.7548\n",
      "Epoch 89/200\n",
      "5946/5946 [==============================] - 6s 963us/step - loss: 0.3512 - accuracy: 0.75521s - l - ETA\n",
      "Epoch 90/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3513 - accuracy: 0.7553\n",
      "Epoch 91/200\n",
      "5946/5946 [==============================] - 6s 987us/step - loss: 0.3511 - accuracy: 0.7551: 0s - loss:\n",
      "Epoch 92/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3511 - accuracy: 0.7555\n",
      "Epoch 93/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3508 - accuracy: 0.7560\n",
      "Epoch 94/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3507 - accuracy: 0.7557: 0s - loss: 0.3508 - accuracy: 0.75\n",
      "Epoch 95/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3501 - accuracy: 0.7567\n",
      "Epoch 96/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3502 - accuracy: 0.7559\n",
      "Epoch 97/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3499 - accuracy: 0.7562\n",
      "Epoch 98/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3498 - accuracy: 0.7560\n",
      "Epoch 99/200\n",
      "5946/5946 [==============================] - 6s 1ms/step - loss: 0.3498 - accuracy: 0.7561\n",
      "Epoch 100/200\n",
      "5946/5946 [==============================] - 6s 975us/step - loss: 0.3492 - accuracy: 0.7564\n",
      "Epoch 101/200\n",
      "5946/5946 [==============================] - 6s 986us/step - loss: 0.3491 - accuracy: 0.7563\n",
      "Epoch 102/200\n",
      "5946/5946 [==============================] - 6s 935us/step - loss: 0.3489 - accuracy: 0.7572\n",
      "Epoch 103/200\n",
      "5946/5946 [==============================] - 6s 977us/step - loss: 0.3486 - accuracy: 0.7570\n",
      "Epoch 104/200\n",
      "5946/5946 [==============================] - 6s 951us/step - loss: 0.3485 - accuracy: 0.75621s - loss: 0.3477 - accuracy\n",
      "Epoch 105/200\n",
      "5946/5946 [==============================] - 6s 940us/step - loss: 0.3481 - accuracy: 0.7570\n",
      "Epoch 106/200\n",
      "5946/5946 [==============================] - 6s 955us/step - loss: 0.3485 - accuracy: 0.75661s\n",
      "Epoch 107/200\n",
      "5946/5946 [==============================] - 6s 942us/step - loss: 0.3479 - accuracy: 0.7570\n",
      "Epoch 108/200\n",
      "5946/5946 [==============================] - 6s 950us/step - loss: 0.3477 - accuracy: 0.7579\n",
      "Epoch 109/200\n",
      "5946/5946 [==============================] - 6s 932us/step - loss: 0.3475 - accuracy: 0.7565\n",
      "Epoch 110/200\n",
      "5946/5946 [==============================] - 6s 948us/step - loss: 0.3473 - accuracy: 0.7571\n",
      "Epoch 111/200\n",
      "5946/5946 [==============================] - 6s 945us/step - loss: 0.3480 - accuracy: 0.7561\n",
      "Epoch 112/200\n",
      "5946/5946 [==============================] - 6s 951us/step - loss: 0.3478 - accuracy: 0.75710s - loss:\n",
      "Epoch 113/200\n",
      "5946/5946 [==============================] - 6s 938us/step - loss: 0.3478 - accuracy: 0.7570\n"
     ]
    }
   ],
   "source": [
    "nn13.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "fit_model = nn13.fit(X_train_scaled,y_train, batch_size=32, epochs=200, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "01eb762d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1982/1982 - 1s - loss: 0.4180 - accuracy: 0.7302\n",
      "Loss: 0.41800761222839355, Accuracy: 0.7301639914512634\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn13.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889fa7c1",
   "metadata": {},
   "source": [
    "## Attempt 14\n",
    "### Attempted to further improve Attempt 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b13f0511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = df_no_pre[\"Diabetes_012\"].values\n",
    "X = df_no_pre.drop(columns=['Diabetes_012']).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "df34fb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_56 (Dense)             (None, 140)               3080      \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 100)               14100     \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 26,961\n",
      "Trainable params: 26,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 140\n",
    "hidden_nodes_layer2 = 100\n",
    "hidden_nodes_layer3 = 80\n",
    "hidden_nodes_layer3 = 60\n",
    "nn14 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn14.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# Second hidden layer\n",
    "nn14.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# Third hidden layer\n",
    "nn14.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn14.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "\n",
    "# Output layer\n",
    "nn14.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn14.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e104e9b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5838/5838 [==============================] - 8s 1ms/step - loss: 0.3945 - accuracy: 0.7356\n",
      "Epoch 2/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3908 - accuracy: 0.7388\n",
      "Epoch 3/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3897 - accuracy: 0.7412\n",
      "Epoch 4/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3889 - accuracy: 0.7416\n",
      "Epoch 5/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3884 - accuracy: 0.7440\n",
      "Epoch 6/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3879 - accuracy: 0.7457\n",
      "Epoch 7/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3875 - accuracy: 0.7456\n",
      "Epoch 8/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3870 - accuracy: 0.7454\n",
      "Epoch 9/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3867 - accuracy: 0.7442\n",
      "Epoch 10/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3861 - accuracy: 0.7439\n",
      "Epoch 11/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3856 - accuracy: 0.7451\n",
      "Epoch 12/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3850 - accuracy: 0.7457\n",
      "Epoch 13/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3847 - accuracy: 0.7471\n",
      "Epoch 14/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3840 - accuracy: 0.7461\n",
      "Epoch 15/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3834 - accuracy: 0.7482\n",
      "Epoch 16/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3829 - accuracy: 0.7477\n",
      "Epoch 17/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3819 - accuracy: 0.7489: 0s - loss: 0.3818 - accuracy: 0.74\n",
      "Epoch 18/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3814 - accuracy: 0.7503\n",
      "Epoch 19/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3806 - accuracy: 0.7527\n",
      "Epoch 20/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3799 - accuracy: 0.7513\n",
      "Epoch 21/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3794 - accuracy: 0.7534\n",
      "Epoch 22/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3785 - accuracy: 0.7537\n",
      "Epoch 23/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3777 - accuracy: 0.7553\n",
      "Epoch 24/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3773 - accuracy: 0.7571\n",
      "Epoch 25/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3760 - accuracy: 0.7582\n",
      "Epoch 26/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3754 - accuracy: 0.7598\n",
      "Epoch 27/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3746 - accuracy: 0.7590\n",
      "Epoch 28/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3736 - accuracy: 0.7594\n",
      "Epoch 29/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3728 - accuracy: 0.7623\n",
      "Epoch 30/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3723 - accuracy: 0.7622: 0s - loss: 0.3728 - accu\n",
      "Epoch 31/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3712 - accuracy: 0.7634\n",
      "Epoch 32/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3703 - accuracy: 0.7644\n",
      "Epoch 33/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3697 - accuracy: 0.7666\n",
      "Epoch 34/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3689 - accuracy: 0.7667\n",
      "Epoch 35/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3685 - accuracy: 0.7679\n",
      "Epoch 36/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3672 - accuracy: 0.7678\n",
      "Epoch 37/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3669 - accuracy: 0.7679\n",
      "Epoch 38/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3660 - accuracy: 0.7694\n",
      "Epoch 39/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3653 - accuracy: 0.7701\n",
      "Epoch 40/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3648 - accuracy: 0.7698\n",
      "Epoch 41/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3640 - accuracy: 0.7715\n",
      "Epoch 42/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3632 - accuracy: 0.7718\n",
      "Epoch 43/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3630 - accuracy: 0.7725\n",
      "Epoch 44/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3618 - accuracy: 0.7715\n",
      "Epoch 45/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3612 - accuracy: 0.7725\n",
      "Epoch 46/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3607 - accuracy: 0.7750\n",
      "Epoch 47/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3602 - accuracy: 0.7747\n",
      "Epoch 48/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3598 - accuracy: 0.7741\n",
      "Epoch 49/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3590 - accuracy: 0.7757\n",
      "Epoch 50/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3584 - accuracy: 0.7757\n",
      "Epoch 51/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3577 - accuracy: 0.7762\n",
      "Epoch 52/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3566 - accuracy: 0.7768\n",
      "Epoch 53/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3568 - accuracy: 0.7755\n",
      "Epoch 54/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3561 - accuracy: 0.7761\n",
      "Epoch 55/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3555 - accuracy: 0.7771\n",
      "Epoch 56/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3544 - accuracy: 0.7770\n",
      "Epoch 57/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3543 - accuracy: 0.7773\n",
      "Epoch 58/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3536 - accuracy: 0.7781\n",
      "Epoch 59/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3537 - accuracy: 0.7778\n",
      "Epoch 60/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3528 - accuracy: 0.7776TA: 0s - loss: 0.3521 - accuracy\n",
      "Epoch 61/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3521 - accuracy: 0.7772\n",
      "Epoch 62/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3516 - accuracy: 0.7784\n",
      "Epoch 63/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3510 - accuracy: 0.7776\n",
      "Epoch 64/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3504 - accuracy: 0.7790\n",
      "Epoch 65/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3505 - accuracy: 0.7779\n",
      "Epoch 66/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3497 - accuracy: 0.7780\n",
      "Epoch 67/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3491 - accuracy: 0.7784\n",
      "Epoch 68/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3486 - accuracy: 0.7786\n",
      "Epoch 69/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3477 - accuracy: 0.7791\n",
      "Epoch 70/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3473 - accuracy: 0.7791\n",
      "Epoch 71/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3473 - accuracy: 0.7794\n",
      "Epoch 72/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3472 - accuracy: 0.7799\n",
      "Epoch 73/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3467 - accuracy: 0.7784\n",
      "Epoch 74/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3465 - accuracy: 0.7789\n",
      "Epoch 75/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3455 - accuracy: 0.7795: 0s - loss: 0.3450 - accu\n",
      "Epoch 76/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3451 - accuracy: 0.7797\n",
      "Epoch 77/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3449 - accuracy: 0.7789\n",
      "Epoch 78/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3443 - accuracy: 0.7798\n",
      "Epoch 79/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3443 - accuracy: 0.7790\n",
      "Epoch 80/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3428 - accuracy: 0.7799\n",
      "Epoch 81/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3421 - accuracy: 0.7802\n",
      "Epoch 82/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3433 - accuracy: 0.7790\n",
      "Epoch 83/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3422 - accuracy: 0.7800\n"
     ]
    }
   ],
   "source": [
    "nn14.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n",
    "fit_model = nn14.fit(X_train_scaled,y_train, batch_size = 32, epochs=200, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4801d32d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1946/1946 - 1s - loss: 0.4203 - accuracy: 0.7466\n",
      "Loss: 0.4202822148799896, Accuracy: 0.7465589642524719\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn14.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1963bc5e",
   "metadata": {},
   "source": [
    "## Attempt 15\n",
    "### Try improving previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5f22cae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = df_no_pre[\"Diabetes_012\"].values\n",
    "X = df_no_pre.drop(columns=['Diabetes_012']).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ec74a1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 140)               3080      \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 100)               14100     \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 26,961\n",
      "Trainable params: 26,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 140\n",
    "hidden_nodes_layer2 = 100\n",
    "hidden_nodes_layer3 = 80\n",
    "hidden_nodes_layer4 = 60\n",
    "nn15 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn15.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn15.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn15.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn15.add(tf.keras.layers.Dense(units=hidden_nodes_layer4, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn15.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn15.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "061267d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3945 - accuracy: 0.7305\n",
      "Epoch 2/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3906 - accuracy: 0.7362\n",
      "Epoch 3/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3895 - accuracy: 0.7395\n",
      "Epoch 4/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3887 - accuracy: 0.7381\n",
      "Epoch 5/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3880 - accuracy: 0.7395\n",
      "Epoch 6/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3874 - accuracy: 0.7410\n",
      "Epoch 7/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3868 - accuracy: 0.7426\n",
      "Epoch 8/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3862 - accuracy: 0.7433: 0s\n",
      "Epoch 9/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3856 - accuracy: 0.7420: 0s - loss: 0.3853 - accuracy\n",
      "Epoch 10/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3848 - accuracy: 0.7413\n",
      "Epoch 11/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3840 - accuracy: 0.7434\n",
      "Epoch 12/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3831 - accuracy: 0.7404\n",
      "Epoch 13/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3823 - accuracy: 0.7431\n",
      "Epoch 14/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3814 - accuracy: 0.7443\n",
      "Epoch 15/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3805 - accuracy: 0.7442\n",
      "Epoch 16/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3792 - accuracy: 0.7471\n",
      "Epoch 17/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3784 - accuracy: 0.7493\n",
      "Epoch 18/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3772 - accuracy: 0.7520\n",
      "Epoch 19/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3759 - accuracy: 0.7524\n",
      "Epoch 20/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3750 - accuracy: 0.7550\n",
      "Epoch 21/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3740 - accuracy: 0.7570\n",
      "Epoch 22/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3726 - accuracy: 0.7568\n",
      "Epoch 23/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3717 - accuracy: 0.7598\n",
      "Epoch 24/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3705 - accuracy: 0.7619\n",
      "Epoch 25/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3692 - accuracy: 0.7619\n",
      "Epoch 26/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3686 - accuracy: 0.7650\n",
      "Epoch 27/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3676 - accuracy: 0.7672\n",
      "Epoch 28/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3668 - accuracy: 0.7662\n",
      "Epoch 29/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3658 - accuracy: 0.7662\n",
      "Epoch 30/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3653 - accuracy: 0.7685\n",
      "Epoch 31/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3639 - accuracy: 0.7711\n",
      "Epoch 32/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3631 - accuracy: 0.7700\n",
      "Epoch 33/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3619 - accuracy: 0.7715: 0s - loss: 0.3620 - accuracy: 0.\n",
      "Epoch 34/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3615 - accuracy: 0.7725\n",
      "Epoch 35/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3608 - accuracy: 0.7731\n",
      "Epoch 36/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3593 - accuracy: 0.7733\n",
      "Epoch 37/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3593 - accuracy: 0.7745\n",
      "Epoch 38/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3586 - accuracy: 0.7757\n",
      "Epoch 39/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3574 - accuracy: 0.7745\n",
      "Epoch 40/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3575 - accuracy: 0.7743\n",
      "Epoch 41/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3561 - accuracy: 0.7742\n",
      "Epoch 42/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3562 - accuracy: 0.7749\n",
      "Epoch 43/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3553 - accuracy: 0.7756\n",
      "Epoch 44/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3540 - accuracy: 0.7753\n",
      "Epoch 45/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3532 - accuracy: 0.7769\n",
      "Epoch 46/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3535 - accuracy: 0.7787: 0s - loss: 0.3537 - accu\n",
      "Epoch 47/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3525 - accuracy: 0.7788\n",
      "Epoch 48/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3514 - accuracy: 0.7786\n",
      "Epoch 49/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3509 - accuracy: 0.7806\n",
      "Epoch 50/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3515 - accuracy: 0.7789\n",
      "Epoch 51/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3503 - accuracy: 0.7797: 0s - loss: 0.3502 \n",
      "Epoch 52/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3491 - accuracy: 0.7797\n",
      "Epoch 53/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3485 - accuracy: 0.7815\n",
      "Epoch 54/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3484 - accuracy: 0.7823\n",
      "Epoch 55/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3478 - accuracy: 0.7808\n",
      "Epoch 56/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3469 - accuracy: 0.7823\n",
      "Epoch 57/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3463 - accuracy: 0.7817\n",
      "Epoch 58/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3454 - accuracy: 0.7837\n",
      "Epoch 59/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3452 - accuracy: 0.7834\n",
      "Epoch 60/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3445 - accuracy: 0.7852\n",
      "Epoch 61/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3443 - accuracy: 0.7837\n",
      "Epoch 62/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3439 - accuracy: 0.7858\n",
      "Epoch 63/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3440 - accuracy: 0.7847\n",
      "Epoch 64/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3440 - accuracy: 0.7857\n"
     ]
    }
   ],
   "source": [
    "nn15.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n",
    "fit_model = nn15.fit(X_train_scaled,y_train, batch_size = 32, epochs=200, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "09733f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1946/1946 - 1s - loss: 0.4172 - accuracy: 0.7646\n",
      "Loss: 0.4171711504459381, Accuracy: 0.7645632028579712\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn15.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659e56a3",
   "metadata": {},
   "source": [
    "## Attempt 16\n",
    "### Similar to 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5900dce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_012</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>MentalHealth</th>\n",
       "      <th>PhysicalHealth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_012  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0           0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1           0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2           0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3           0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4           0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                   0.0           0.0     0.0  ...            1.0   \n",
       "1                   0.0           1.0     0.0  ...            0.0   \n",
       "2                   0.0           0.0     1.0  ...            1.0   \n",
       "3                   0.0           1.0     1.0  ...            1.0   \n",
       "4                   0.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "   NoDocbcCost  GenHlth  DiffWalk  Sex   Age  Education  Income  MentalHealth  \\\n",
       "0          0.0      5.0       1.0  0.0   9.0        4.0     3.0           4.0   \n",
       "1          1.0      3.0       0.0  0.0   7.0        6.0     1.0           1.0   \n",
       "2          1.0      5.0       1.0  0.0   9.0        4.0     8.0           6.0   \n",
       "3          0.0      2.0       0.0  0.0  11.0        3.0     6.0           1.0   \n",
       "4          0.0      2.0       0.0  0.0  11.0        5.0     4.0           1.0   \n",
       "\n",
       "   PhysicalHealth  \n",
       "0             3.0  \n",
       "1             1.0  \n",
       "2             6.0  \n",
       "3             1.0  \n",
       "4             1.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_pre2 = df[df[\"Diabetes_012\"] != 1]\n",
    "df_no_pre2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0934fe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = df_no_pre2[\"Diabetes_012\"].values\n",
    "X = df_no_pre2.drop(columns=['Diabetes_012']).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "14fdd04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_91 (Dense)             (None, 140)               3080      \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 120)               16920     \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 100)               12100     \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 80)                8080      \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 1)                 81        \n",
      "=================================================================\n",
      "Total params: 40,261\n",
      "Trainable params: 40,261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 140\n",
    "hidden_nodes_layer2 = 120\n",
    "hidden_nodes_layer3 = 100\n",
    "hidden_nodes_layer4 = 80\n",
    "nn16 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn16.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn16.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn16.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn16.add(tf.keras.layers.Dense(units=hidden_nodes_layer4, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn16.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f05508fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5838/5838 [==============================] - 8s 1ms/step - loss: 0.3945 - accuracy: 0.7375: 1s - loss: 0.3948 -  - ETA: 0s - l\n",
      "Epoch 2/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3909 - accuracy: 0.7409\n",
      "Epoch 3/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3895 - accuracy: 0.7399: 0s - loss: 0.3890 \n",
      "Epoch 4/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3888 - accuracy: 0.7418\n",
      "Epoch 5/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3879 - accuracy: 0.7420\n",
      "Epoch 6/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3873 - accuracy: 0.7399: 0s - loss: 0.386\n",
      "Epoch 7/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3869 - accuracy: 0.7407\n",
      "Epoch 8/200\n",
      "5838/5838 [==============================] - 8s 1ms/step - loss: 0.3862 - accuracy: 0.7424\n",
      "Epoch 9/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3854 - accuracy: 0.7420\n",
      "Epoch 10/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3846 - accuracy: 0.7432\n",
      "Epoch 11/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3838 - accuracy: 0.7429\n",
      "Epoch 12/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3830 - accuracy: 0.7449\n",
      "Epoch 13/200\n",
      "5838/5838 [==============================] - 8s 1ms/step - loss: 0.3821 - accuracy: 0.7454\n",
      "Epoch 14/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3809 - accuracy: 0.7486\n",
      "Epoch 15/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3800 - accuracy: 0.7481\n",
      "Epoch 16/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3792 - accuracy: 0.7508\n",
      "Epoch 17/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3779 - accuracy: 0.7530\n",
      "Epoch 18/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3768 - accuracy: 0.7565\n",
      "Epoch 19/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3760 - accuracy: 0.7597\n",
      "Epoch 20/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3747 - accuracy: 0.7586\n",
      "Epoch 21/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3735 - accuracy: 0.7596\n",
      "Epoch 22/200\n",
      "5838/5838 [==============================] - 8s 1ms/step - loss: 0.3723 - accuracy: 0.7626: 0s - loss: 0.3719 - accuracy\n",
      "Epoch 23/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3713 - accuracy: 0.7688\n",
      "Epoch 24/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3705 - accuracy: 0.7666\n",
      "Epoch 25/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3697 - accuracy: 0.7662\n",
      "Epoch 26/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3689 - accuracy: 0.7679\n",
      "Epoch 27/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3679 - accuracy: 0.7675\n",
      "Epoch 28/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3667 - accuracy: 0.7686\n",
      "Epoch 29/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3655 - accuracy: 0.7690\n",
      "Epoch 30/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3649 - accuracy: 0.7694\n",
      "Epoch 31/200\n",
      "5838/5838 [==============================] - 8s 1ms/step - loss: 0.3637 - accuracy: 0.7714: 0s - loss: 0.3639 - accuracy\n",
      "Epoch 32/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3635 - accuracy: 0.7724: 0s - loss: 0.3634 - accuracy: \n",
      "Epoch 33/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3622 - accuracy: 0.7729\n",
      "Epoch 34/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3611 - accuracy: 0.7729\n",
      "Epoch 35/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3609 - accuracy: 0.7743\n",
      "Epoch 36/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3601 - accuracy: 0.7770\n",
      "Epoch 37/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3589 - accuracy: 0.7777\n",
      "Epoch 38/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3582 - accuracy: 0.7783\n",
      "Epoch 39/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3576 - accuracy: 0.7764\n",
      "Epoch 40/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3571 - accuracy: 0.7799\n",
      "Epoch 41/200\n",
      "5838/5838 [==============================] - ETA: 0s - loss: 0.3559 - accuracy: 0.78 - 7s 1ms/step - loss: 0.3558 - accuracy: 0.7801\n",
      "Epoch 42/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3559 - accuracy: 0.7796\n",
      "Epoch 43/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3549 - accuracy: 0.7794\n",
      "Epoch 44/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3539 - accuracy: 0.7791\n",
      "Epoch 45/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3535 - accuracy: 0.7808: 0s - loss: 0.3533 - accuracy: 0.\n",
      "Epoch 46/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3522 - accuracy: 0.7811\n",
      "Epoch 47/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3525 - accuracy: 0.7819: 0s\n",
      "Epoch 48/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3524 - accuracy: 0.7812\n",
      "Epoch 49/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3505 - accuracy: 0.7826\n",
      "Epoch 50/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3503 - accuracy: 0.7823\n",
      "Epoch 51/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3502 - accuracy: 0.7828\n",
      "Epoch 52/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3493 - accuracy: 0.7846\n",
      "Epoch 53/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3481 - accuracy: 0.7837\n",
      "Epoch 54/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3475 - accuracy: 0.7858: 0s - l\n",
      "Epoch 55/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3479 - accuracy: 0.7853\n",
      "Epoch 56/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3473 - accuracy: 0.7849: 0s - loss: 0.3466 - ac\n",
      "Epoch 57/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3465 - accuracy: 0.7855: 0s - loss: 0.3465 \n",
      "Epoch 58/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3455 - accuracy: 0.7852\n",
      "Epoch 59/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3454 - accuracy: 0.7844\n",
      "Epoch 60/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3447 - accuracy: 0.7862: 0s - loss: 0.344\n",
      "Epoch 61/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3444 - accuracy: 0.7856\n",
      "Epoch 62/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3443 - accuracy: 0.7850\n",
      "Epoch 63/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3438 - accuracy: 0.7856\n",
      "Epoch 64/200\n",
      "5838/5838 [==============================] - 6s 1ms/step - loss: 0.3436 - accuracy: 0.7851\n",
      "Epoch 65/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3427 - accuracy: 0.7857\n",
      "Epoch 66/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3419 - accuracy: 0.7874\n",
      "Epoch 67/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3421 - accuracy: 0.7864\n",
      "Epoch 68/200\n",
      "5838/5838 [==============================] - 8s 1ms/step - loss: 0.3415 - accuracy: 0.7867\n",
      "Epoch 69/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3416 - accuracy: 0.7878\n",
      "Epoch 70/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3414 - accuracy: 0.7869\n",
      "Epoch 71/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3406 - accuracy: 0.7870\n",
      "Epoch 72/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3393 - accuracy: 0.7884\n",
      "Epoch 73/200\n",
      "5838/5838 [==============================] - 8s 1ms/step - loss: 0.3407 - accuracy: 0.7874\n",
      "Epoch 74/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3394 - accuracy: 0.7880\n",
      "Epoch 75/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3401 - accuracy: 0.7889: 0s - loss: 0.3400 - accura\n"
     ]
    }
   ],
   "source": [
    "nn16.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "fit_model = nn16.fit(X_train_scaled,y_train, batch_size = 32, epochs=200, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b41be676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1946/1946 - 1s - loss: 0.4250 - accuracy: 0.7682\n",
      "Loss: 0.42496955394744873, Accuracy: 0.7681769132614136\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn16.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9a9fa411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Models/diabetes_02_model\\assets\n"
     ]
    }
   ],
   "source": [
    "nn16.save('../Models/diabetes_02_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3c17e1",
   "metadata": {},
   "source": [
    "## Attempt 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "31dddb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = df_no_pre2[\"Diabetes_012\"].values\n",
    "X = df_no_pre2.drop(columns=['Diabetes_012']).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6fb4b32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_86 (Dense)             (None, 160)               3520      \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 140)               22540     \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 120)               16920     \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 100)               12100     \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 55,181\n",
      "Trainable params: 55,181\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 160\n",
    "hidden_nodes_layer2 = 140\n",
    "hidden_nodes_layer3 = 120\n",
    "hidden_nodes_layer4 = 100\n",
    "nn17 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn17.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn17.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn17.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn17.add(tf.keras.layers.Dense(units=hidden_nodes_layer4, activation=\"sigmoid\"))\n",
    "\n",
    "# Output layer\n",
    "nn17.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn17.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "57727268",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3951 - accuracy: 0.7338\n",
      "Epoch 2/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3912 - accuracy: 0.7292\n",
      "Epoch 3/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3899 - accuracy: 0.7307\n",
      "Epoch 4/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3890 - accuracy: 0.7325\n",
      "Epoch 5/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3883 - accuracy: 0.7350\n",
      "Epoch 6/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3876 - accuracy: 0.7348\n",
      "Epoch 7/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3869 - accuracy: 0.7370\n",
      "Epoch 8/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3862 - accuracy: 0.7364\n",
      "Epoch 9/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3855 - accuracy: 0.7393\n",
      "Epoch 10/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3847 - accuracy: 0.7408\n",
      "Epoch 11/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3837 - accuracy: 0.7427\n",
      "Epoch 12/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3827 - accuracy: 0.7445\n",
      "Epoch 13/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3812 - accuracy: 0.7481\n",
      "Epoch 14/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3799 - accuracy: 0.7503\n",
      "Epoch 15/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3786 - accuracy: 0.7543\n",
      "Epoch 16/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3775 - accuracy: 0.7566\n",
      "Epoch 17/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3761 - accuracy: 0.7591\n",
      "Epoch 18/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3752 - accuracy: 0.7602: 0s - loss: 0.3752 - accu\n",
      "Epoch 19/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3738 - accuracy: 0.7623\n",
      "Epoch 20/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3732 - accuracy: 0.7632\n",
      "Epoch 21/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3718 - accuracy: 0.7650\n",
      "Epoch 22/200\n",
      "5838/5838 [==============================] - 8s 1ms/step - loss: 0.3707 - accuracy: 0.7673\n",
      "Epoch 23/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3693 - accuracy: 0.7697\n",
      "Epoch 24/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3684 - accuracy: 0.7705\n",
      "Epoch 25/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3671 - accuracy: 0.7715\n",
      "Epoch 26/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3664 - accuracy: 0.7741: 0s - loss: 0\n",
      "Epoch 27/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3654 - accuracy: 0.7738: 0s - loss: 0.3651 - ac\n",
      "Epoch 28/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3647 - accuracy: 0.7741\n",
      "Epoch 29/200\n",
      "5838/5838 [==============================] - 8s 1ms/step - loss: 0.3636 - accuracy: 0.7753\n",
      "Epoch 30/200\n",
      "5838/5838 [==============================] - 8s 1ms/step - loss: 0.3627 - accuracy: 0.7770\n",
      "Epoch 31/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3621 - accuracy: 0.7774\n",
      "Epoch 32/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3607 - accuracy: 0.7787\n",
      "Epoch 33/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3601 - accuracy: 0.7789\n",
      "Epoch 34/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3596 - accuracy: 0.7790\n",
      "Epoch 35/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3584 - accuracy: 0.7799\n",
      "Epoch 36/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3581 - accuracy: 0.7815\n",
      "Epoch 37/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3572 - accuracy: 0.7798\n",
      "Epoch 38/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3570 - accuracy: 0.7813\n",
      "Epoch 39/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3556 - accuracy: 0.7815\n",
      "Epoch 40/200\n",
      "5838/5838 [==============================] - 9s 1ms/step - loss: 0.3552 - accuracy: 0.7828: 0s - l\n",
      "Epoch 41/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3550 - accuracy: 0.7819\n",
      "Epoch 42/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3540 - accuracy: 0.7835\n",
      "Epoch 43/200\n",
      "5838/5838 [==============================] - 8s 1ms/step - loss: 0.3538 - accuracy: 0.7860\n",
      "Epoch 44/200\n",
      "5838/5838 [==============================] - 8s 1ms/step - loss: 0.3534 - accuracy: 0.7845\n",
      "Epoch 45/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3532 - accuracy: 0.7860\n",
      "Epoch 46/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3524 - accuracy: 0.7861\n",
      "Epoch 47/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3520 - accuracy: 0.7863\n",
      "Epoch 48/200\n",
      "5838/5838 [==============================] - 8s 1ms/step - loss: 0.3520 - accuracy: 0.7867\n",
      "Epoch 49/200\n",
      "5838/5838 [==============================] - 8s 1ms/step - loss: 0.3507 - accuracy: 0.7869\n",
      "Epoch 50/200\n",
      "5838/5838 [==============================] - 8s 1ms/step - loss: 0.3507 - accuracy: 0.7864\n",
      "Epoch 51/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3503 - accuracy: 0.7879\n",
      "Epoch 52/200\n",
      "5838/5838 [==============================] - 8s 1ms/step - loss: 0.3502 - accuracy: 0.7876\n",
      "Epoch 53/200\n",
      "5838/5838 [==============================] - 8s 1ms/step - loss: 0.3496 - accuracy: 0.7889\n",
      "Epoch 54/200\n",
      "5838/5838 [==============================] - 9s 2ms/step - loss: 0.3488 - accuracy: 0.7887\n",
      "Epoch 55/200\n",
      "5838/5838 [==============================] - 9s 2ms/step - loss: 0.3485 - accuracy: 0.7888\n",
      "Epoch 56/200\n",
      "5838/5838 [==============================] - 8s 1ms/step - loss: 0.3477 - accuracy: 0.7894\n",
      "Epoch 57/200\n",
      "5838/5838 [==============================] - 8s 1ms/step - loss: 0.3479 - accuracy: 0.7891\n",
      "Epoch 58/200\n",
      "5838/5838 [==============================] - 7s 1ms/step - loss: 0.3496 - accuracy: 0.7888: 0s - loss: 0.3494 - accu - ETA: 0s - loss: 0.3493 - accuracy\n"
     ]
    }
   ],
   "source": [
    "nn17.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "fit_model = nn17.fit(X_train_scaled,y_train, batch_size = 32, epochs=200, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "312c7d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1946/1946 - 1s - loss: 0.4161 - accuracy: 0.7577\n",
      "Loss: 0.416098415851593, Accuracy: 0.7577052116394043\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn17.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eb8c4a",
   "metadata": {},
   "source": [
    "## Attempt 18\n",
    "### Similar to 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "22fcdd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = df_no_pre2[\"Diabetes_012\"].values\n",
    "X = df_no_pre2.drop(columns=['Diabetes_012']).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d48aa946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_154 (Dense)            (None, 140)               3080      \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 80)                11280     \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 5)                 405       \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 60)                360       \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 5)                 305       \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 40)                240       \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 15,711\n",
      "Trainable params: 15,711\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 140\n",
    "hidden_nodes_layer2 = 80\n",
    "hidden_nodes_layer3 = 60\n",
    "hidden_nodes_layer4 = 40\n",
    "nn17 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn17.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn17.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Dropout\n",
    "nn17.add(tf.keras.layers.Dense(5, input_dim=5, kernel_initializer='ones', kernel_regularizer=tf.keras.regularizers.L1(0.01),\n",
    "    activity_regularizer=tf.keras.regularizers.L2(0.01)))\n",
    "\n",
    "# Third hidden layer\n",
    "nn17.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Dropout\n",
    "nn17.add(tf.keras.layers.Dense(5, input_dim=5, kernel_initializer='ones', kernel_regularizer=tf.keras.regularizers.L1(0.01),\n",
    "    activity_regularizer=tf.keras.regularizers.L2(0.01)))\n",
    "\n",
    "# Fourth hidden layer\n",
    "nn17.add(tf.keras.layers.Dense(units=hidden_nodes_layer4, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn17.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn17.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "61395346",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4670/4670 [==============================] - 7s 1ms/step - loss: 4.6162 - accuracy: 0.8346 - val_loss: 1.5151 - val_accuracy: 0.6458\n",
      "Epoch 2/200\n",
      "4670/4670 [==============================] - 6s 1ms/step - loss: 0.6609 - accuracy: 0.7172 - val_loss: 0.4215 - val_accuracy: 0.7054\n",
      "Epoch 3/200\n",
      "4670/4670 [==============================] - 7s 1ms/step - loss: 0.4051 - accuracy: 0.7302 - val_loss: 0.4092 - val_accuracy: 0.7180\n",
      "Epoch 4/200\n",
      "4670/4670 [==============================] - 6s 1ms/step - loss: 0.3990 - accuracy: 0.7331 - val_loss: 0.4088 - val_accuracy: 0.7450\n",
      "Epoch 5/200\n",
      "4670/4670 [==============================] - 7s 1ms/step - loss: 0.3966 - accuracy: 0.7355 - val_loss: 0.4079 - val_accuracy: 0.7448\n",
      "Epoch 6/200\n",
      "4670/4670 [==============================] - 6s 1ms/step - loss: 0.3948 - accuracy: 0.7392 - val_loss: 0.4077 - val_accuracy: 0.7509\n",
      "Epoch 7/200\n",
      "4670/4670 [==============================] - 6s 1ms/step - loss: 0.3944 - accuracy: 0.7385 - val_loss: 0.4059 - val_accuracy: 0.7579\n",
      "Epoch 8/200\n",
      "4670/4670 [==============================] - 6s 1ms/step - loss: 0.3931 - accuracy: 0.7426 - val_loss: 0.4071 - val_accuracy: 0.7502\n",
      "Epoch 9/200\n",
      "4670/4670 [==============================] - 6s 1ms/step - loss: 0.3925 - accuracy: 0.7434 - val_loss: 0.4134 - val_accuracy: 0.7804\n",
      "Epoch 10/200\n",
      "4670/4670 [==============================] - 6s 1ms/step - loss: 0.3919 - accuracy: 0.7444 - val_loss: 0.4051 - val_accuracy: 0.7455\n",
      "Epoch 11/200\n",
      "4670/4670 [==============================] - 6s 1ms/step - loss: 0.3913 - accuracy: 0.7443 - val_loss: 0.4038 - val_accuracy: 0.7435\n",
      "Epoch 12/200\n",
      "4670/4670 [==============================] - 6s 1ms/step - loss: 0.3910 - accuracy: 0.7440 - val_loss: 0.4113 - val_accuracy: 0.7724\n",
      "Epoch 13/200\n",
      "4670/4670 [==============================] - 6s 1ms/step - loss: 0.3903 - accuracy: 0.7458 - val_loss: 0.4058 - val_accuracy: 0.7605\n",
      "Epoch 14/200\n",
      "4670/4670 [==============================] - 6s 1ms/step - loss: 0.3897 - accuracy: 0.7462 - val_loss: 0.4046 - val_accuracy: 0.7495\n"
     ]
    }
   ],
   "source": [
    "nn17.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "fit_model = nn17.fit(X_train_scaled,y_train, batch_size = 32, epochs=200, callbacks=[callback], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6bd8bb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1946/1946 - 1s - loss: 0.3994 - accuracy: 0.7521\n",
      "Loss: 0.39938727021217346, Accuracy: 0.7520678639411926\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn17.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9b817845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.title('Learning Curves')\n",
    "pyplot.xlabel('Epoch')\n",
    "pyplot.ylabel('Cross Entropy')\n",
    "pyplot.plot(fit_model.history['loss'], label='train')\n",
    "pyplot.plot(fit_model.history['val_loss'], label='val')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaedaf12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b2141c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
